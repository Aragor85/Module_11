{"cells": [{"metadata": {}, "id": "441159cc", "cell_type": "markdown", "source": "# D\u00e9ployez un mod\u00e8le dans le cloud\n\n\n# Sommaire :\n\n**1. Pr\u00e9ambule**<br />\n&emsp;1.1 Probl\u00e9matique<br />\n&emsp;1.2 Objectifs dans ce projet<br />\n&emsp;1.3 D\u00e9roulement des \u00e9tapes du projet<br />\n**2. Choix techniques g\u00e9n\u00e9raux retenus**<br />\n&emsp;2.1 Calcul distribu\u00e9<br />\n&emsp;2.2 Transfert Learning<br />\n**3. D\u00e9ploiement de la solution en local**<br />\n&emsp;3.1 Environnement de travail<br />\n&emsp;3.2 Installation de Spark<br />\n&emsp;3.3 Installation des packages<br />\n&emsp;3.4 Import des librairies<br />\n&emsp;3.5 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats<br />\n&emsp;3.6 Cr\u00e9ation de la SparkSession<br />\n&emsp;3.7 Traitement des donn\u00e9es<br />\n&emsp;&emsp;3.7.1 Chargement des donn\u00e9es<br />\n&emsp;&emsp;3.7.2 Pr\u00e9paration du mod\u00e8le<br />\n&emsp;&emsp;3.7.3 D\u00e9finition du processus de chargement des images et application <br />\n&emsp;&emsp;&emsp;&emsp;&emsp;de leur featurisation \u00e0 travers l'utilisation de pandas UDF<br />\n&emsp;&emsp;3.7.4 Ex\u00e9cution des actions d'extractions de features<br />\n&emsp;3.8 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat<br />\n**4. D\u00e9ploiement de la solution sur le cloud**<br />\n&emsp;4.1 Choix du prestataire cloud : AWS<br />\n&emsp;4.2 Choix de la solution technique : EMR<br />\n&emsp;4.3 Choix de la solution de stockage des donn\u00e9es : Amazon S3<br />\n&emsp;4.4 Configuration de l'environnement de travail<br />\n&emsp;4.5 Upload de nos donn\u00e9es sur S3<br />\n&emsp;4.6 Configuration du serveur EMR<br />\n&emsp;&emsp;4.6.1 \u00c9tape 1 : Logiciels et \u00e9tapes<br />\n&emsp;&emsp;&emsp;4.6.1.1 Configuration des logiciels<br />\n&emsp;&emsp;&emsp;4.6.1.2 Modifier les param\u00e8tres du logiciel<br />\n&emsp;&emsp;4.6.2 \u00c9tape 2 : Mat\u00e9riel<br />\n&emsp;&emsp;4.6.3 \u00c9tape 3 : Param\u00e8tres de cluster g\u00e9n\u00e9raux<br />\n&emsp;&emsp;&emsp;4.6.3.1 Options g\u00e9n\u00e9rales<br />\n&emsp;&emsp;&emsp;4.6.3.2 Actions d'amor\u00e7age<br />\n&emsp;&emsp;4.6.4 \u00c9tape 4 : S\u00e9curit\u00e9<br />\n&emsp;&emsp;&emsp;4.6.4.1 Options de s\u00e9curit\u00e9<br />\n&emsp;4.7 Instanciation du serveur<br />\n&emsp;4.8 Cr\u00e9ation du tunnel SSH \u00e0 l'instance EC2 (Ma\u00eetre)<br />\n&emsp;&emsp;4.8.1 Cr\u00e9ation des autorisations sur les connexions entrantes<br />\n&emsp;&emsp;4.8.2 Cr\u00e9ation du tunnel ssh vers le Driver<br />\n&emsp;&emsp;4.8.3 Configuration de FoxyProxy<br />\n&emsp;&emsp;4.8.4 Acc\u00e8s aux applications du serveur EMR via le tunnel ssh<br />\n&emsp;4.9 Connexion au notebook JupyterHub<br />\n&emsp;4.10 Ex\u00e9cution du code<br />\n&emsp;&emsp;4.10.1 D\u00e9marrage de la session Spark<br />\n&emsp;&emsp;4.10.2 Installation des packages<br />\n&emsp;&emsp;4.10.3 Import des librairies<br />\n&emsp;&emsp;4.10.4 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats<br />\n&emsp;&emsp;4.10.5 Traitement des donn\u00e9es<br />\n&emsp;&emsp;&emsp;4.10.5.1 Chargement des donn\u00e9es<br />\n&emsp;&emsp;&emsp;4.10.5.2 Pr\u00e9paration du mod\u00e8le<br />\n&emsp;&emsp;&emsp;4.10.5.3 D\u00e9finition du processus de chargement des images<br />\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;et application de leur featurisation \u00e0 travers l'utilisation de pandas UDF<br />\n&emsp;&emsp;&emsp;4.10.5.4 Ex\u00e9cutions des actions d'extractions de features<br />\n&emsp;&emsp;4.10.6 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat<br />\n&emsp;4.11 Suivi de l'avancement des t\u00e2ches avec le Serveur d'Historique Spark<br />\n&emsp;4.12 R\u00e9siliation de l'instance EMR<br />\n&emsp;4.13 Cloner le serveur EMR (si besoin)<br />\n&emsp;4.14 Arborescence du serveur S3 \u00e0 la fin du projet<br />\n**5. Conclusion**"}, {"metadata": {}, "id": "ec2cee08", "cell_type": "markdown", "source": "# 1. Pr\u00e9ambule\n\n## 1.1 Probl\u00e9matique\n\nLa tr\u00e8s jeune start-up de l'AgriTech, nomm\u00e9e \"**Fruits**!\", <br />\ncherche \u00e0 proposer des solutions innovantes pour la r\u00e9colte des fruits.\n\nLa volont\u00e9 de l\u2019entreprise est de pr\u00e9server la biodiversit\u00e9 des fruits <br />\nen permettant des traitements sp\u00e9cifiques pour chaque esp\u00e8ce de fruits <br />\nen d\u00e9veloppant des robots cueilleurs intelligents.\n\nLa start-up souhaite dans un premier temps se faire conna\u00eetre en mettant <br />\n\u00e0 disposition du grand public une application mobile qui permettrait aux <br />\nutilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n\nPour la start-up, cette application permettrait de sensibiliser le grand public <br /> \n\u00e0 la biodiversit\u00e9 des fruits et de mettre en place une premi\u00e8re version du moteur <br />\nde classification des images de fruits.\n\nDe plus, le d\u00e9veloppement de l\u2019application mobile permettra de construire <br />\nune premi\u00e8re version de l'architecture **Big Data** n\u00e9cessaire.\n\n## 1.2 Objectifs dans ce projet\n\n1. D\u00e9velopper une premi\u00e8re cha\u00eene de traitement des donn\u00e9es qui <br />\n   comprendra le **preprocessing** et une \u00e9tape de **r\u00e9duction de dimension**.\n2. Tenir compte du fait que <u>le volume de donn\u00e9es va augmenter <br />\n   tr\u00e8s rapidement</u> apr\u00e8s la livraison de ce projet, ce qui implique de:\n - D\u00e9ployer le traitement des donn\u00e9es dans un environnement **Big Data**\n - D\u00e9velopper les scripts en **pyspark** pour effectuer du **calcul distribu\u00e9**"}, {"metadata": {}, "id": "6b95e6ce", "cell_type": "markdown", "source": "## 1.3 D\u00e9roulement des \u00e9tapes du projet\n\nLe projet va \u00eatre r\u00e9alis\u00e9 en 2 temps, dans deux environnements diff\u00e9rents. <br />\nNous allons dans un premier temps d\u00e9velopper et ex\u00e9cuter notre code en local, <br />\nen travaillant sur un nombre limit\u00e9 d'images \u00e0 traiter.\n\nUne fois les choix techniques valid\u00e9s, nous d\u00e9ploierons notre solution <br />\ndans un environnement Big Data en mode distribu\u00e9.\n\n<u>Pour cette raison, ce projet sera divis\u00e9 en 3 parties</u>:\n1. Liste des choix techniques g\u00e9n\u00e9raux retenus\n2. D\u00e9ploiement de la solution en local\n3. D\u00e9ploiement de la solution dans le cloud"}, {"metadata": {}, "id": "f5b34029", "cell_type": "markdown", "source": "# 2. Choix techniques g\u00e9n\u00e9raux retenus"}, {"metadata": {}, "id": "32baf092", "cell_type": "markdown", "source": "## 2.1 Calcul distribu\u00e9\n\nL\u2019\u00e9nonc\u00e9 du projet nous impose de d\u00e9velopper des scripts en **pyspark** <br />\nafin de <u>prendre en compte l\u2019augmentation tr\u00e8s rapide du volume <br />\nde donn\u00e9 apr\u00e8s la livraison du projet</u>.\n\nPour comprendre rapidement et simplement ce qu\u2019est **pyspark** <br />\net son principe de fonctionnement, nous vous conseillons de lire <br />\ncet article : [PySpark : Tout savoir sur la librairie Python](https://datascientest.com/pyspark)\n\n<u>Le d\u00e9but de l\u2019article nous dit ceci </u>:<br />\n\u00ab *Lorsque l\u2019on parle de traitement de bases de donn\u00e9es sur python, <br />\non pense imm\u00e9diatement \u00e0 la librairie pandas. Cependant, lorsqu\u2019on a <br />\naffaire \u00e0 des bases de donn\u00e9es trop massives, les calculs deviennent trop lents.<br />\nHeureusement, il existe une autre librairie python, assez proche <br />\nde pandas, qui permet de traiter des tr\u00e8s grandes quantit\u00e9s de donn\u00e9es : PySpark.<br />\nApache Spark est un framework open-source d\u00e9velopp\u00e9 par l\u2019AMPLab <br />\nde UC Berkeley permettant de traiter des bases de donn\u00e9es massives <br />\nen utilisant le calcul distribu\u00e9, technique qui consiste \u00e0 exploiter <br />\nplusieurs unit\u00e9s de calcul r\u00e9parties en clusters au profit d\u2019un seul <br />\nprojet afin de diviser le temps d\u2019ex\u00e9cution d\u2019une requ\u00eate.<br />\nSpark a \u00e9t\u00e9 d\u00e9velopp\u00e9 en Scala et est au meilleur de ses capacit\u00e9s <br />\ndans son langage natif. Cependant, la librairie PySpark propose de <br />\nl\u2019utiliser avec le langage Python, en gardant des performances <br />\nsimilaires \u00e0 des impl\u00e9mentations en Scala.<br />\nPyspark est donc une bonne alternative \u00e0 la librairie pandas lorsqu\u2019on <br />\ncherche \u00e0 traiter des jeux de donn\u00e9es trop volumineux qui entra\u00eenent <br />\ndes calculs trop chronophages.* \u00bb\n\nComme nous le constatons, **pySpark** est un moyen de communiquer <br />\navec **Spark** via le langage **Python**.<br />\n**Spark**, quant \u00e0 lui, est un outil qui permet de g\u00e9rer et de coordonner <br />\nl'ex\u00e9cution de t\u00e2ches sur des donn\u00e9es \u00e0 travers un groupe d'ordinateurs. <br />\n<u>Spark (ou Apache Spark) est un framework open source de calcul distribu\u00e9 <br />\nin-memory pour le traitement et l'analyse de donn\u00e9es massives</u>.\n\nUn autre [article tr\u00e8s int\u00e9ressant et beaucoup plus complet pour <br />\ncomprendre le **fonctionnement de Spark**](https://www.veonum.com/apache-spark-pour-les-nuls/), ainsi que le r\u00f4le <br />\ndes **Spark Session** que nous utiliserons dans ce projet.\n\n<u>Voici \u00e9galement un extrait</u>:\n\n*Les applications Spark se composent d\u2019un pilote (\u00ab\u202fdriver process\u202f\u00bb) <br />\net de plusieurs ex\u00e9cuteurs (\u00ab\u202fexecutor processes\u202f\u00bb). Il peut \u00eatre configur\u00e9 <br />\npour \u00eatre lui-m\u00eame l\u2019ex\u00e9cuteur (local mode) ou en utiliser autant que <br />\nn\u00e9cessaire pour traiter l\u2019application, Spark prenant en charge la mise <br />\n\u00e0 l\u2019\u00e9chelle automatique par une configuration d\u2019un nombre minimum <br />\net maximum d\u2019ex\u00e9cuteurs.*\n\n![Sch\u00e9ma de Spark](img/spark-schema.png)\n\n*Le driver (parfois appel\u00e9 \u00ab\u202fSpark Session\u202f\u00bb) distribue et planifie <br />\nles t\u00e2ches entre les diff\u00e9rents ex\u00e9cuteurs qui les ex\u00e9cutent et permettent <br />\nun traitement r\u00e9parti. Il est le responsable de l\u2019ex\u00e9cution du code <br />\nsur les diff\u00e9rentes machines.\n\nChaque ex\u00e9cuteur est un processus Java Virtual Machine (JVM) distinct <br />\ndont il est possible de configurer le nombre de CPU et la quantit\u00e9 de <br />\nm\u00e9moire qui lui est allou\u00e9. <br />\nUne seule t\u00e2che peut traiter un fractionnement de donn\u00e9es \u00e0 la fois.*\n\nDans les deux environnements (Local et Cloud) nous utiliserons donc **Spark** <br />\net nous l\u2019exploiterons \u00e0 travers des scripts python gr\u00e2ce \u00e0 **PySpark**.\n\nDans la <u>version locale</u> de notre script nous **simulerons <br />\nle calcul distribu\u00e9** afin de valider que notre solution fonctionne.<br />\nDans la <u>version cloud</u> nous **r\u00e9aliserons les op\u00e9rations sur un cluster de machine**."}, {"metadata": {}, "id": "5364c9f9", "cell_type": "markdown", "source": "## 2.2 Transfert Learning\n\nL'\u00e9nonc\u00e9 du projet nous demande \u00e9galement de <br />\nr\u00e9aliser une premi\u00e8re cha\u00eene de traitement <br />\ndes donn\u00e9es qui comprendra le preprocessing et <br />\nune \u00e9tape de r\u00e9duction de dimension.\n\nIl est \u00e9galement pr\u00e9cis\u00e9 qu'il n'est pas n\u00e9cessaire <br />\nd'entra\u00eener un mod\u00e8le pour le moment.\n\nNous d\u00e9cidons de partir sur une solution de **transfert learning**.\n\nSimplement, le **transfert learning** consiste <br />\n\u00e0 utiliser la connaissance d\u00e9j\u00e0 acquise <br />\npar un mod\u00e8le entra\u00een\u00e9 (ici **MobileNetV2**) pour <br />\nl'adapter \u00e0 notre probl\u00e9matique.\n\nNous allons fournir au mod\u00e8le nos images, et nous allons <br />\n<u>r\u00e9cup\u00e9rer l'avant derni\u00e8re couche</u> du mod\u00e8le.<br />\nEn effet la derni\u00e8re couche de mod\u00e8le est une couche softmax <br />\nqui permet la classification des images ce que nous ne <br />\nsouhaitons pas dans ce projet.\n\nL'avant derni\u00e8re couche correspond \u00e0 un **vecteur <br />\nr\u00e9duit** de dimension (1,1,1280).\n\nCela permettra de r\u00e9aliser une premi\u00e8re version du moteur <br />\npour la classification des images des fruits.\n\n**MobileNetV2** a \u00e9t\u00e9 retenu pour sa <u>rapidit\u00e9 d'ex\u00e9cution</u>, <br />\nparticuli\u00e8rement adapt\u00e9e pour le traitement d'un gros volume <br />\nde donn\u00e9es ainsi que la <u>faible dimensionnalit\u00e9 du vecteur <br />\nde caract\u00e9ristique en sortie</u> (1,1,1280)"}, {"metadata": {}, "id": "1e89a2da", "cell_type": "markdown", "source": "# 3. D\u00e9ploiement de la solution en local\n\n\n## 3.1 Environnement de travail\n\nPour des raisons de simplicit\u00e9, nous d\u00e9veloppons dans un environnement <br />\nLinux Unbuntu (ex\u00e9cut\u00e9 depuis une machine Windows dans une machine virtuelle)\n* Pour installer une machine virtuelle :  https://www.malekal.com/meilleurs-logiciels-de-machine-virtuelle-gratuits-ou-payants/\n\n## 3.2 Installation de Spark\n\n[La premi\u00e8re \u00e9tape consiste \u00e0 installer Spark ](https://computingforgeeks.com/how-to-install-apache-spark-on-ubuntu-debian/)\n\n## 3.3 Installation des packages\n\n<u>On installe ensuite \u00e0 l'aide de la commande **pip** <br />\nles packages qui nous seront n\u00e9cessaires</u> :"}, {"metadata": {"scrolled": true, "trusted": false}, "id": "456be0a9-abe6-4240-901a-7a3164976db7", "cell_type": "code", "source": "import pyspark\nprint(pyspark.__version__)\n", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "An error was encountered:\nInvalid status code '404' from http://ip-172-31-45-20.eu-west-3.compute.internal:8998/sessions/14 with error payload: {\"msg\":\"Session '14' not found.\"}\n", "name": "stderr"}]}, {"metadata": {}, "id": "33a43845", "cell_type": "markdown", "source": "## 3.4 Import des librairies"}, {"metadata": {"trusted": false}, "id": "40617371-0bb4-4c97-8d1d-1d832d9ac972", "cell_type": "code", "source": "import os\n\nPATH = os.getcwd()                   # r\u00e9pertoire courant du notebook\nPATH_Data = os.path.join(PATH, 'data', 'Test1')   # chemin vers ton dossier de donn\u00e9es\nPATH_Result = os.path.join(PATH, 'data', 'Results')  # chemin pour enregistrer les r\u00e9sultats\n\nprint('PATH:        ', PATH)\nprint('PATH_Data:   ', PATH_Data)\nprint('PATH_Result: ', PATH_Result)\n", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "An error was encountered:\nInvalid status code '404' from http://ip-172-31-45-20.eu-west-3.compute.internal:8998/sessions/14 with error payload: {\"msg\":\"Session '14' not found.\"}\n", "name": "stderr"}]}, {"metadata": {"trusted": false}, "id": "b7d1ece9-11dc-44ba-a4ad-3da80fb64145", "cell_type": "code", "source": "print(os.path.exists(PATH_Data))  \nprint(os.listdir(PATH_Data))      # liste les fichiers\n", "execution_count": 23, "outputs": [{"name": "stdout", "output_type": "stream", "text": "True\n['Corn', 'Carambula', 'Banana Red', 'Apple Red 2', 'Apple Red Yellow 2', 'Avocado ripe', 'Apple Golden 1', 'Cucumber Ripe 2', 'Cherry Wax Yellow', 'Banana', 'Cantaloupe 2', 'Cantaloupe 1', '.ipynb_checkpoints', 'Apple Red 3', 'Cherry Wax Black', 'Chestnut', 'Apple Granny Smith', 'Cherry 2', 'Apple Braeburn', 'Cherry Rainier', 'Apple Golden 3', 'Apple Red Delicious', 'Apple Golden 2', 'Clementine', 'Apple Red 1', 'Cauliflower', 'Cocos', 'Cherry 1', 'Cucumber Ripe', 'Beetroot', 'Corn Husk', 'Apple Pink Lady', 'Cherry Wax Red', 'Apple Crimson Snow', 'Apricot', 'Apple Red Yellow 1', 'Cactus fruit', 'Avocado', 'Blueberry']\n"}]}, {"metadata": {"trusted": false}, "id": "4b93d5d1-5524-48c7-8f3c-17f3c27e2b7b", "cell_type": "code", "source": "ls /home/djamel/Module_11/Notebook/data/Test1", "execution_count": 24, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u001b[0m\u001b[34;42m'Apple Braeburn'\u001b[0m/        \u001b[01;34mApricot\u001b[0m/        \u001b[01;34m'Cherry 2'\u001b[0m/\n\u001b[34;42m'Apple Crimson Snow'\u001b[0m/    \u001b[01;34mAvocado\u001b[0m/        \u001b[01;34m'Cherry Rainier'\u001b[0m/\n\u001b[34;42m'Apple Golden 1'\u001b[0m/       \u001b[01;34m'Avocado ripe'\u001b[0m/  \u001b[01;34m'Cherry Wax Black'\u001b[0m/\n\u001b[34;42m'Apple Golden 2'\u001b[0m/        \u001b[01;34mBanana\u001b[0m/         \u001b[01;34m'Cherry Wax Red'\u001b[0m/\n\u001b[34;42m'Apple Golden 3'\u001b[0m/       \u001b[01;34m'Banana Red'\u001b[0m/    \u001b[01;34m'Cherry Wax Yellow'\u001b[0m/\n\u001b[34;42m'Apple Granny Smith'\u001b[0m/    \u001b[01;34mBeetroot\u001b[0m/        \u001b[01;34mChestnut\u001b[0m/\n\u001b[34;42m'Apple Pink Lady'\u001b[0m/       \u001b[01;34mBlueberry\u001b[0m/       \u001b[01;34mClementine\u001b[0m/\n\u001b[34;42m'Apple Red 1'\u001b[0m/          \u001b[01;34m'Cactus fruit'\u001b[0m/   \u001b[01;34mCocos\u001b[0m/\n\u001b[34;42m'Apple Red 2'\u001b[0m/          \u001b[01;34m'Cantaloupe 1'\u001b[0m/   \u001b[01;34mCorn\u001b[0m/\n\u001b[34;42m'Apple Red 3'\u001b[0m/          \u001b[01;34m'Cantaloupe 2'\u001b[0m/  \u001b[01;34m'Corn Husk'\u001b[0m/\n\u001b[34;42m'Apple Red Delicious'\u001b[0m/   \u001b[01;34mCarambula\u001b[0m/      \u001b[01;34m'Cucumber Ripe'\u001b[0m/\n\u001b[34;42m'Apple Red Yellow 1'\u001b[0m/    \u001b[01;34mCauliflower\u001b[0m/    \u001b[01;34m'Cucumber Ripe 2'\u001b[0m/\n\u001b[34;42m'Apple Red Yellow 2'\u001b[0m/   \u001b[01;34m'Cherry 1'\u001b[0m/\n"}]}, {"metadata": {"trusted": false}, "id": "2ba60f77-068d-49e4-8d38-52e9c52b21d6", "cell_type": "code", "source": "PATH_Data = \"/home/djamel/Module_11/data/Test1\"\nPATH_Result = \"file:/home/djamel/Module_11/Notebook/data/Results\"\n", "execution_count": 25, "outputs": []}, {"metadata": {"trusted": false}, "id": "8a5dacff-627f-473c-8d4c-e960d58f60f0", "cell_type": "code", "source": "import os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n\nfrom pyspark.sql import SparkSession\n\nspark = (\n    SparkSession.builder\n    .appName(\"SparkJava8Fix\")\n    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n    .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"true\")\n    .getOrCreate()\n)\n\nprint(\"\u2705 Spark lanc\u00e9 avec Java 8\")\n", "execution_count": 26, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u2705 Spark lanc\u00e9 avec Java 8\n"}, {"name": "stderr", "output_type": "stream", "text": "25/10/23 23:01:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}]}, {"metadata": {"trusted": false}, "id": "e39e06f3-c0d9-4db0-9bfc-25787a056e96", "cell_type": "code", "source": "print(\"Spark version:\", spark.version)\nspark.range(5).show()\n", "execution_count": 27, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Spark version: 3.5.2\n+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+\n\n"}]}, {"metadata": {"trusted": false}, "id": "a5c0c74f", "cell_type": "code", "source": "import pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport io\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras import Model\nfrom pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\nfrom pyspark.sql import SparkSession", "execution_count": 28, "outputs": []}, {"metadata": {}, "id": "661ff67c", "cell_type": "markdown", "source": "## 3.5 D\u00e9finition des PATH pour charger les images <br /> et enregistrer les r\u00e9sultats\n\nDans cette version locale nous partons du principe que les donn\u00e9es <br />\nsont stock\u00e9es dans le m\u00eame r\u00e9pertoire que le notebook.<br />\nNous n'utilisons qu'un extrait de **5928 images** \u00e0 traiter dans cette <br />\npremi\u00e8re version en local.<br />\nL'extrait des images \u00e0 charger est stock\u00e9e dans le dossier **Test1**.<br />\nNous enregistrerons le r\u00e9sultat de notre traitement <br />\ndans le dossier \"**Results_Local**\""}, {"metadata": {"trusted": false}, "id": "cde0aa67", "cell_type": "code", "source": "import os\n\n# Chemins Linux et Windows correctement configur\u00e9s pour WSL\nPATH_Data = \"/home/djamel/Module_11/data/Test1/\"\nPATH_Result = \"file:/home/djamel/Module_11/data/Results\"\n\n\n# Cr\u00e9e les dossiers si ils n'existent pas\nos.makedirs(PATH_Data, exist_ok=True)\nos.makedirs(PATH_Result, exist_ok=True)\n\nprint(\"Dossiers cr\u00e9\u00e9s ou d\u00e9j\u00e0 existants :\")\nprint(PATH_Data)\nprint(PATH_Result)\n", "execution_count": 29, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Dossiers cr\u00e9\u00e9s ou d\u00e9j\u00e0 existants :\n/home/djamel/Module_11/data/Test1/\nfile:/home/djamel/Module_11/data/Results\n"}]}, {"metadata": {}, "id": "da5e637a", "cell_type": "markdown", "source": "## 3.6 Cr\u00e9ation de la SparkSession\n\nL\u2019application Spark est contr\u00f4l\u00e9e gr\u00e2ce \u00e0 un processus de pilotage (driver process) appel\u00e9 **SparkSession**. <br />\n<u>Une instance de **SparkSession** est la fa\u00e7on dont Spark ex\u00e9cute les fonctions d\u00e9finies par l\u2019utilisateur <br />\ndans l\u2019ensemble du cluster</u>. <u>Une SparkSession correspond toujours \u00e0 une application Spark</u>.\n\n<u>Ici nous cr\u00e9ons une session spark en sp\u00e9cifiant dans l'ordre</u> :\n 1. un **nom pour l'application**, qui sera affich\u00e9e dans l'interface utilisateur Web Spark \"**P8**\"\n 2. que l'application doit s'ex\u00e9cuter **localement**. <br />\n   Nous ne d\u00e9finissons pas le nombre de c\u0153urs \u00e0 utiliser (comme .master('local[4]) pour 4 c\u0153urs \u00e0 utiliser), <br />\n   nous utiliserons donc tous les c\u0153urs disponibles dans notre processeur.<br />\n 3. une option de configuration suppl\u00e9mentaire permettant d'utiliser le **format \"parquet\"** <br />\n   que nous utiliserons pour enregistrer et charger le r\u00e9sultat de notre travail.\n 4. vouloir **obtenir une session spark** existante ou si aucune n'existe, en cr\u00e9er une nouvelle"}, {"metadata": {"trusted": false}, "id": "efc9b007-202d-4eec-b2a8-337599de3378", "cell_type": "code", "source": "spark = (SparkSession\n             .builder\n             .appName('P8')\n             .master('local')\n             .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n             .getOrCreate()\n)", "execution_count": 30, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/10/23 23:01:37 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}]}, {"metadata": {"trusted": false}, "id": "db4e30a5-5b26-4856-8b94-93644383a25c", "cell_type": "code", "source": "sc = spark.sparkContext", "execution_count": 31, "outputs": []}, {"metadata": {"trusted": false}, "id": "b7bea157", "cell_type": "code", "source": "spark", "execution_count": 32, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>SparkJava8Fix</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7ce7b42774f0>"}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "id": "5c8b53ac", "cell_type": "markdown", "source": "<u>Nous cr\u00e9ons \u00e9galement la variable \"**sc**\" qui est un **SparkContext** issue de la variable **spark**</u> :"}, {"metadata": {"trusted": false}, "id": "14aeccb1", "cell_type": "code", "source": "sc = spark.sparkContext", "execution_count": 33, "outputs": []}, {"metadata": {}, "id": "5a086010", "cell_type": "markdown", "source": "<u>Affichage des informations de Spark en cours d'execution</u> :"}, {"metadata": {"trusted": false}, "id": "e97bf13b", "cell_type": "code", "source": "spark", "execution_count": 34, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.255.255.254:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>SparkJava8Fix</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7ce7b42774f0>"}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "id": "195a88b0", "cell_type": "markdown", "source": "## 3.7 Traitement des donn\u00e9es\n\n<u>Dans la suite de notre flux de travail, <br />\nnous allons successivement</u> :\n1. Pr\u00e9parer nos donn\u00e9es\n    1. Importer les images dans un dataframe **pandas UDF**\n    2. Associer aux images leur **label**\n    3. Pr\u00e9processer en **redimensionnant nos images pour <br />\n       qu'elles soient compatibles avec notre mod\u00e8le**\n2. Pr\u00e9parer notre mod\u00e8le\n    1. Importer le mod\u00e8le **MobileNetV2**\n    2. Cr\u00e9er un **nouveau mod\u00e8le** d\u00e9pourvu de la derni\u00e8re couche de MobileNetV2\n3. D\u00e9finir le processus de chargement des images et l'application <br />\n   de leur featurisation \u00e0 travers l'utilisation de pandas UDF\n3. Ex\u00e9cuter les actions d'extraction de features\n4. Enregistrer le r\u00e9sultat de nos actions\n5. Tester le bon fonctionnement en chargeant les donn\u00e9es enregistr\u00e9es\n\n\n"}, {"metadata": {}, "id": "386fe0bc", "cell_type": "markdown", "source": "### 3.7.1 Chargement des donn\u00e9es\n\nLes images sont charg\u00e9es au format binaire, ce qui offre, <br />\nplus de souplesse dans la fa\u00e7on de pr\u00e9traiter les images.\n\nAvant de charger les images, nous sp\u00e9cifions que nous voulons charger <br />\nuniquement les fichiers dont l'extension est **jpg**.\n\nNous indiquons \u00e9galement de charger tous les objets possibles contenus <br />\ndans les sous-dossiers du dossier communiqu\u00e9."}, {"metadata": {"trusted": false}, "id": "5a1f7b09-3416-4714-aa88-73f4fbcb4403", "cell_type": "code", "source": "spark.conf.set(\"spark.hadoop.io.nativeio.native\", \"false\")\nspark.conf.set(\"spark.hadoop.fs.file.impl.disable.cache\", \"true\")\n", "execution_count": 35, "outputs": []}, {"metadata": {"trusted": false}, "id": "7624a410-23ea-4fba-8c66-4b18b78aedb5", "cell_type": "code", "source": "images = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(PATH_Data)", "execution_count": 36, "outputs": []}, {"metadata": {"trusted": false}, "id": "093ca5c7-399f-4fee-b519-40e886ecee7c", "cell_type": "code", "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import split, element_at, input_file_name\n\n# Cr\u00e9e la session Spark\nspark = SparkSession.builder \\\n    .appName(\"ImagesTest\") \\\n    .getOrCreate()\n\n# Chemin racine des images\nimage_root_path = \"/home/djamel/Module_11/Notebook/data/Test1/*/*\"\n\n# Lis toutes les images des sous-dossiers\nimages = spark.read.format(\"binaryFile\") \\\n    .option(\"pathGlobFilter\", \"*.jpg\") \\\n    .load(image_root_path)\n\n# Ajoute la colonne 'label' \u00e0 partir du nom du dossier parent\nimages = images.withColumn(\"label\", element_at(split(input_file_name(), \"/\"), -2))\n\n# V\u00e9rifie\nimages.printSchema()\nimages.select(\"path\", \"label\").show(10, False)\n", "execution_count": 37, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/10/23 23:01:40 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n                                                                                "}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\n+---------------------------------------------------------------------------+---------------+\n|path                                                                       |label          |\n+---------------------------------------------------------------------------+---------------+\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cucumber Ripe/r_165_100.jpg|Cucumber%20Ripe|\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cucumber Ripe/r_163_100.jpg|Cucumber%20Ripe|\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cucumber Ripe/r_164_100.jpg|Cucumber%20Ripe|\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cauliflower/r_183_100.jpg  |Cauliflower    |\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cauliflower/r_173_100.jpg  |Cauliflower    |\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cauliflower/r_181_100.jpg  |Cauliflower    |\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cauliflower/r_180_100.jpg  |Cauliflower    |\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cauliflower/r_185_100.jpg  |Cauliflower    |\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cauliflower/r_184_100.jpg  |Cauliflower    |\n|file:/home/djamel/Module_11/Notebook/data/Test1/Cucumber Ripe/r_166_100.jpg|Cucumber%20Ripe|\n+---------------------------------------------------------------------------+---------------+\nonly showing top 10 rows\n\n"}]}, {"metadata": {}, "id": "645faeaf", "cell_type": "markdown", "source": "<u>Affichage des 5 premi\u00e8res images contenant</u> :\n - le path de l'image\n - la date et heure de sa derni\u00e8re modification\n - sa longueur\n - son contenu encod\u00e9 en valeur hexad\u00e9cimal"}, {"metadata": {}, "id": "863981e5", "cell_type": "markdown", "source": "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n    une colonne contenant les **labels** de chaque image</u> :"}, {"metadata": {}, "id": "83d47705", "cell_type": "markdown", "source": "### 3.7.2 Pr\u00e9paration du mod\u00e8le\n\nJe vais utiliser la technique du **transfert learning** pour extraire les features des images.<br />\nJ'ai choisi d'utiliser le mod\u00e8le **MobileNetV2** pour sa rapidit\u00e9 d'ex\u00e9cution compar\u00e9e <br />\n\u00e0 d'autres mod\u00e8les comme *VGG16* par exemple.\n\nPour en savoir plus sur la conception et le fonctionnement de MobileNetV2, <br />\nje vous invite \u00e0 lire [cet article](https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c).\n\n<u>Voici le sch\u00e9ma de son architecture globale</u> : \n\n![Architecture de MobileNetV2](img/mobilenetv2_architecture.png)\n\nIl existe une derni\u00e8re couche qui sert \u00e0 classer les images <br />\nselon 1000 cat\u00e9gories que nous ne voulons pas utiliser.<br />\nL'id\u00e9e dans ce projet est de r\u00e9cup\u00e9rer le **vecteur de caract\u00e9ristiques <br />\nde dimensions (1,1,1280)** qui servira, plus tard, au travers d'un moteur <br />\nde classification \u00e0 reconnaitre les diff\u00e9rents fruits du jeu de donn\u00e9es.\n\nComme d'autres mod\u00e8les similaires, **MobileNetV2**, lorsqu'on l'utilise <br />\nen incluant toutes ses couches, attend obligatoirement des images <br />\nde dimension (224,224,3). Nos images \u00e9tant toutes de dimension (100,100,3), <br />\nnous devrons simplement les **redimensionner** avant de les confier au mod\u00e8le.\n\n<u>Dans l'odre</u> :\n 1. Nous chargeons le mod\u00e8le **MobileNetV2** avec les poids **pr\u00e9calcul\u00e9s** <br />\n    issus d'**imagenet** et en sp\u00e9cifiant le format de nos images en entr\u00e9e\n 2. Nous cr\u00e9ons un nouveau mod\u00e8le avec:\n  - <u>en entr\u00e9e</u> : l'entr\u00e9e du mod\u00e8le MobileNetV2\n  - <u>en sortie</u> : l'avant derni\u00e8re couche du mod\u00e8le MobileNetV2"}, {"metadata": {"trusted": false}, "id": "9cdd9bdf", "cell_type": "code", "source": "model = MobileNetV2(weights='imagenet',\n                    include_top=True,\n                    input_shape=(224, 224, 3))", "execution_count": 38, "outputs": [{"name": "stderr", "output_type": "stream", "text": "2025-10-23 23:02:12.232015: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"}]}, {"metadata": {"trusted": false}, "id": "99d6b68d", "cell_type": "code", "source": "new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)", "execution_count": 39, "outputs": []}, {"metadata": {}, "id": "7b197379", "cell_type": "markdown", "source": "Affichage du r\u00e9sum\u00e9 de notre nouveau mod\u00e8le o\u00f9 nous constatons <br />\nque <u>nous r\u00e9cup\u00e9rons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"}, {"metadata": {"trusted": false}, "id": "e8207725", "cell_type": "code", "source": "new_model.summary()", "execution_count": 40, "outputs": [{"data": {"text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n", "text/plain": "\u001b[1mModel: \"functional\"\u001b[0m\n"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503<span style=\"font-weight: bold\"> Layer (type)        </span>\u2503<span style=\"font-weight: bold\"> Output Shape      </span>\u2503<span style=\"font-weight: bold\">    Param # </span>\u2503<span style=\"font-weight: bold\"> Connected to      </span>\u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 -                 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> \u2502 input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bn_Conv1            \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502 Conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 bn_Conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> \u2502 Conv1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 block_1_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_1_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_pad         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>,  \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_1_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> \u2502 block_1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> \u2502 block_1_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_1_project_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> \u2502 block_2_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_2_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> \u2502 block_2_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502         <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> \u2502 block_2_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_1_project_\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               \u2502            \u2502 block_2_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> \u2502 block_3_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_3_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_pad         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_3_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> \u2502 block_3_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502 block_3_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> \u2502 block_3_project_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> \u2502 block_4_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_4_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> \u2502 block_4_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502 block_4_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_3_project_\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502 block_4_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> \u2502 block_4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> \u2502 block_5_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_5_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> \u2502 block_5_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \u2502 block_5_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               \u2502            \u2502 block_5_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> \u2502 block_5_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> \u2502 block_6_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_6_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_pad         \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_6_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> \u2502 block_6_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 block_6_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_6_project_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_7_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_7_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_7_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 block_7_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_6_project_\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502 block_7_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_7_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_8_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_8_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_8_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 block_8_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_7_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502 block_8_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand      \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_8_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_BN   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_9_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_relu \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_9_expand_B\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_9_expand_r\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \u2502 block_9_project[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)   \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_8_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               \u2502            \u2502 block_9_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> \u2502 block_9_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_10_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_10_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,456</span> \u2502 block_10_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 block_10_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> \u2502 block_10_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_11_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_11_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> \u2502 block_11_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 block_11_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_10_project\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502 block_11_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> \u2502 block_11_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_12_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_12_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> \u2502 block_12_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> \u2502 block_12_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_11_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               \u2502            \u2502 block_12_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> \u2502 block_12_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_13_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_13_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_pad        \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_13_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> \u2502 block_13_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502     <span style=\"color: #00af00; text-decoration-color: #00af00\">92,160</span> \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \u2502 block_13_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,600</span> \u2502 block_13_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> \u2502 block_14_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_14_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,640</span> \u2502 block_14_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,600</span> \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \u2502 block_14_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_13_project\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_14_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,600</span> \u2502 block_14_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> \u2502 block_15_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_15_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,640</span> \u2502 block_15_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,600</span> \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \u2502 block_15_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_14_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_15_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,600</span> \u2502 block_15_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_BN  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> \u2502 block_16_expand[<span style=\"color: #00af00; text-decoration-color: #00af00\">\u2026</span> \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_re\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_16_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise  \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,640</span> \u2502 block_16_expand_\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>) \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project    \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>) \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">307,200</span> \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project_BN \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>) \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> \u2502 block_16_project\u2026 \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      \u2502    <span style=\"color: #00af00; text-decoration-color: #00af00\">409,600</span> \u2502 block_16_project\u2026 \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1_bn           \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      \u2502      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> \u2502 Conv_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio\u2026</span> \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 out_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 Conv_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \u2502\n\u2502                     \u2502 <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_poo\u2026 \u2502 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      \u2502          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \u2502 out_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \u2502\n\u2502 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool\u2026</span> \u2502                   \u2502            \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre>\n", "text/plain": "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 -                 \u2502\n\u2502 (\u001b[38;5;33mInputLayer\u001b[0m)        \u2502 \u001b[38;5;34m3\u001b[0m)                \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1 (\u001b[38;5;33mConv2D\u001b[0m)      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502        \u001b[38;5;34m864\u001b[0m \u2502 input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bn_Conv1            \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502        \u001b[38;5;34m128\u001b[0m \u2502 Conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv1_relu (\u001b[38;5;33mReLU\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 bn_Conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502        \u001b[38;5;34m288\u001b[0m \u2502 Conv1_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502        \u001b[38;5;34m128\u001b[0m \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_dept\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502        \u001b[38;5;34m512\u001b[0m \u2502 expanded_conv_de\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m16\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 expanded_conv_proj\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502         \u001b[38;5;34m64\u001b[0m \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m16\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 expanded_conv_pr\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502        \u001b[38;5;34m384\u001b[0m \u2502 block_1_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_1_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_pad         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m,  \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_1_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mZeroPadding2D\u001b[0m)     \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502        \u001b[38;5;34m864\u001b[0m \u2502 block_1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502        \u001b[38;5;34m384\u001b[0m \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_1_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m24\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_1_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502         \u001b[38;5;34m96\u001b[0m \u2502 block_1_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m24\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_1_project_\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502        \u001b[38;5;34m576\u001b[0m \u2502 block_2_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_2_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502      \u001b[38;5;34m1,296\u001b[0m \u2502 block_2_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502        \u001b[38;5;34m576\u001b[0m \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_2_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m24\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502         \u001b[38;5;34m96\u001b[0m \u2502 block_2_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m24\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_2_add (\u001b[38;5;33mAdd\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_1_project_\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m24\u001b[0m)               \u2502            \u2502 block_2_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502        \u001b[38;5;34m576\u001b[0m \u2502 block_3_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_3_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_pad         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m, \u001b[38;5;34m57\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_3_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mZeroPadding2D\u001b[0m)     \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m1,296\u001b[0m \u2502 block_3_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m576\u001b[0m \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m144\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m4,608\u001b[0m \u2502 block_3_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_3_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m128\u001b[0m \u2502 block_3_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m6,144\u001b[0m \u2502 block_3_project_\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m768\u001b[0m \u2502 block_4_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_4_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m1,728\u001b[0m \u2502 block_4_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m768\u001b[0m \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m6,144\u001b[0m \u2502 block_4_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m128\u001b[0m \u2502 block_4_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_4_add (\u001b[38;5;33mAdd\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_3_project_\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502 block_4_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m6,144\u001b[0m \u2502 block_4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m768\u001b[0m \u2502 block_5_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_5_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m1,728\u001b[0m \u2502 block_5_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m768\u001b[0m \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m6,144\u001b[0m \u2502 block_5_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m128\u001b[0m \u2502 block_5_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_5_add (\u001b[38;5;33mAdd\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m32\u001b[0m)               \u2502            \u2502 block_5_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502      \u001b[38;5;34m6,144\u001b[0m \u2502 block_5_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502        \u001b[38;5;34m768\u001b[0m \u2502 block_6_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_6_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_pad         \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_6_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mZeroPadding2D\u001b[0m)     \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,728\u001b[0m \u2502 block_6_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m768\u001b[0m \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m192\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m12,288\u001b[0m \u2502 block_6_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_6_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 block_6_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_6_project_\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_7_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_7_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_7_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_7_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 block_7_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_7_add (\u001b[38;5;33mAdd\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_6_project_\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502 block_7_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_7_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_8_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_8_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_8_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_8_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 block_8_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_8_add (\u001b[38;5;33mAdd\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_7_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502 block_8_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand      \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_8_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_BN   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_9_expand[\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_expand_relu \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_9_expand_B\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_9_expand_r\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_depthwise_\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_9_depthwis\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_project_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m256\u001b[0m \u2502 block_9_project[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_9_add (\u001b[38;5;33mAdd\u001b[0m)   \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_8_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m64\u001b[0m)               \u2502            \u2502 block_9_project_\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m24,576\u001b[0m \u2502 block_9_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_10_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_10_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m3,456\u001b[0m \u2502 block_10_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m1,536\u001b[0m \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m384\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m36,864\u001b[0m \u2502 block_10_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_10_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m384\u001b[0m \u2502 block_10_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m55,296\u001b[0m \u2502 block_10_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_11_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_11_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m5,184\u001b[0m \u2502 block_11_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m55,296\u001b[0m \u2502 block_11_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m384\u001b[0m \u2502 block_11_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_11_add (\u001b[38;5;33mAdd\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_10_project\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502 block_11_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m55,296\u001b[0m \u2502 block_11_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_12_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_12_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m5,184\u001b[0m \u2502 block_12_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m55,296\u001b[0m \u2502 block_12_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502        \u001b[38;5;34m384\u001b[0m \u2502 block_12_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_12_add (\u001b[38;5;33mAdd\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_11_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502                     \u2502 \u001b[38;5;34m96\u001b[0m)               \u2502            \u2502 block_12_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502     \u001b[38;5;34m55,296\u001b[0m \u2502 block_12_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_13_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_13_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_pad        \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_13_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mZeroPadding2D\u001b[0m)     \u2502 \u001b[38;5;34m576\u001b[0m)              \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m) \u2502      \u001b[38;5;34m5,184\u001b[0m \u2502 block_13_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m) \u2502      \u001b[38;5;34m2,304\u001b[0m \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502     \u001b[38;5;34m92,160\u001b[0m \u2502 block_13_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_13_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502        \u001b[38;5;34m640\u001b[0m \u2502 block_13_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502    \u001b[38;5;34m153,600\u001b[0m \u2502 block_13_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m3,840\u001b[0m \u2502 block_14_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_14_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m8,640\u001b[0m \u2502 block_14_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m3,840\u001b[0m \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502    \u001b[38;5;34m153,600\u001b[0m \u2502 block_14_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502        \u001b[38;5;34m640\u001b[0m \u2502 block_14_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_14_add (\u001b[38;5;33mAdd\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_13_project\u2026 \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_14_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502    \u001b[38;5;34m153,600\u001b[0m \u2502 block_14_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m3,840\u001b[0m \u2502 block_15_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_15_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m8,640\u001b[0m \u2502 block_15_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m3,840\u001b[0m \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502    \u001b[38;5;34m153,600\u001b[0m \u2502 block_15_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502        \u001b[38;5;34m640\u001b[0m \u2502 block_15_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_15_add (\u001b[38;5;33mAdd\u001b[0m)  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_14_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502                     \u2502                   \u2502            \u2502 block_15_project\u2026 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502    \u001b[38;5;34m153,600\u001b[0m \u2502 block_15_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_BN  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m3,840\u001b[0m \u2502 block_16_expand[\u001b[38;5;34m\u2026\u001b[0m \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_expand_re\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_16_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise  \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m8,640\u001b[0m \u2502 block_16_expand_\u2026 \u2502\n\u2502 (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502      \u001b[38;5;34m3,840\u001b[0m \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_depthwise\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m960\u001b[0m) \u2502          \u001b[38;5;34m0\u001b[0m \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mReLU\u001b[0m)              \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project    \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m320\u001b[0m) \u2502    \u001b[38;5;34m307,200\u001b[0m \u2502 block_16_depthwi\u2026 \u2502\n\u2502 (\u001b[38;5;33mConv2D\u001b[0m)            \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 block_16_project_BN \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m320\u001b[0m) \u2502      \u001b[38;5;34m1,280\u001b[0m \u2502 block_16_project\u2026 \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1 (\u001b[38;5;33mConv2D\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      \u2502    \u001b[38;5;34m409,600\u001b[0m \u2502 block_16_project\u2026 \u2502\n\u2502                     \u2502 \u001b[38;5;34m1280\u001b[0m)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Conv_1_bn           \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      \u2502      \u001b[38;5;34m5,120\u001b[0m \u2502 Conv_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \u2502\n\u2502 (\u001b[38;5;33mBatchNormalizatio\u2026\u001b[0m \u2502 \u001b[38;5;34m1280\u001b[0m)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 out_relu (\u001b[38;5;33mReLU\u001b[0m)     \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      \u2502          \u001b[38;5;34m0\u001b[0m \u2502 Conv_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \u2502\n\u2502                     \u2502 \u001b[38;5;34m1280\u001b[0m)             \u2502            \u2502                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 global_average_poo\u2026 \u2502 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      \u2502          \u001b[38;5;34m0\u001b[0m \u2502 out_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \u2502\n\u2502 (\u001b[38;5;33mGlobalAveragePool\u2026\u001b[0m \u2502                   \u2502            \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n</pre>\n", "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,223,872</span> (8.48 MB)\n</pre>\n", "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,223,872\u001b[0m (8.48 MB)\n"}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n</pre>\n", "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "2a0adcf5", "cell_type": "markdown", "source": "Tous les workeurs doivent pouvoir acc\u00e9der au mod\u00e8le ainsi qu'\u00e0 ses poids. <br />\nUne bonne pratique consiste \u00e0 charger le mod\u00e8le sur le driver puis \u00e0 diffuser <br />\nensuite les poids aux diff\u00e9rents workeurs."}, {"metadata": {"trusted": false}, "id": "1cc53ff0", "cell_type": "code", "source": "brodcast_weights = sc.broadcast(new_model.get_weights())", "execution_count": 41, "outputs": []}, {"metadata": {}, "id": "8bc0e34e", "cell_type": "markdown", "source": "<u>Mettons cela sous forme de fonction</u> :"}, {"metadata": {"trusted": false}, "id": "3fd51ba9", "cell_type": "code", "source": "def model_fn():\n    \"\"\"\n    Returns a MobileNetV2 model with top layer removed \n    and broadcasted pretrained weights.\n    \"\"\"\n    model = MobileNetV2(weights='imagenet',\n                        include_top=True,\n                        input_shape=(224, 224, 3))\n    for layer in model.layers:\n        layer.trainable = False\n    new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n    new_model.set_weights(brodcast_weights.value)\n    return new_model", "execution_count": 42, "outputs": []}, {"metadata": {}, "id": "e5620876", "cell_type": "markdown", "source": "### 3.7.3 D\u00e9finition du processus de chargement des images et application <br/>de leur featurisation \u00e0 travers l'utilisation de pandas UDF\n\nCe notebook d\u00e9finit la logique par \u00e9tapes, jusqu'\u00e0 Pandas UDF.\n\n<u>L'empilement des appels est la suivante</u> :\n\n- Pandas UDF\n  - featuriser une s\u00e9rie d'images pd.Series\n   - pr\u00e9traiter une image"}, {"metadata": {"trusted": false}, "id": "dc4e5f69", "cell_type": "code", "source": "def preprocess(content):\n    \"\"\"\n    Preprocesses raw image bytes for prediction.\n    \"\"\"\n    img = Image.open(io.BytesIO(content)).resize([224, 224])\n    arr = img_to_array(img)\n    return preprocess_input(arr)\n\ndef featurize_series(model, content_series):\n    \"\"\"\n    Featurize a pd.Series of raw images using the input model.\n    :return: a pd.Series of image features\n    \"\"\"\n    input = np.stack(content_series.map(preprocess))\n    preds = model.predict(input)\n    # For some layers, output features will be multi-dimensional tensors.\n    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n    output = [p.flatten() for p in preds]\n    return pd.Series(output)\n\n@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\ndef featurize_udf(content_series_iter):\n    '''\n    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n\n    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n                              is a pandas Series of image data.\n    '''\n    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n    # for multiple data batches.  This amortizes the overhead of loading big models.\n    model = model_fn()\n    for content_series in content_series_iter:\n        yield featurize_series(model, content_series)", "execution_count": 43, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/home/djamel/Module_11/venv310/lib/python3.10/site-packages/pyspark/sql/pandas/functions.py:407: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n  warnings.warn(\n"}]}, {"metadata": {"trusted": false}, "id": "2e04a246-fd97-4cde-9250-0a97052b77e3", "cell_type": "code", "source": "pip show Pyarrow\n", "execution_count": 44, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Name: pyarrow\nVersion: 14.0.0\nSummary: Python library for Apache Arrow\nHome-page: https://arrow.apache.org/\nAuthor: \nAuthor-email: \nLicense: Apache License, Version 2.0\nLocation: /home/djamel/Module_11/venv310/lib/python3.10/site-packages\nRequires: numpy\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\n"}]}, {"metadata": {}, "id": "2bdf2ef9", "cell_type": "markdown", "source": "### 3.7.4 Ex\u00e9cution des actions d'extraction de features\n\nLes Pandas UDF, sur de grands enregistrements (par exemple, de tr\u00e8s grandes images), <br />\npeuvent rencontrer des erreurs de type Out Of Memory (OOM).<br />\nSi vous rencontrez de telles erreurs dans la cellule ci-dessous, <br />\nessayez de r\u00e9duire la taille du lot Arrow via 'maxRecordsPerBatch'\n\nJe n'utiliserai pas cette commande dans ce projet <br />\net je laisse donc la commande en commentaire."}, {"metadata": {"trusted": false}, "id": "1f30d28c", "cell_type": "code", "source": "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")", "execution_count": 45, "outputs": []}, {"metadata": {}, "id": "70f8f95d", "cell_type": "markdown", "source": "Nous pouvons maintenant ex\u00e9cuter la featurisation sur l'ensemble de notre DataFrame Spark.<br />\n<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout d\u00e9pend du volume de donn\u00e9es \u00e0 traiter. <br />\n\nNotre jeu de donn\u00e9es de **Test** contient **22819 images**. <br />\nCependant, dans l'ex\u00e9cution en mode **local**, <br />\nnous <u>traiterons un ensemble r\u00e9duit de **5928 images**</u>."}, {"metadata": {"trusted": false}, "id": "7691547d-ad6b-4612-a4ca-0df2f9007145", "cell_type": "code", "source": "features_df = images.repartition(20).select(col(\"path\"),\n                                            col(\"label\"),\n                                            featurize_udf(\"content\").alias(\"features\")\n                                           )", "execution_count": 46, "outputs": []}, {"metadata": {"trusted": false}, "id": "16ec39e4-0622-43aa-a8a2-6114f85d314f", "cell_type": "code", "source": "print(PATH_Result)", "execution_count": 47, "outputs": [{"name": "stdout", "output_type": "stream", "text": "file:/home/djamel/Module_11/data/Results\n"}]}, {"metadata": {}, "id": "eb5e83ec", "cell_type": "markdown", "source": "<u>Rappel du PATH o\u00f9 seront inscrits les fichiers au format \"**parquet**\" <br />\ncontenant nos r\u00e9sultats, \u00e0 savoir, un DataFrame contenant 3 colonnes</u> :\n 1. Path des images\n 2. Label de l'image\n 3. Vecteur de caract\u00e9ristiques de l'image"}, {"metadata": {}, "id": "f8901db3", "cell_type": "markdown", "source": "<u>Enregistrement des donn\u00e9es trait\u00e9es au format \"**parquet**\"</u> :"}, {"metadata": {"trusted": false}, "id": "7242aca9-3341-468c-a735-88eb39cd77d6", "cell_type": "code", "source": "\nimport time\n\n#Mesure du temps d\u2019\u00e9criture Parquet\nstart_time = time.time()\nfeatures_df.write.mode(\"overwrite\").parquet(PATH_Result)\nend_time = time.time()\n\n#Temps d\u2019ex\u00e9cution\nelapsed_time = end_time - start_time\nprint(f\"\u2705 termin\u00e9e et sauvegard\u00e9e dans : {PATH_Result}\")\nprint(f\"\u23f1\ufe0f Temps d'\u00e9criture Parquet : {elapsed_time:.2f} secondes\")\n", "execution_count": 48, "outputs": [{"name": "stderr", "output_type": "stream", "text": "2025-10-23 23:02:30.544253: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:30.567768: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:30.680430: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:30.846616: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:36.819296: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:36.871871: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:36.909484: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:36.925333: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-10-23 23:02:41.120557: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n2025-10-23 23:02:41.120608: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n2025-10-23 23:02:41.129702: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n2025-10-23 23:02:41.131293: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n\u001b[1m9/9\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7s/step\n\u001b[1m9/9\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7s/step\n\u001b[1m9/9\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 8s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 8s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 8s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 8s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step\n\u001b[1m10/10\u001b[0m \u001b[32m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step\n"}, {"name": "stdout", "output_type": "stream", "text": "\u2705 termin\u00e9e et sauvegard\u00e9e dans : file:/home/djamel/Module_11/data/Results\n\u23f1\ufe0f Temps d'\u00e9criture Parquet : 492.86 secondes\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                "}]}, {"metadata": {}, "id": "f9506f21", "cell_type": "markdown", "source": "## 3.8 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat\n\n<u>On charge les donn\u00e9es fraichement enregistr\u00e9es dans un **DataFrame Pandas**</u> :"}, {"metadata": {"trusted": false}, "id": "1c714fcb-0a0b-4626-b981-f60fed8dc9af", "cell_type": "code", "source": "df = pd.read_parquet(PATH_Result, engine='pyarrow')", "execution_count": 49, "outputs": []}, {"metadata": {"trusted": false}, "id": "19243bf5", "cell_type": "code", "source": "df_read = spark.read.parquet(\"/home/djamel/Module_11/data/Results\")\ndf_read.show(5)\n", "execution_count": 50, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-----------+--------------------+\n|                path|      label|            features|\n+--------------------+-----------+--------------------+\n|file:/home/djamel...|Cauliflower|[0.0, 0.46702707,...|\n|file:/home/djamel...|Cauliflower|[0.0, 0.1903695, ...|\n|file:/home/djamel...|Cauliflower|[0.024995405, 0.3...|\n|file:/home/djamel...|Cauliflower|[0.0, 1.3841028, ...|\n|file:/home/djamel...|Cauliflower|[0.0038408455, 1....|\n+--------------------+-----------+--------------------+\nonly showing top 5 rows\n\n"}]}, {"metadata": {}, "id": "27f15070", "cell_type": "markdown", "source": "<u>On affiche les 5 premi\u00e8res lignes du DataFrame</u> :"}, {"metadata": {"trusted": false}, "id": "8a1bcdeb", "cell_type": "code", "source": "df.head()", "execution_count": 51, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file:/home/djamel/Module_11/Notebook/data/Test...</td>\n      <td>Cauliflower</td>\n      <td>[0.0, 0.6462093, 1.8202561, 0.0, 0.019632787, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file:/home/djamel/Module_11/Notebook/data/Test...</td>\n      <td>Cauliflower</td>\n      <td>[0.0, 0.663455, 3.1199613, 0.0, 0.0, 0.0, 0.0,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file:/home/djamel/Module_11/Notebook/data/Test...</td>\n      <td>Cauliflower</td>\n      <td>[0.0, 0.18666272, 1.8489289, 0.0, 0.0, 0.0, 0....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file:/home/djamel/Module_11/Notebook/data/Test...</td>\n      <td>Cauliflower</td>\n      <td>[0.0, 0.7003504, 1.9360892, 0.0, 0.0, 0.0, 0.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file:/home/djamel/Module_11/Notebook/data/Test...</td>\n      <td>Cauliflower</td>\n      <td>[0.13815041, 0.3238665, 2.6318932, 0.0, 0.0128...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                path        label  \\\n0  file:/home/djamel/Module_11/Notebook/data/Test...  Cauliflower   \n1  file:/home/djamel/Module_11/Notebook/data/Test...  Cauliflower   \n2  file:/home/djamel/Module_11/Notebook/data/Test...  Cauliflower   \n3  file:/home/djamel/Module_11/Notebook/data/Test...  Cauliflower   \n4  file:/home/djamel/Module_11/Notebook/data/Test...  Cauliflower   \n\n                                            features  \n0  [0.0, 0.6462093, 1.8202561, 0.0, 0.019632787, ...  \n1  [0.0, 0.663455, 3.1199613, 0.0, 0.0, 0.0, 0.0,...  \n2  [0.0, 0.18666272, 1.8489289, 0.0, 0.0, 0.0, 0....  \n3  [0.0, 0.7003504, 1.9360892, 0.0, 0.0, 0.0, 0.0...  \n4  [0.13815041, 0.3238665, 2.6318932, 0.0, 0.0128...  "}, "execution_count": 51, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "id": "e2794fca", "cell_type": "markdown", "source": "<u>On valide que la dimension du vecteur de caract\u00e9ristiques des images est bien de dimension 1280</u> :"}, {"metadata": {"trusted": false}, "id": "0bb933b9", "cell_type": "code", "source": "df.loc[0,'features'].shape", "execution_count": 52, "outputs": [{"data": {"text/plain": "(1280,)"}, "execution_count": 52, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "id": "efe5348d", "cell_type": "markdown", "source": "Nous venons de valider le processus sur un jeu de donn\u00e9es all\u00e9g\u00e9 en local <br />\no\u00f9 nous avons simul\u00e9 un cluster de machines en r\u00e9partissant la charge de travail <br />\nsur diff\u00e9rents c\u0153urs de processeur au sein d'une m\u00eame machine.\n\nNous allons maintenant g\u00e9n\u00e9raliser le processus en d\u00e9ployant notre solution <br />\nsur un r\u00e9el cluster de machines et nous travaillerons d\u00e9sormais sur la totalit\u00e9 <br />\ndes 22819 images de notre dossier \"Test\"."}, {"metadata": {"trusted": false}, "id": "08ddc9b5-7966-4655-b032-25e7c2db0677", "cell_type": "code", "source": "df.shape", "execution_count": 53, "outputs": [{"data": {"text/plain": "(5927, 3)"}, "execution_count": 53, "metadata": {}, "output_type": "execute_result"}, {"name": "stderr", "output_type": "stream", "text": "25/10/25 18:39:20 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 11786996 ms exceeds timeout 120000 ms\n25/10/25 18:39:20 WARN SparkContext: Killing executors is not supported by current scheduler.\n25/10/25 18:39:21 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:21 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:29 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:29 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:39 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:39 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:49 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:49 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:58 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:39:58 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:08 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:08 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:18 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:18 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:27 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:27 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:37 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:37 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:47 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:47 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:56 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:40:56 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:06 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:06 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:16 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:16 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:24 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:24 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:34 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:34 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:44 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:44 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:53 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:41:53 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:03 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:03 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:13 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:13 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:23 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:23 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:32 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:32 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:42 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:42 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:52 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:42:52 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:00 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:00 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:10 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:10 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:20 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:20 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:29 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:29 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:39 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:39 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:49 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:49 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:57 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:43:57 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:07 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:07 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:17 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n\t... 17 more\n25/10/25 18:44:17 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:312)\n\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n\t... 17 more\n25/10/25 18:44:27 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:27 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:36 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:36 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:46 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:46 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:56 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:44:56 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:05 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:05 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:15 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:15 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:25 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:25 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:33 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:33 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:43 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:43 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:53 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:45:53 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:02 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:02 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:12 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:12 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:22 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:22 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:32 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:32 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:41 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:41 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:51 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:46:51 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:01 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:01 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:09 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:09 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:19 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:19 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:29 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:29 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:38 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:38 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:48 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:48 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:58 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:47:58 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:07 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:07 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:17 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:17 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:27 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:27 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:35 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:35 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:45 ERROR Inbox: Ignoring error\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:45 WARN Executor: Issue communicating with driver in heartbeater\norg.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n\t... 3 more\nCaused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.255.255.254:45985\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n\tat scala.concurrent.Promise.complete(Promise.scala:57)\n\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n\tat scala.concurrent.Promise.success(Promise.scala:91)\n\tat scala.concurrent.Promise.success$(Promise.scala:91)\n\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n\t... 8 more\n25/10/25 18:48:45 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"}]}, {"metadata": {}, "id": "a0f0f7c1", "cell_type": "markdown", "source": "# 4. D\u00e9ploiement de la solution sur le cloud\n\nMaintenant que nous avons v\u00e9rifi\u00e9 que notre solution fonctionne, <br />\nil est temps de la <u>d\u00e9ployer \u00e0 plus grande \u00e9chelle sur un vrai cluster de machines</u>.\n\n**Attention**, *je travaille sous Linux avec une version Ubuntu, <br />\nles commandes d\u00e9crites ci-dessous sont donc r\u00e9alis\u00e9es <br />\nexclusivement dans cet environnement.*\n\n<u>Plusieurs contraintes se posent</u> :\n 1. Quel prestataire de Cloud choisir ?\n 2. Quelles solutions de ce prestataire adopter ?\n 3. O\u00f9 stocker nos donn\u00e9es ?\n 4. Comment configurer nos outils dans ce nouvel environnement ?\n \n## 4.1 Choix du prestataire cloud : AWS\n\nLe prestataire le plus connu et qui offre \u00e0 ce jour l'offre <br />\nla plus large dans le cloud computing est **Amazon Web Services** (AWS).<br />\nCertaines de leurs offres sont parfaitement adapt\u00e9es \u00e0 notre probl\u00e9matique <br />\net c'est la raison pour laquelle j'utiliserai leurs services.\n\nL'objectif premier est de pouvoir, gr\u00e2ce \u00e0 AWS, <u>louer de la puissance de calcul \u00e0 la demande</u>. <br />\nL'id\u00e9e \u00e9tant de pouvoir, quel que soit la charge de travail, <br />\nobtenir suffisamment de puissance de calcul pour pouvoir traiter nos images, <br />\nm\u00eame si le volume de donn\u00e9es venait \u00e0 fortement augmenter.\n\nDe plus, la capacit\u00e9 d'utiliser cette puissance de calcul \u00e0 la demande <br />\npermet de diminuer drastiquement les co\u00fbts si l'on compare les co\u00fbts d'une location <br />\nde serveur complet sur une dur\u00e9e fixe (1 mois, 1 ann\u00e9e par exemple).\n\n## 4.2 Choix de la solution technique : EMR\n\n<u>Plusieurs solutions s'offre \u00e0 nous</u> :\n1. Solution **IAAS** (Infrastructure AS A Service)\n - Dans cette configuration **AWS** met \u00e0 notre disposition des serveurs vierges <br />\n   sur lequel nous avons un acc\u00e8s en administrateur, ils sont nomm\u00e9s **instance EC2**.<br />\n   Pour faire simple, nous pouvons avec cette solution reproduire pratiquement <br />\n   \u00e0 l'identique la solution mis en \u0153uvre en local sur notre machine.<br />\n   <u>On installe nous-m\u00eame l'int\u00e9gralit\u00e9 des outils puis on ex\u00e9cute notre script</u> :\n  - Installation de **Spark**, **Java** etc.\n  - Installation de **Python** (via Anaconda par exemple)\n  - Installation de **Jupyter Notebook**\n  - Installation des **librairies compl\u00e9mentaires**\n  - Il faudra bien \u00e9videment veiller \u00e0 **impl\u00e9menter les librairies \n    n\u00e9cessaires \u00e0 toutes les machines (workers) du cluster**\n  - <u>Avantages</u> :\n      - Libert\u00e9 totale de mise en \u0153uvre de la solution\n      - Facilit\u00e9 de mise en \u0153uvre \u00e0 partir d'un mod\u00e8le qui s'ex\u00e9cute en local sur une machine Linux\n  - <u>Inconv\u00e9nients</u> :\n      - Cronophage\n          - N\u00e9cessit\u00e9 d'installer et de configurer toute la solution\n      - Possible probl\u00e8mes techniques \u00e0 l'installation des outils (des probl\u00e9matiques qui <br />\n        n'existaient pas en local sur notre machine peuvent apparaitre sur le serveur EC2)\n      - Solution non p\u00e9renne dans le temps, il faudra veiller \u00e0 la mise \u00e0 jour des outils <br />\n        et \u00e9ventuellement devoir r\u00e9installer Spark, Java etc. \n2. Solution **PAAS** (Plateforme As A Service)\n - **AWS** fournit \u00e9norm\u00e9ment de services diff\u00e9rents, dans l'un de ceux-l\u00e0 <br />\n   il existe une offre qui permet de louer des **instances EC2** <br />\n   avec des applications pr\u00e9install\u00e9es et configur\u00e9es : il s'agit du **service EMR**.\n - **Spark** y sera d\u00e9j\u00e0 install\u00e9\n - Possibilit\u00e9 de demander l'installation de **Tensorflow** ainsi que **JupyterHub**\n - Possibilit\u00e9 d'indiquer des **packages compl\u00e9mentaires** \u00e0 installer <br />\n   \u00e0 l'initialisation du serveur **sur l'ensemble des machines du cluster**.\n - <u>Avantages</u> :\n     - Facilit\u00e9 de mise en \u0153uvre\n         - Il suffit de tr\u00e8s peu de configuration pour obtenir <br />\n           un environnement parfaitement fonctionnel\n     - Rapidit\u00e9 de mise en \u0153uvre\n         - Une fois la premi\u00e8re configuration r\u00e9alis\u00e9e, il est tr\u00e8s facile <br />\n           et tr\u00e8s rapide de recr\u00e9er des clusters \u00e0 l'identique qui seront <br />\n           disponibles presque instantan\u00e9ment (le temps d'instancier les <br />\n           serveurs soit environ 15/20 minutes)\n     - Solutions mat\u00e9rielless et logicielles optimis\u00e9es par les ing\u00e9nieurs d'AWS\n         - On sait que les versions install\u00e9es vont fonctionner <br />\n           et que l'architecture propos\u00e9e est optimis\u00e9e\n     - Stabilit\u00e9 de la solution\n    - Solution \u00e9volutive\n        Il est facile d\u2019obtenir \u00e0 chaque nouvelle instanciation une version \u00e0 jour <br />\n        de chaque package, en \u00e9tant garanti de leur compatibilit\u00e9 avec le reste de l\u2019environnement.\n  - Plus s\u00e9curis\u00e9\n\t- Les \u00e9ventuels patchs de s\u00e9curit\u00e9 seront automatiquement mis \u00e0 jour <br />\n      \u00e0 chaque nouvelle instanciation du cluster EMR.\n - <u>Inconv\u00e9nients</u> :\n     - Peut-\u00eatre un certain manque de libert\u00e9 sur la version des packages disponibles ? <br />\n       M\u00eame si je n'ai pas constat\u00e9 ce probl\u00e8me.\n   \n\nJe retiens la solution **PAAS** en choisissant d'utiliser <br />\nle service **EMR** d'Amazon Web Services.<br />\nJe la trouve plus adapt\u00e9e \u00e0 notre probl\u00e9matique et permet <br />\nune mise en \u0153uvre qui soit \u00e0 la fois plus rapide et <br />\nplus efficace que la solution IAAS.\n\n## 4.3 Choix de la solution de stockage des donn\u00e9es : Amazon S3\n\n<u>Amazon propose une solution tr\u00e8s efficace pour la gestion du stockage des donn\u00e9es</u> : **Amazon S3**. <br />\nS3 pour Amazon Simple Storage Service.\n\nIl pourrait \u00eatre tentant de stocker nos donn\u00e9es sur l'espace allou\u00e9 par le serveur **EC2**, <br />\nmais si nous ne prenons aucune mesure pour les sauvegarder ensuite sur un autre support, <br />\n<u>les donn\u00e9es seront perdues</u> lorsque le serveur sera r\u00e9sili\u00e9 (on r\u00e9silie le serveur lorsqu'on <br />\nne s'en sert pas pour des raisons de co\u00fbt).<br />\nDe fait, si l'on d\u00e9cide d'utiliser l'espace disque du serveur EC2 il faudra imaginer <br />\nune solution pour sauvegarder les donn\u00e9es avant la r\u00e9siliation du serveur.\nDe plus, nous serions expos\u00e9s \u00e0 certaines probl\u00e9matiques si nos donn\u00e9es venaient \u00e0 <br />\n**saturer** l'espace disponible de nos serveurs (ralentissements, disfonctionnements).\n\n<u>Utiliser **Amazon S3** permet de s'affranchir de toutes ces probl\u00e9matiques</u>. <br />\nL'espace disque disponible est **illimit\u00e9**, et il est **ind\u00e9pendant de nos serveurs EC2**. <br />\nL'acc\u00e8s aux donn\u00e9es est **tr\u00e8s rapide** car nous restons dans l'environnement d'AWS <br />\net nous prenons soin de <u>choisir la m\u00eame r\u00e9gion pour nos serveurs **EC2** et **S3**</u>.\n\nDe plus, comme nous le verrons <u>il est possible d'acc\u00e9der aux donn\u00e9es sur **S3** <br />\n    de la m\u00eame mani\u00e8re que l'on **acc\u00e8de aux donn\u00e9es sur un disque local**</u>.<br />\nNous utiliserons simplement un **PATH au format s3://...** .\n\n## 4.4 Configuration de l'environnement de travail\n\nLa premi\u00e8re \u00e9tape est d'installer et de configurer [**AWS Cli**](https://aws.amazon.com/fr/cli/),<br />\nil s'agit de l'**interface en ligne de commande d'AWS**.<br />\nElle nous permet d'**interagir avec les diff\u00e9rents services d'AWS**, comme **S3** par exemple.\n\nPour pouvoir utiliser **AWS Cli**, il faut le configurer en cr\u00e9ant pr\u00e9alablement <br />\nun utilisateur \u00e0 qui on donnera les autorisations dont nous aurons besoin.<br />\nDans ce projet il faut que l'utilisateur ait \u00e0 minima un contr\u00f4le total sur le service S3.\n\n<u>La gestion des utilisateurs et de leurs droits s'effectue via le service **AMI**</u> d'AWS.\n\nUne fois l'utilisateur cr\u00e9\u00e9 et ses autorisations configur\u00e9es nous cr\u00e9ons une **paire de cl\u00e9s** <br />\nqui nous permettra de nous **connecter sans \u00e0 avoir \u00e0 devoir saisir syst\u00e9matiquement notre login/mot de passe**.<br />\n\nIl faut \u00e9galement configurer l'**acc\u00e8s SSH** \u00e0 nos futurs serveurs EC2. <br />\nIci aussi, via un syst\u00e8me de cl\u00e9s qui nous dispense de devoir nous authentifier \"\u00e0 la main\" \u00e0 chaque connexion.\n\nToutes ses \u00e9tapes de configuration sont parfaitement d\u00e9crites <br />\ndans le cours du projet: [D\u00e9couvrez le cloud avec Amazon Web Services / Faites vos premiers pas sur AWS](https://openclassrooms.com/fr/courses/4810836-decouvrez-le-cloud-avec-amazon-web-services/7821712-faites-vos-premiers-pas-sur-aws)\n\n## 4.5 Upload de nos donn\u00e9es sur S3\n\nNos outils sont configur\u00e9s. <br />\nIl faut maintenant uploader nos donn\u00e9es de travail sur Amazon S3.\n\nIci aussi les \u00e9tapes sont d\u00e9crites avec pr\u00e9cision <br />\ndans le cours [D\u00e9couvrez le cloud avec Amazon Web Services / Stockez et acc\u00e9dez \u00e0 des fichiers sur Amazon S3](https://openclassrooms.com/fr/courses/4810836-decouvrez-le-cloud-avec-amazon-web-services/7822690-stockez-et-accedez-a-des-fichiers-sur-amazon-s3)\n\nJe d\u00e9cide de n'uploader que les donn\u00e9es contenues dans le dossier **Test** du [jeu de donn\u00e9es du projet](https://www.kaggle.com/moltean/fruits/download)\n\n\nLa premi\u00e8re \u00e9tape consiste \u00e0 **cr\u00e9er un bucket sur S3** <br />\ndans lequel nous uploaderons les donn\u00e9es du projet:\n- **aws s3 mb s3://p8-data**\n\nOn v\u00e9rifie que le bucket \u00e0 bien \u00e9t\u00e9 cr\u00e9\u00e9\n- **aws s3 ls**\n - Si le nom du bucket s'affiche alors c'est qu'il a \u00e9t\u00e9 correctement cr\u00e9\u00e9.\n\nOn copie ensuite le contenu du dossier \"**Test**\" <br />\ndans un r\u00e9pertoire \"**Test**\" sur notre bucket \"**p8-data**\":\n1. On se place \u00e0 l'int\u00e9rieur du r\u00e9pertoire **Test**\n2. **aws sync . s3://p8-data/Test**\n\nLa commande **sync** est utile pour synchroniser deux r\u00e9pertoires.\n\n<u>Nos donn\u00e9es du projet sont maintenant disponibles sur Amazon S3</u>.\n\n## 4.6 Configuration du serveur EMR\n\nUne fois encore, le cours [D\u00e9couvrez le cloud avec Amazon Web Services / D\u00e9couvrez les services d'Amazon EC2](https://openclassrooms.com/fr/courses/4810836-decouvrez-le-cloud-avec-amazon-web-services/7822091-demarrez-votre-premiere-instance-ec2) <br /> d\u00e9taille l'essentiel des \u00e9tapes pour lancer un cluster avec **EMR**.\n\n<u>Je d\u00e9taillerai ici les \u00e9tapes particuli\u00e8res qui nous permettent <br />\nde configurer le serveur selon nos besoins</u> :\n\n1. Cliquez sur Cr\u00e9er un cluster\n![Cr\u00e9er un cluster](img/EMR_creer.png)\n2. Cliquez sur Acc\u00e9der aux options avanc\u00e9es\n![Cr\u00e9er un cluster](img/EMR_options_avancees.png)\n\n### 4.6.1 \u00c9tape 1 : Logiciels et \u00e9tapes\n\n#### 4.6.1.1 Configuration des logiciels\n\n<u>S\u00e9lectionnez les packages dont nous aurons besoin comme dans la capture d'\u00e9cran</u> :\n1. Nous s\u00e9lectionnons la derni\u00e8re version d'**EMR**, soit la version **6.3.0** au moment o\u00f9 je r\u00e9dige ce document\n2. Nous cochons bien \u00e9videment **Hadoop** et **Spark** qui seront pr\u00e9install\u00e9s dans leur version la plus r\u00e9cente\n3. Nous aurons \u00e9galement besoin de **TensorFlow** pour importer notre mod\u00e8le et r\u00e9aliser le **transfert learning**\n4. Nous travaillerons enfin avec un **notebook Jupyter** via l'application **JupyterHub**<br />\n - Comme nous le verrons dans un instant nous allons <u>param\u00e9trer l'application afin que les notebooks</u>, <br />\n   comme le reste de nos donn\u00e9es de travail, <u>soient enregistr\u00e9s directement sur S3</u>.\n![Cr\u00e9er un cluster](img/EMR_configuration_logiciels.png)\n\n#### 4.6.1.2 Modifier les param\u00e8tres du logiciel\n\n<u>Param\u00e9trez la persistance des notebooks cr\u00e9\u00e9s et ouvert via JupyterHub</u> :\n- On peut \u00e0 cette \u00e9tape effectuer des demandes de param\u00e9trage particuli\u00e8res sur nos applications. <br />\n  L'objectif est, comme pour le reste de nos donn\u00e9es de travail, <br />\n  d'\u00e9viter toutes les probl\u00e9matiques \u00e9voqu\u00e9es pr\u00e9c\u00e9demment. <br />\n  C'est l'objectif \u00e0 cette \u00e9tape, <u>nous allons enregistrer <br />\n  et ouvrir les notebooks</u> non pas sur l'espace disque de  l'instance EC2 (comme <br />\n  ce serait le cas dans la configuration par d\u00e9faut de JupyterHub) mais <br />\n  <u>directement sur **Amazon S3**</u>.\n- <u>deux solutions sont possibles pour r\u00e9aliser cela</u> :\n 1. Cr\u00e9er un **fichier de configuration JSON** que l'on **upload sur S3** et on indique ensuite le chemin d\u2019acc\u00e8s au fichier JSON\n 2. Rentrez directement la configuration au format JSON\n \nJ'ai personnellement cr\u00e9\u00e9 un fichier JSON lors de la cr\u00e9ation de ma premi\u00e8re instance EMR, <br />\npuis lorsqu'on d\u00e9cide de cloner notre serveur pour en recr\u00e9er un facilement \u00e0 l'identique, <br />\nla configuration du fichier JSON se retrouve directement copi\u00e9 comme dans la capture ci-dessous.\n\n<u>Voici le contenu de mon fichier JSON</u> :  [{\"classification\":\"jupyter-s3-conf\",\"properties\":{\"s3.persistence.bucket\":\"p8-data\",\"s3.persistence.enabled\":\"true\"}}]\n Appuyez ensuite sur \"**Suivant**\"\n![Modifier les param\u00e8tres du logiciel](img/EMR_parametres_logiciel.png)\n\n### 4.6.2 \u00c9tape 2 : Mat\u00e9riel\n\nA cette \u00e9tape, laissez les choix par d\u00e9faut. <br />\n<u>L'important ici est la s\u00e9lection de nos instances</u> :\n\n1. je choisi les instances de type **M5** qui sont des **instances de type \u00e9quilibr\u00e9s**\n2. je choisi le type **xlarge** qui est l'instance la **moins on\u00e9reuse disponible**\n [Plus d'informations sur les instances M5 Amazon EC2](https://aws.amazon.com/fr/ec2/instance-types/m5/)\n3. Je s\u00e9lectionne **1 instance Ma\u00eetre** (le driver) et **2 instances Principales** (les workeurs) <br />\n   soit **un total de 3 instance EC2**.\n![Choix du materiel](img/EMR_materiel.png)\n\n### 4.6.3 \u00c9tape 3 : Param\u00e8tres de cluster g\u00e9n\u00e9raux\n\n#### 4.6.3.1 Options g\u00e9n\u00e9rales\n<u>La premi\u00e8re chose \u00e0 faire est de donner un nom au cluster</u> :<br />\n*J'ai \u00e9galement d\u00e9coch\u00e9 \"Protection de la r\u00e9siliation\" pour des raisons pratiques.*\n    \n![Nom du Cluster](img/EMR_nom_cluster.png)\n\n#### 4.6.3.2 Actions d'amor\u00e7age\n\nNous allons \u00e0 cette \u00e9tape **choisir les packages manquants \u00e0 installer** et qui <br />\nnous serons utiles dans l'ex\u00e9cution de notre notebook.<br />\n<u>L'avantage de r\u00e9aliser cette \u00e9tape maintenant est que les packages <br />\ninstall\u00e9s le seront sur l'ensemble des machines du cluster</u>.\n\nNous cr\u00e9ons un fichier nomm\u00e9 \"**bootstrap-emr.sh**\" que nous <u>uploadons <br />\nsur S3</u>(je l\u2019installe \u00e0 la racine de mon **bucket \"p8-data\"**) et nous l'ajoutons <br />\ncomme indiqu\u00e9 dans la capture d'\u00e9cran ci-dessous:\n![Actions d'amorcage](img/EMR_amorcage.png)\n\nVoici le contenu du fichier **bootstrap-emr.sh**<br />\nComme on peut le constater il s'agit simplement de commande \"**pip install**\" <br />\npour **installer les biblioth\u00e8ques manquantes** comme r\u00e9alis\u00e9 en local.<br />\nUne fois encore, <u>il est n\u00e9cessaire de r\u00e9aliser ces actions \u00e0 cette \u00e9tape</u> <br />\npour que <u>les packages soient install\u00e9s sur l'ensemble des machines du cluster</u> <br />\net non pas uniquement sur le driver, comme cela serait le cas si nous ex\u00e9cutions <br />\nces commandes directement dans le notebook JupyterHub ou dans la console EMR (connect\u00e9 au driver).\n![Contenu du fichier bootstrap](img/EMR_bootstrap.png)\n\n**setuptools** et **pip** sont mis \u00e0 jour pour \u00e9viter une probl\u00e9matique <br />\navec l'installation du package **pyarrow**.<br />\n**Pandas** a eu droit \u00e0 une mise \u00e0 jour majeur (1.3.0) il y a moins d'une semaine <br />\nau moment de la r\u00e9daction de ce notebook, et la nouvelle version de **Pandas** <br />\nn\u00e9cessite une version plus r\u00e9cente de **Numpy** que la version install\u00e9e par <br />\nd\u00e9faut (1.16.5) \u00e0 l'initialisation des instances **EC2**. <u>Il ne semble pas <br />\npossible d'imposer une autre version de Numpy que celle install\u00e9 par <br />\nd\u00e9faut</u> m\u00eame si on force l'installation d'une version r\u00e9cente de **Numpy** <br />\n(en tout cas, ni simplement ni intuitivement).<br />\nLa mise \u00e0 jour \u00e9tant tr\u00e8s r\u00e9cente <u>la version de **Numpy** n'est pas encore <br />\nmise \u00e0 jour sur **EC2**</u> mais on peut imaginer que ce sera le cas tr\u00e8s rapidement <br />\net il ne sera plus n\u00e9cessaire d'imposer une version sp\u00e9cifique de **Pandas**.<br />\nEn attendant, je demande <u>l'installation de l'avant derni\u00e8re version de **Pandas (1.2.5)**</u>\n\nOn clique ensuite sur ***Suivant***\n\n### 4.6.4 \u00c9tape 4 : S\u00e9curit\u00e9\n\n#### 4.6.4.1 Options de s\u00e9curit\u00e9\n\nA cette \u00e9tape nous s\u00e9lectionnons la **paire de cl\u00e9s EC2** cr\u00e9\u00e9 pr\u00e9c\u00e9demment. <br />\nElle nous permettra de se connecter en **ssh** \u00e0 nos **instances EC2** <br />\nsans avoir \u00e0 entrer nos login/mot de passe.<br />\nOn laisse les autres param\u00e8tres par d\u00e9faut. <br />\nEt enfin, on clique sur \"***Cr\u00e9er un cluster***\"\n \n![EMR S\u00e9curit\u00e9](img/EMR_securite.png)\n\n## 4.7 Instanciation du serveur\n\nIl ne nous reste plus qu'\u00e0 attendre que le serveur soit pr\u00eat. <br />\nCette \u00e9tape peut prendre entre **15 et 20 minutes**.\n\n<u>Plusieurs \u00e9tapes s'encha\u00eene, on peut suivre l'avanc\u00e9 du statut du **cluster EMR**</u> :\n\n![Instanciation \u00e9tape 1](img/EMR_instanciation_01.png)\n![Instanciation \u00e9tape 2](img/EMR_instanciation_02.png)\n![Instanciation \u00e9tape 3](img/EMR_instanciation_03.png)\n\n<u>Lorsque le statut affiche en vert: \"**En attente**\" cela signifie que l'instanciation <br />\ns'est bien d\u00e9roul\u00e9e et que notre serveur est pr\u00eat \u00e0 \u00eatre utilis\u00e9</u>. \n\n## 4.8 Cr\u00e9ation du tunnel SSH \u00e0 l'instance EC2 (Ma\u00eetre)\n\n### 4.8.1 Cr\u00e9ation des autorisations sur les connexions entrantes\n\n<u>Nous souhaitons maintenant pouvoir acc\u00e9der \u00e0 nos applications</u> :\n - **JupyterHub** pour l'ex\u00e9cution de notre notebook\n - **Serveur d'historique Spark** pour le suivi de l'ex\u00e9cution <br />\n   des t\u00e2ches de notre script lorsqu'il sera lanc\u00e9\n \nCependant, <u>ces applications ne sont accessibles que depuis le r\u00e9seau local du driver</u>, <br />\net pour y acc\u00e9der nous devons **cr\u00e9er un tunnel SSH vers le driver**.\n\nPar d\u00e9faut, ce driver se situe derri\u00e8re un firewall qui bloque l'acc\u00e8s en SSH. <br />\n<u>Pour ouvrir le port 22 qui correspond au port sur lequel \u00e9coute le serveur SSH, <br />\nil faut modifier le **groupe de s\u00e9curit\u00e9 EC2 du driver**</u>.\n\n*Il faudra que l'on se connecte en SSH au driver de notre cluster. <br />\nPar d\u00e9faut, ce driver se situe derri\u00e8re un firewall qui bloque l'acc\u00e8s en SSH. <br />\nPour ouvrir le port 22 qui correspond au port sur lequel \u00e9coute le serveur SSH, <br />\nil faut modifier le groupe de s\u00e9curit\u00e9 EC2 du driver. Sur la page de la console <br />\nconsacr\u00e9e \u00e0 EC2, dans l'onglet \"R\u00e9seau et s\u00e9curit\u00e9\", cliquez sur \"Groupes de s\u00e9curit\u00e9\". <br />\nVous allez devoir modifier le groupe de s\u00e9curit\u00e9 d\u2019ElasticMapReduce-Master. <br />\nDans l'onglet \"Entrant\", ajoutez une r\u00e8gle SSH dont la source est \"N'importe o\u00f9\" <br />\n(ou \"Mon IP\" si vous disposez d'une adresse IP fixe).*\n\n![Configuration autorisation ports entrants pour ssh](img/EMR_config_ssh_01.png)\n\n<u>Une fois cette \u00e9tape r\u00e9alis\u00e9e vous devriez avoir une configuration semblable \u00e0 la mienne</u> :\n\n![Configuration ssh termin\u00e9e](img/EMR_config_ssh_02.png)\n\n### 4.8.2 Cr\u00e9ation du tunnel ssh vers le Driver\n\nOn peut maintenant \u00e9tablir le **tunnel SSH** vers le **Driver**. <br />\nPour cela on r\u00e9cup\u00e8re les informations de connexion fournis par Amazon <br />\ndepuis la page du service EMR / Cluster / onglet R\u00e9capitulatif en <br />\ncliquant sur \"**Activer la connexion Web**\"\n\n![Activer la connexion Web](img/EMR_tunnel_ssh_01.png)\n\n<u>On r\u00e9cup\u00e8re ensuite la commande fournis par Amazon pour **\u00e9tablir le tunnel SSH**</u> :\n\n![R\u00e9cup\u00e9rer la commande pour \u00e9tablir le tunnel ssh](img/EMR_tunnel_ssh_02.png)\n\n<u>Dans mon cas, la commande ne fonctionne pas tel</u> quel et j'ai du **l'adapter \u00e0 ma configuration**. <br />\nLa **cl\u00e9 ssh** se situe dans un dossier \"**.ssh**\" elle-m\u00eame situ\u00e9e dans <br />\nmon **r\u00e9pertoire personnel** dont le symbole est, sous Linux, identifi\u00e9 par un tilde \"**~**\".\n\n<u>Finalement, j'utilise la commande suivante dans un terminal pour \u00e9tablir <br />\n    mon tunnel ssh (seul l'URL change d'une instance \u00e0 une autre)</u> : <br />\n\"**ssh -i ~/.ssh/p8-ec2.pem -D 5555 hadoop@ec2-35-180-91-39.eu-west-3.compute.amazonaws.com**\"\n\n<u>On inscrit \"**yes**\" pour valider la connexion et si <br />\n    la connexion est \u00e9tablit on obtient le r\u00e9sultat suivant</u> :\n\n![Cr\u00e9ation du tunnel SSH](img/EMR_connexion_ssh_01.png)\n\nNous avons **correctement \u00e9tabli le tunnel ssh avec le driver** sur le port \"5555\".\n\n### 4.8.3 Configuration de FoxyProxy\n\nUne derni\u00e8re \u00e9tape est n\u00e9cessaire pour acc\u00e9der \u00e0 nos applications, <br />\nen demandant \u00e0 notre navigateur d'emprunter le tunnel ssh.<br />\nJ'utilise pour cela **FoxyProxy**.\n\nSinon, ouvrez la configuration de **FoxyProxy** et <u>cliquez sur **Ajouter**</u> en haut \u00e0 gauche <br />\npuis renseigner les \u00e9l\u00e9ments comme dans la capture ci-dessous :\n\n![Configuration FoxyProxy Etape 1](img/EMR_foxyproxy_config_01.png)\n\n<u>On obtient le r\u00e9sultat ci-dessous</u> :\n\n![Configuration FoxyProxy Etape 2](img/EMR_foxyproxy_config_02.png)\n\n\n### 4.8.4 Acc\u00e8s aux applications du serveur EMR via le tunnel ssh\n\n\n<u>Avant d'\u00e9tablir notre **tunnel ssh** nous avions \u00e7a</u> :\n\n![avant tunnel ssh](img/EMR_tunnel_ssh_avant.png)\n\n<u>On active le **tunnel ssh** comme vu pr\u00e9c\u00e9demment puis on demande <br />\n\u00e0 notre navigateur de l'utiliser avec **FoxyProxy**</u> :\n\n![FoxyProxy activation](img/EMR_foxyproxy_activation.png)\n\n<u>On peut maintenant s'apercevoir que plusieurs applications nous sont accessibles</u> :\n\n![avant tunnel ssh](img/EMR_tunnel_ssh_apres.png)\n\n## 4.9 Connexion au notebook JupyterHub\n\nPour se connecter \u00e0 **JupyterHub** en vue d'ex\u00e9cuter notre **notebook**, <br />\nil faut commencer par <u>cliquer sur l'application **JupyterHub**</u> apparu <br />\ndepuis que nous avons configur\u00e9 le **tunnel ssh** et **foxyproxy** sur <br />\nnotre navigateur (actualisez la page si ce n\u2019est pas le cas).\n\n![D\u00e9marrage de JupyterHub](img/EMR_jupyterhub_connexion_01.png)\n\nOn passe les \u00e9ventuels avertissements de s\u00e9curit\u00e9 puis <br />\nnous arrivons sur une page de connexion.\n    \n<u>On se connecte avec les informations par d\u00e9faut</u> :\n - <u>login</u>: **jovyan**\n - <u>password</u>: **jupyter**\n \n![Connexion \u00e0 JupyterHub](img/EMR_jupyterhub_connexion_02.png)\n\nNous arrivons ensuite dans un dossier vierge de notebook.<br />\nIl suffit d'en cr\u00e9er un en cliquant sur \"**New**\" en haut \u00e0 droite.\n\n![Liste et cr\u00e9ation des notebook](img/EMR_jupyterhub_creer_notebooks.png)\n\nIl est \u00e9galement possible d'en <u>uploader un directement dans notre **bucket S3**</u>.\n\nGrace \u00e0 la <u>**persistance** param\u00e9tr\u00e9e \u00e0 l'instanciation du cluster <br />\nnous sommes actuellement dans l'arborescence de notre **bucket S3**</u>\n\n![Notebook stock\u00e9s sur S3](img/EMR_jupyterhub_S3.png)\n\nJe d\u00e9cide d'**importer un notebook d\u00e9j\u00e0 r\u00e9dig\u00e9 en local directement <br />\nsur S3** et je l'ouvre depuis **l'interface JupyterHub**.\n\n## 4.10 Ex\u00e9cution du code\n\nJe d\u00e9cide d'ex\u00e9cuter cette partie du code depuis **JupyterHub h\u00e9berg\u00e9 sur notre cluster EMR**.<br />\nPour ne pas alourdir inutilement les explications du **notebook**, je ne r\u00e9expliquerai pas les \u00e9tapes communes <br />\nque nous avons d\u00e9j\u00e0 vues dans la premi\u00e8re partie o\u00f9 l'on a ex\u00e9cut\u00e9 le code localement sur notre machine virtuelle Ubuntu.\n\n<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n\n**En utilisant ce kernel, une session spark est cr\u00e9\u00e9 \u00e0 l'ex\u00e9cution de la premi\u00e8re cellule**. <br />\nIl n'est donc **plus n\u00e9cessaire d'ex\u00e9cuter le code \"spark = (SparkSession ...\"** comme lors <br />\nde l'ex\u00e9cution de notre notebook en local sur notre VM Ubuntu."}, {"metadata": {}, "id": "4e759c1e", "cell_type": "markdown", "source": "### 4.10.1 D\u00e9marrage de la session Spark"}, {"metadata": {"trusted": false}, "id": "e5f0fbe1", "cell_type": "code", "source": "# L'ex\u00e9cution de cette cellule d\u00e9marre l'application Spark", "execution_count": 22, "outputs": [{"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "", "version_major": 2, "version_minor": 0}, "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026"}, "metadata": {}, "output_type": "display_data"}]}, {"metadata": {}, "id": "3aba202f", "cell_type": "markdown", "source": "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"}, {"metadata": {"trusted": true}, "id": "fb788991", "cell_type": "code", "source": "%%info", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'hadoop', 'kind': 'pyspark'}</tt><br>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>24</td><td>application_1760655022197_0027</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-45-20.eu-west-3.compute.internal:20888/proxy/application_1760655022197_0027/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-40-68.eu-west-3.compute.internal:8042/node/containerlogs/container_1760655022197_0027_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}]}, {"metadata": {}, "id": "27ac9832", "cell_type": "markdown", "source": "### 4.10.2 Installation des packages\n\nLes packages n\u00e9cessaires ont \u00e9t\u00e9 install\u00e9 via l'\u00e9tape de **bootstrap** \u00e0 l'instanciation du serveur.\n\n### 4.10.3 Import des librairies"}, {"metadata": {"trusted": true}, "id": "49a61b3c", "cell_type": "code", "source": "import os\nos.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\nos.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "ad562eab", "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport io\nimport os\nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras import Model\nfrom pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {}, "id": "83663cbd", "cell_type": "markdown", "source": "### 4.10.4 D\u00e9finition des PATH pour charger les images et enregistrer les r\u00e9sultats\n\nNous acc\u00e9dons directement \u00e0 nos **donn\u00e9es sur S3** comme si elles \u00e9taient **stock\u00e9es localement**."}, {"metadata": {"trusted": true}, "id": "46be859d", "cell_type": "code", "source": "# Chemin du bucket\nPATH = 's3a://p8-data-djamel/jupyter/hadoop/data'\n\n# Chemin des donn\u00e9es et des r\u00e9sultats\nPATH_Data = PATH + '/Test1'\nPATH_Result = PATH + '/Results'\nPATH_Result_PCA = PATH + '/Results_PCA'\n\n# Affichage pour v\u00e9rification\nprint('PATH:        ' + PATH + \n      '\\nPATH_Data:   ' + PATH_Data + \n      '\\nPATH_Result: ' + PATH_Result+\n      '\\nPATH_Result_PCA: ' + PATH_Result_PCA)\n", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "PATH:        s3a://p8-data-djamel/jupyter/hadoop/data\nPATH_Data:   s3a://p8-data-djamel/jupyter/hadoop/data/Test1\nPATH_Result: s3a://p8-data-djamel/jupyter/hadoop/data/Results\nPATH_Result_PCA: s3a://p8-data-djamel/jupyter/hadoop/data/Results_PCA", "name": "stdout"}]}, {"metadata": {}, "id": "cf883c20", "cell_type": "markdown", "source": "### 4.10.5 Traitement des donn\u00e9es"}, {"metadata": {}, "id": "2ffe93f5", "cell_type": "markdown", "source": "#### 4.10.5.1 Chargement des donn\u00e9es"}, {"metadata": {"trusted": true}, "id": "7e4b319a", "cell_type": "code", "source": "images = spark.read.format(\"binaryFile\") \\\n  .option(\"pathGlobFilter\", \"*.jpg\") \\\n  .option(\"recursiveFileLookup\", \"true\") \\\n  .load(PATH_Data)", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "16bfeb4d", "cell_type": "code", "source": "images.show(5)", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+--------------------+-------------------+------+--------------------+\n|                path|   modificationTime|length|             content|\n+--------------------+-------------------+------+--------------------+\n|s3a://p8-data-dja...|2025-10-17 22:49:14|  7353|[FF D8 FF E0 00 1...|\n|s3a://p8-data-dja...|2025-10-17 22:49:14|  7350|[FF D8 FF E0 00 1...|\n|s3a://p8-data-dja...|2025-10-17 22:49:14|  7349|[FF D8 FF E0 00 1...|\n|s3a://p8-data-dja...|2025-10-17 22:49:14|  7348|[FF D8 FF E0 00 1...|\n|s3a://p8-data-dja...|2025-10-17 22:49:14|  7328|[FF D8 FF E0 00 1...|\n+--------------------+-------------------+------+--------------------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {}, "id": "8b32ac34", "cell_type": "markdown", "source": "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n    une colonne contenant les **labels** de chaque image</u> :"}, {"metadata": {"trusted": true}, "id": "a52ab808", "cell_type": "code", "source": "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\nprint(images.printSchema())\nprint(images.select('path','label').show(5,False))", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\nNone\n+-----------------------------------------------------------------------+----------+\n|path                                                                   |label     |\n+-----------------------------------------------------------------------+----------+\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_106_100.jpg|Watermelon|\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_109_100.jpg|Watermelon|\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_108_100.jpg|Watermelon|\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_107_100.jpg|Watermelon|\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_95_100.jpg |Watermelon|\n+-----------------------------------------------------------------------+----------+\nonly showing top 5 rows\n\nNone", "name": "stdout"}]}, {"metadata": {}, "id": "8f15b199", "cell_type": "markdown", "source": "#### 4.10.5.2 Pr\u00e9paration du mod\u00e8le"}, {"metadata": {"trusted": true}, "id": "ec7c7165", "cell_type": "code", "source": "model = MobileNetV2(weights='imagenet',\n                    include_top=True,\n                    input_shape=(224, 224, 3))", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "1b9bc650", "cell_type": "code", "source": "new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "a0d497f2", "cell_type": "code", "source": "brodcast_weights = sc.broadcast(new_model.get_weights())", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "1bc0bf14", "cell_type": "code", "source": "new_model.summary()", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \n__________________________________________________________________________________________________\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n__________________________________________________________________________________________________\nConv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n__________________________________________________________________________________________________\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n__________________________________________________________________________________________________\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n__________________________________________________________________________________________________\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n__________________________________________________________________________________________________\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n__________________________________________________________________________________________________\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n__________________________________________________________________________________________________\nblock_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n__________________________________________________________________________________________________\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n__________________________________________________________________________________________________\nblock_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n                                                                 block_2_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n__________________________________________________________________________________________________\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n__________________________________________________________________________________________________\nblock_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n__________________________________________________________________________________________________\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n__________________________________________________________________________________________________\nblock_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n                                                                 block_4_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n__________________________________________________________________________________________________\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n__________________________________________________________________________________________________\nblock_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n__________________________________________________________________________________________________\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n                                                                 block_5_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n__________________________________________________________________________________________________\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n__________________________________________________________________________________________________\nblock_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n__________________________________________________________________________________________________\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n__________________________________________________________________________________________________\nblock_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n                                                                 block_7_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n__________________________________________________________________________________________________\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n__________________________________________________________________________________________________\nblock_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n__________________________________________________________________________________________________\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n                                                                 block_8_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n__________________________________________________________________________________________________\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n__________________________________________________________________________________________________\nblock_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n__________________________________________________________________________________________________\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n                                                                 block_9_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n__________________________________________________________________________________________________\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n__________________________________________________________________________________________________\nblock_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n__________________________________________________________________________________________________\nblock_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n==================================================================================================\nTotal params: 2,257,984\nTrainable params: 2,223,872\nNon-trainable params: 34,112\n__________________________________________________________________________________________________", "name": "stdout"}]}, {"metadata": {"trusted": true}, "id": "be8fe2b9", "cell_type": "code", "source": "def model_fn():\n    \"\"\"\n    Returns a MobileNetV2 model with top layer removed \n    and broadcasted pretrained weights.\n    \"\"\"\n    model = MobileNetV2(weights='imagenet',\n                        include_top=True,\n                        input_shape=(224, 224, 3))\n    for layer in model.layers:\n        layer.trainable = False\n    new_model = Model(inputs=model.input,\n                  outputs=model.layers[-2].output)\n    new_model.set_weights(brodcast_weights.value)\n    return new_model", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {}, "id": "c032f135", "cell_type": "markdown", "source": "xm#### 4.10.5.3 D\u00e9finition du processus de chargement des images <br/> et application de leur featurisation \u00e0 travers l'utilisation de pandas UDF"}, {"metadata": {"trusted": true}, "id": "32b100d8", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "id": "7941dfb3", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "trusted": true}, "id": "933100cf", "cell_type": "code", "source": "def preprocess(content):\n    \"\"\"\n    Preprocess raw image bytes for prediction.\n    \"\"\"\n    img = Image.open(io.BytesIO(content)).resize([224, 224])\n    arr = img_to_array(img)\n    return preprocess_input(arr)\n\n\ndef featurize_series(model, content_series):\n    \"\"\"\n    Featurize a pandas Series of raw images using the input model.\n    :return: a pandas Series of image features\n    \"\"\"\n    input = np.stack(content_series.map(preprocess))\n    preds = model.predict(input)\n    # Flatten feature tensors to 1D vectors for Spark compatibility\n    output = [p.flatten() for p in preds]\n    return pd.Series(output)\n\n\n@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\ndef featurize_udf(content_series_iter):\n    \"\"\"\n    A Scalar Iterator pandas UDF wrapping the featurization function.\n    Loads the model once and applies it to multiple data batches.\n    \"\"\"\n    model = model_fn()  # load model once (e.g., MobileNetV2)\n    for content_series in content_series_iter:\n        yield featurize_series(model, content_series)\n", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/pandas/functions.py:392: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.", "name": "stdout"}]}, {"metadata": {}, "id": "f23206e8", "cell_type": "markdown", "source": "#### 4.10.5.4 Ex\u00e9cutions des actions d'extractions de features"}, {"metadata": {"trusted": true}, "id": "22d760c2", "cell_type": "code", "source": "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "5e07fd68", "cell_type": "code", "source": "features_df = images.repartition(24).select(col(\"path\"),\n                                            col(\"label\"),\n                                            featurize_udf(\"content\").alias(\"features\")\n                                           )", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "06a930b3", "cell_type": "code", "source": "print(PATH_Result)", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "s3a://p8-data-djamel/jupyter/hadoop/data/Results", "name": "stdout"}]}, {"metadata": {"trusted": false}, "id": "378a836d", "cell_type": "code", "source": "import time\n\n# D\u00e9but du chronom\u00e8tre\nstart_time = time.time()\n\n# \u00c9criture du DataFrame en Parquet\nfeatures_df.write.mode(\"overwrite\").parquet(PATH_Result)\n\n# Fin du chronom\u00e8tre\nend_time = time.time()\n\n# Calcul du temps \u00e9coul\u00e9\nelapsed_time = end_time - start_time\nprint(f\"Temps d'ex\u00e9cution de l'\u00e9criture Parquet : {elapsed_time:.2f} secondes\")\n", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Temps d'ex\u00e9cution de l'\u00e9criture Parquet : 290.09 secondes", "name": "stdout"}]}, {"metadata": {}, "cell_type": "raw", "source": "from pyspark.ml.functions import array_to_vector\nfrom pyspark.ml.feature import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Conversion du tableau en vecteur Spark\nfeatures_vector_df = features_df.withColumn(\"features\", array_to_vector(\"features\"))\n\n# \u00c9tape 1\ufe0f\u20e3 : entra\u00eenement PCA sur un grand nombre de composantes\n# Ici on fixe un k \u00e9lev\u00e9 (ex : 100) pour analyser la variance cumul\u00e9e\npca_full = PCA(k=40, inputCol=\"features\", outputCol=\"pcaFeatures\")\npca_model_full = pca_full.fit(features_vector_df)\n\n# \u00c9tape 2\ufe0f\u20e3 : r\u00e9cup\u00e9ration de la variance expliqu\u00e9e\nexplained_variance = np.array(pca_model_full.explainedVariance.toArray())\n"}, {"metadata": {}, "cell_type": "raw", "source": "for i, v in enumerate(explained_variance[:15], start=1):\n    print(f\"Composante {i}: {v*100:.2f}% de variance\")\n"}, {"metadata": {"trusted": false}, "id": "5a6f4a59", "cell_type": "code", "source": "from pyspark.ml.functions import array_to_vector\nfrom pyspark.ml.feature import PCA\nimport time\n\n# Mesure du temps total\nt0_total = time.time()\n\n# 1\ufe0f\u20e3 Conversion de la colonne \"features\" (array<float>) en vecteur MLlib\nfeatures_vector_df = features_df.withColumn(\"features\", array_to_vector(\"features\"))\n\n# V\u00e9rifions le sch\u00e9ma\nfeatures_vector_df.printSchema()\n\n# 2\ufe0f\u20e3 D\u00e9finir le mod\u00e8le PCA\npca = PCA(k=15, inputCol=\"features\", outputCol=\"pcaFeatures\")\n\n# 3\ufe0f\u20e3 Entra\u00eener le mod\u00e8le PCA\npca_model = pca.fit(features_vector_df)\n\n# 4\ufe0f\u20e3 Transformer les donn\u00e9es\ndf_pca = pca_model.transform(features_vector_df)\n\n# 5\ufe0f\u20e3 V\u00e9rification du r\u00e9sultat\ndf_pca.select(\"label\", \"pcaFeatures\").show(5, truncate=False)\n\n# 6\ufe0f\u20e3 Mesure du temps d\u2019\u00e9criture Parquet\nt0_write = time.time()\ndf_pca.write.mode(\"overwrite\").parquet(PATH_Result_PCA)\nt1_write = time.time()\n\n# 7\ufe0f\u20e3 Calcul des dur\u00e9es\nt1_total = time.time()\nwrite_time = t1_write - t0_write\ntotal_time = t1_total - t0_total\n\n# 8\ufe0f\u20e3 R\u00e9sultats\nprint(f\"\u2705 R\u00e9duction de dimension PCA termin\u00e9e et sauvegard\u00e9e dans : {PATH_Result_PCA}\")\nprint(f\"\u23f1\ufe0f Temps d'\u00e9criture Parquet : {write_time:.2f} secondes\")\nprint(f\"\ud83d\udd52 Temps total du script (PCA + \u00e9criture) : {total_time:.2f} secondes\")\n", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- label: string (nullable = true)\n |-- features: vector (nullable = true)\n\n+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|label         |pcaFeatures                                                                                                                                                                                                                                                                                       |\n+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|Watermelon    |[-2.49120588276131,3.266504005175197,-5.938666739962395,-3.445156726423453,7.723911613982808,3.9186541053864645,1.1355998054773735,1.52377627959652,-8.653507984718113,2.0315513845565905,-3.9795308951181867,0.9090998768326705,-1.3036325536071607,5.034942037472479,2.2861172299684878]        |\n|Pineapple Mini|[-5.573069563524853,3.0685097283790457,1.1482152290887455,-4.848734823196476,-3.5478279005657316,3.1048024574369038,1.4757194961130748,-0.7376465093564185,-9.900173731306584,4.5363601639289906,-3.356643106948406,1.5331945574955579,0.7454305437122242,-4.314449083450975,-3.3758916775986076] |\n|Cauliflower   |[-3.8691150664634577,2.0796112452411264,2.0848201554892256,-2.601644304919722,-3.4164113814879467,2.315963606584777,-0.727320764749438,1.5814310925566095,-1.9699532648144258,2.987484478702245,-5.315908626900185,1.418946007316179,1.0744015787783618,-3.6039220354888566,0.9072445390063494]   |\n|Cauliflower   |[-4.316437278750687,3.2076347031305463,0.41090941440481654,-2.9500711010456833,-3.783265948875256,4.014821083199644,-0.5901651618853926,3.1171409255762343,-2.140948073134023,2.949888513683378,-5.676046095162067,1.9755610392974674,3.1147117740775756,-2.6353988881138823,-0.35194603416044473]|\n|Pineapple     |[-5.215521359841994,5.66422126554102,0.8794791153786501,-3.534723540208319,-3.9303098079264704,1.324219588501732,0.4282338718045482,0.4999960974906096,-6.676128572474377,4.827889603677068,-6.798696924318403,1.1958238106897574,1.067169090123532,-4.751934204047615,-5.494817675095042]        |\n+--------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n\u2705 R\u00e9duction de dimension PCA termin\u00e9e et sauvegard\u00e9e dans : s3a://p8-data-djamel/jupyter/hadoop/data/Results_PCA\n\u23f1\ufe0f Temps d'\u00e9criture Parquet : 300.58 secondes\n\ud83d\udd52 Temps total du script (PCA + \u00e9criture) : 1392.94 secondes", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "id": "558aa5b2", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "1fe01b72", "cell_type": "markdown", "source": "### 4.10.6 Chargement des donn\u00e9es enregistr\u00e9es et validation du r\u00e9sultat"}, {"metadata": {"trusted": true}, "id": "2d314e61", "cell_type": "code", "source": "PATH_Result = \"s3a://p8-data-djamel/jupyter/hadoop/data/Results/\"\n\ndf = spark.read.parquet(PATH_Result, engine='pysparrow')\n", "execution_count": 20, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "PATH_Result = \"s3a://p8-data-djamel/jupyter/hadoop/data/Results/\"\ndf = spark.read.parquet(PATH_Result)\ndf.printSchema()\ndf.show(5, truncate=False)\n", "execution_count": 21, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "root\n |-- path: string (nullable = true)\n |-- label: string (nullable = true)\n |-- features: array (nullable = true)\n |    |-- element: float (containsNull = true)\n\n+-------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|path                                                                     |label         |features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n+-------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_104_100.jpg  |Watermelon    |[0.18860275, 0.35067454, 0.06652759, 0.0, 0.64708406, 0.086963564, 0.15536618, 0.91209006, 0.0, 0.0, 1.1872078, 0.3226737, 0.018724443, 0.0, 0.042194095, 0.39726838, 0.0, 0.0, 0.0, 0.44304568, 0.0, 0.05283413, 0.0, 0.0, 0.035101544, 0.7966696, 1.4184748, 0.0, 0.0, 1.9026569, 0.0, 0.0, 0.13683996, 0.3491295, 0.0, 0.16854462, 0.30362502, 1.7479804, 0.048970655, 0.0, 0.015576453, 0.0, 0.91876173, 0.16272576, 0.31893468, 0.0, 0.47098163, 0.20162284, 1.6303529, 0.009996396, 0.0, 0.0, 0.04909752, 0.0, 0.89470613, 1.6532434, 0.0, 1.2668737, 0.0, 0.005108189, 0.3048966, 0.0153817125, 0.0, 0.0, 1.3083223, 2.4649832, 1.7693584, 0.053403564, 0.010496594, 0.008338833, 0.0, 0.040953472, 0.0, 0.7510549, 0.76305467, 1.5488753, 0.08774639, 0.15404382, 0.0, 0.0, 0.0, 0.6082489, 0.10375076, 9.0637227E-4, 0.0, 0.0, 0.041977037, 0.8837576, 1.3686955, 3.1628542, 0.4656882, 0.0, 0.0, 0.0, 1.173883, 0.2860091, 0.4244447, 0.0, 1.3722844, 0.0, 0.2104465, 0.33644134, 0.00513973, 0.0, 0.84988844, 0.10613863, 0.0, 0.1872014, 0.020695604, 0.04723331, 0.0, 0.0, 0.016028158, 0.6937306, 0.0012192699, 1.4071585, 1.2390158, 0.15445413, 0.0, 0.5670969, 0.6551061, 0.010019733, 0.09454962, 0.4512857, 0.0, 1.2326326, 1.2978764, 2.1844435, 2.51691, 0.1285062, 0.0, 2.7823875, 0.11332219, 0.0, 1.1220789, 0.0, 0.5266951, 0.062136408, 0.8303406, 1.2865838, 0.77637076, 0.0082276715, 0.3189334, 0.32338235, 0.0, 0.14851, 0.0, 0.7108946, 0.0596567, 0.56151783, 0.022301324, 0.0, 0.3526964, 0.0, 0.36663637, 1.2391903, 0.0076626963, 2.6190697E-4, 0.47963032, 0.51522475, 0.0, 0.026631458, 0.0, 0.24233511, 1.1855321, 2.1371734, 1.2755095, 1.0157759, 1.0955024, 0.22124939, 0.09128376, 0.0, 0.055413757, 0.009472423, 0.0, 0.6109292, 0.15352932, 0.5137229, 0.006234874, 0.6790155, 2.5118806, 0.29928663, 0.038338218, 0.0, 0.9906536, 1.3518151, 0.9892907, 0.0, 0.0, 0.23469105, 0.0463494, 1.0531847, 0.031096505, 1.9110092, 0.09800791, 0.0, 0.0, 0.0, 0.060673635, 0.16453929, 0.7163865, 0.046675224, 0.0, 0.41702184, 1.0440965, 0.0034843714, 0.0, 0.0, 0.0, 1.0266879, 0.0, 0.0, 0.21355546, 0.03682649, 0.0, 0.9350901, 0.0061862404, 0.026416883, 0.44469398, 0.0, 0.8191946, 0.0204782, 0.0, 0.26972157, 0.0, 0.0, 0.03441405, 0.0, 1.6733149, 0.36297482, 0.16260529, 0.24128091, 0.8413727, 0.30181104, 0.1955567, 0.26834807, 0.039803647, 0.052205876, 0.17132802, 0.9752822, 1.7078308, 0.35847571, 5.8809237E-4, 0.0, 1.6724852, 0.12787169, 2.1786087, 0.0, 1.4364539, 0.23354882, 1.5380026, 0.0, 0.4112202, 2.3857549E-4, 0.8902254, 3.0276234, 3.2001688, 0.45642635, 0.27744272, 1.1793036, 0.0, 0.5673877, 0.13352501, 0.5506843, 0.0, 8.9425774E-4, 0.0, 0.0, 0.0, 0.15086748, 0.0054865973, 0.0031715701, 1.344139, 0.35211512, 0.22546133, 0.52066225, 0.6365771, 0.0, 0.024806071, 0.0, 0.2850287, 0.0, 0.18276586, 0.6953855, 0.91823125, 0.64953756, 0.0, 0.09106703, 0.69568026, 0.0, 0.7170332, 0.047948293, 0.0, 0.0, 0.0, 0.66668683, 0.0, 0.0, 0.03513339, 0.0, 0.0, 0.0, 0.14583063, 0.04570439, 0.0525297, 0.0, 0.0, 0.13782382, 0.0, 0.37293103, 0.9726046, 0.359142, 0.0, 0.03295215, 1.4228673, 0.8010249, 0.0, 0.0, 0.0, 0.06569162, 0.44534022, 1.520112, 0.4961828, 0.5916789, 0.0, 0.0, 0.0, 0.019648427, 0.0, 0.06726529, 4.6103747E-4, 0.0, 0.629286, 2.0294142, 0.0, 0.84065855, 0.047436386, 0.0, 0.017928889, 1.4114547, 0.0, 0.0, 0.2658197, 0.079169855, 0.071969755, 0.9624553, 0.0, 0.0, 0.7352846, 0.4169832, 0.012253625, 0.1115268, 0.0, 1.5058715, 0.0, 0.028307771, 0.020641698, 0.062443666, 1.0258045, 0.068765566, 0.009281203, 2.2374296, 0.27672172, 1.9391797, 0.25824144, 0.0, 1.6106083, 0.051002093, 0.0, 0.0, 0.08178311, 0.0, 0.0, 0.00841951, 2.8840086, 0.0, 0.011073872, 0.9391289, 0.20196062, 0.0, 0.0, 0.16903444, 0.08002177, 0.0, 0.053891163, 0.0, 0.41799724, 0.0, 0.0, 0.7170039, 2.2924316, 0.04576133, 0.0, 0.0, 0.0, 0.015331287, 0.26271078, 0.035400927, 0.072950706, 0.059219442, 0.04684584, 1.6900735, 0.0, 0.0035910662, 0.0, 1.2735409, 0.031163523, 0.41341907, 0.8410191, 0.0334875, 2.5801787, 2.1467664, 0.0, 0.0514857, 0.47369966, 0.58654535, 0.0, 1.4325782, 0.50097954, 2.2501202, 0.54676557, 2.2826657, 0.53816926, 0.0, 0.046792343, 0.5375587, 0.27836204, 0.0, 0.0, 0.0, 0.6747503, 0.0022892603, 0.0, 0.0, 0.010466762, 0.18163766, 0.0356175, 0.14953226, 0.0, 0.045352966, 0.0, 0.0, 2.13509, 1.8920096, 1.6084656, 1.3017937, 0.31311977, 0.07941133, 0.0, 0.0, 0.5585496, 0.14441691, 0.50556666, 0.06979175, 1.8355464, 0.8659685, 0.0, 0.0, 0.27599624, 0.0, 1.1230348, 0.0, 0.0, 0.0, 1.4875429, 0.0, 2.218007, 0.0013354897, 2.363881, 0.2403529, 0.122980855, 0.0, 0.0, 0.98190767, 0.36773732, 0.22681126, 0.0061660768, 0.0, 0.0, 2.0834146, 0.0, 0.14097269, 0.0017679349, 0.1157566, 0.73066837, 0.11645008, 0.24134488, 1.4678994, 0.0, 1.2858497, 0.31073922, 0.03095122, 0.0, 2.3340256, 0.977312, 0.0, 0.6548616, 0.47111207, 0.2599545, 1.3917029, 0.0, 0.29207966, 0.0, 0.0, 0.0673962, 0.0, 0.0, 0.0, 0.0, 0.10084271, 0.7269369, 0.71289885, 0.17290826, 1.049369, 0.32312799, 0.7222618, 0.0, 0.07818221, 0.22066566, 0.22542551, 0.0, 1.968685, 0.0, 0.4638027, 0.117615886, 0.0, 0.30728412, 0.5132017, 1.8733363, 0.0, 0.0052771084, 2.2909288, 0.0, 0.11051905, 0.26959622, 0.09859912, 0.49248838, 1.2092844E-4, 0.18922347, 0.062971406, 0.039634347, 0.0, 1.1188483, 0.10802304, 0.29055405, 0.0, 0.0, 0.0973473, 0.17894734, 1.1162277, 1.0876293, 0.0, 0.0, 0.0, 0.14010412, 0.0, 0.8399586, 1.780473, 1.8555495, 2.3873808, 0.35327095, 0.0, 1.9959118, 0.0, 0.2463593, 0.10128317, 0.7448562, 0.19977343, 0.09590949, 0.0, 0.027678879, 1.0039712, 0.0, 0.16742527, 1.033622, 0.8427531, 0.020999964, 0.20926538, 0.0, 0.702868, 0.0, 0.0, 0.0, 0.0, 0.01925219, 0.010792284, 0.9152643, 0.0, 0.1642163, 0.09464757, 0.648538, 1.5029979, 0.08629108, 2.691204, 0.085045435, 0.0901224, 0.0, 1.613972, 0.11653791, 0.0, 0.5885406, 0.08604109, 0.86613435, 0.31694302, 0.0, 0.0, 0.3434701, 0.06784824, 0.43612123, 0.1613274, 1.5946991, 0.6197906, 0.052116074, 0.0, 2.969982, 0.83716685, 1.3910023, 0.6978477, 0.12427097, 0.0, 0.010922679, 1.5761112, 1.1301966, 0.39055008, 0.19982718, 0.0, 0.45951307, 0.0, 0.0, 0.0, 0.26911664, 0.14257497, 0.32357967, 0.0, 0.023282368, 0.8714958, 1.4652482, 1.7559805, 0.3380277, 1.6636124, 0.0, 0.5736366, 1.9748524, 0.6074936, 0.0, 1.6468095, 0.0, 0.0, 1.137251, 0.048081663, 0.08807118, 0.14512725, 0.0, 0.0064376704, 1.2707071, 0.13718143, 0.24273913, 0.019619646, 0.0, 0.0, 0.53648597, 0.44150645, 0.0, 0.0, 0.16047202, 0.55717474, 0.0, 0.0, 0.07298009, 0.6759313, 1.8692429, 0.20278808, 3.6185632, 2.3473, 0.24111828, 0.71522343, 0.15431187, 1.5043527, 0.0, 0.42054644, 0.20077612, 0.30427015, 0.045471463, 0.9846882, 0.0, 0.9981758, 0.31886214, 0.17502281, 1.2080542, 2.25848, 0.030941874, 0.09800082, 0.0, 0.0, 0.73543656, 0.0, 0.0, 0.6472228, 0.24470535, 0.017144727, 0.0, 0.6891769, 0.37774515, 0.0, 0.54818195, 0.0, 0.9736076, 0.040052846, 0.0, 0.0, 0.0, 1.1333014, 1.2968361, 0.0, 1.1116998, 0.27348068, 1.1055355, 0.41058236, 0.064733036, 1.729652, 0.50266105, 0.062431768, 1.0768265, 0.0, 1.1444342, 0.5709044, 1.5611368, 0.086108156, 1.1167785, 0.5362629, 0.002567173, 2.003937, 1.0204625, 0.0, 0.111683056, 0.027164033, 2.3204806, 0.0, 0.075530075, 0.0, 1.0773916, 0.43044233, 0.79032993, 0.14349736, 0.010794449, 0.055958763, 0.21480003, 0.8142557, 0.14399302, 0.0, 0.0, 0.0, 0.008873776, 1.2417483, 0.79752076, 0.0, 0.83335793, 0.103694335, 1.1226413, 0.022324365, 0.030076029, 0.0, 0.78528976, 9.889076E-4, 0.0, 1.0791721, 0.9028333, 0.26179343, 0.7982046, 0.0, 0.08672674, 0.0, 0.31300193, 0.9400447, 0.0, 2.4918525, 1.3858907, 0.0015832662, 0.03428902, 1.3574169, 0.0015943161, 0.06732616, 0.0, 0.04820628, 0.5370394, 0.12834491, 0.013316895, 0.07433172, 0.019102322, 0.0, 0.2128004, 1.1651961, 1.0466635, 0.16123666, 0.8229546, 0.806829, 0.0, 0.0, 0.0, 0.0, 0.4609852, 0.0, 0.049039792, 0.05571704, 0.31547776, 0.009685496, 0.33546087, 9.933389E-4, 0.008733896, 0.04776414, 0.63246924, 0.63938594, 0.1677011, 0.16952826, 0.09188105, 0.38072369, 0.0, 0.0, 0.43981004, 0.5699546, 0.44342685, 0.0023093454, 0.0, 0.27442285, 0.6551631, 2.3841143, 0.0, 3.4845722, 0.029696602, 0.21619345, 0.8721219, 0.026705256, 0.0, 0.0, 0.0, 0.032929312, 0.6659805, 0.0, 0.7226234, 0.017285503, 0.012313505, 0.0, 0.07078606, 2.1361172, 0.45105645, 0.013157837, 0.0, 0.40135205, 0.18588187, 0.0, 0.0, 2.477521, 0.27485824, 0.08816205, 0.016116098, 0.025787832, 0.99606454, 0.00622664, 0.0, 0.0, 1.1137757, 0.011691347, 0.01707699, 0.45520577, 0.048409544, 0.0, 0.24868082, 0.0, 0.13288634, 0.5570855, 0.00752869, 0.0, 0.16759537, 0.0, 0.0, 0.0, 0.0, 0.79944515, 0.028174017, 2.0567746, 0.0, 0.0, 1.1106303, 0.9385847, 0.24830572, 0.091646254, 1.2724081, 0.0, 0.1201077, 0.0, 0.12582435, 0.0, 0.071137734, 0.12111571, 0.024620205, 0.0, 0.2189872, 0.0708622, 0.0, 0.0, 0.03034092, 1.3232386, 0.49403492, 0.0, 0.38865012, 0.25784788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026747577, 0.0052049058, 0.0, 0.0, 0.0, 0.0, 0.07643304, 0.049984187, 0.0, 0.0, 0.0089048315, 0.79700696, 0.0, 0.0, 1.0509573, 0.16951026, 0.0, 0.0, 0.0, 0.0, 0.0058867917, 0.08206799, 0.6597719, 0.0, 0.054245982, 0.2348201, 0.5388212, 0.013745196, 0.92534286, 0.0, 0.58122265, 0.0, 0.42008263, 1.4196196, 1.3160812, 3.3058908, 0.10032931, 0.40773714, 0.0, 0.22563624, 0.025948128, 0.15381108, 0.0, 0.0, 0.029058661, 0.7905716, 0.0, 0.470217, 0.29257596, 0.054092474, 0.0, 0.0, 0.0, 0.95832694, 0.0, 0.014188559, 0.7109337, 0.0, 1.7416975, 0.02244065, 2.128699, 1.5867755, 3.0088408, 0.04100692, 0.2443554, 1.8591361, 0.54631984, 0.0, 0.72098076, 0.11798866, 0.4884684, 0.8989739, 0.0058958298, 0.5421711, 0.17515767, 0.087608516, 0.0, 0.0, 0.0, 0.013566416, 0.07420263, 0.0, 0.58736527, 0.64272064, 0.01553119, 1.2367654, 0.055506997, 0.0063982364, 0.7814839, 0.058961738, 0.5232268, 0.0, 0.21092142, 0.23166294, 1.9271221, 0.031136353, 0.0, 0.0, 0.16761553, 0.116907336, 0.0, 0.0, 1.8799647, 0.1611798, 0.040376984, 1.1037283, 0.9625173, 0.4938932, 0.095417745, 0.0, 0.49557447, 1.7128508, 0.057364125, 0.336677, 0.0, 0.0012904664, 0.009162417, 1.2315785, 0.57811016, 0.09154806, 0.0, 1.65195, 0.54879034, 0.78540343, 0.017313264, 0.0, 0.05353878, 1.3259628, 1.3490673, 0.69835234, 0.0, 0.29675928, 0.20056666, 0.059297875, 0.062002487, 0.0, 1.8892633, 0.0, 0.15516661, 0.0077750715, 0.0134305265, 0.93173975, 0.781563, 1.1873335, 0.6818453, 1.6972942, 2.3918574, 0.20376275, 0.0, 0.8717428, 0.0, 1.3299463, 0.23528296, 0.011621599, 0.0, 0.36127943, 0.0, 1.4237888, 0.11913973, 0.38122493, 0.84080535, 0.0, 0.376961, 0.23454821, 0.8122755, 0.0, 1.5606416, 0.14089409, 0.0, 0.46397734, 0.0, 0.1719782, 0.003594443, 0.52582484, 0.13689308, 0.0, 0.6179642, 0.35375333, 0.10538109, 0.0, 0.2746513, 0.058661956, 1.3853225, 0.018942453, 0.0, 0.27329972, 0.46358657, 0.21075225, 0.23921491, 8.646215E-4, 0.47761765, 0.75759816, 0.03593806, 0.19403885, 0.0, 1.2272284, 0.010226342, 0.0, 0.0, 0.11498784, 0.14380333, 0.010224863, 0.45858806, 0.17675477, 0.17270897, 0.24169761, 0.6047678, 0.29947215, 0.0, 0.13507693, 0.0, 0.0, 0.04769252, 0.41075414, 0.025913317, 0.77440417, 0.03569507, 0.459925, 0.8330048, 1.8641474, 0.0, 0.21997821, 0.124644086, 3.4598541, 0.0, 1.7700939, 1.0902721, 0.013166788, 0.0, 0.0, 0.38197818, 0.48948362, 0.096523724, 0.0, 0.88084817, 0.025961732, 0.0, 0.0, 0.022271393, 1.5077429, 0.41698655, 0.559237, 0.15588793, 1.1897231, 0.0, 1.0800439, 0.0, 1.5406901, 0.02518306, 2.060219, 0.027862968, 0.091167726, 0.016085591, 0.0, 0.31277004, 0.122699, 0.095275335, 0.0, 0.0, 0.0, 0.0, 1.6253762, 0.0, 0.0, 1.3756293, 0.16066745, 0.7971398, 0.5248084, 0.0, 0.025311707, 0.15399401, 1.1030703, 0.0, 0.83545476, 0.2296833, 0.0, 2.1830935, 0.1859293, 1.6060888, 0.4681675, 0.13971286, 0.31148443, 0.17997743, 0.03965463, 1.3660583, 0.027291996, 0.45073214, 0.41580087, 1.9513984, 0.31619075, 1.0913105, 0.38874477, 0.24323697, 1.2025099, 0.0, 0.0, 0.59300023, 0.13997906, 0.055102717, 0.42766815, 0.21471463, 0.0, 0.3372087, 0.023558125, 0.0, 0.1226895, 0.0, 0.7174275, 0.08863688, 0.0, 0.77714306, 0.4343585, 0.0, 0.59494317, 1.4624004, 0.42508492, 0.18546852, 2.5850046, 0.0, 0.33837152, 0.40405113, 0.0060515776, 0.0, 1.463094, 0.6996786, 0.0690641, 0.43203774, 0.0, 0.78414744, 0.17743777, 0.033376668, 0.3293021, 0.10326909, 0.0, 0.015223129, 0.0, 0.16587798, 0.93682575, 0.0, 0.0, 0.10455225, 0.0, 0.59684336, 0.013749366, 0.008756952, 0.27412894, 0.024755891, 0.41315675, 0.054543894, 0.0, 0.0, 0.0, 0.5823159, 0.58956677, 0.02081541, 0.08226528, 0.0, 0.14998582, 0.67472005, 0.08389563, 0.0, 0.14357111, 0.9545806, 0.81002766, 0.2762206, 0.0, 0.41760588, 0.36168057, 0.0]|\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Pineapple Mini/306_100.jpg|Pineapple Mini|[0.0, 4.519898, 0.0, 0.0, 0.0, 0.0, 0.32750982, 0.0, 0.0, 0.17494838, 0.0, 0.0, 1.0715562, 0.36303872, 0.0, 0.0, 0.0, 0.05326088, 0.0, 1.1264638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3061794, 0.1002091, 0.29003832, 0.0, 0.0, 0.0, 0.01009849, 3.4061677, 0.0, 0.45659757, 0.45732626, 0.30560482, 0.060856957, 0.006627169, 0.0, 0.0, 0.0, 0.0, 0.91287285, 0.0, 1.3753402, 0.750732, 1.0006154, 0.65338916, 0.33365977, 0.0, 0.0, 0.0, 0.3663179, 1.3029355, 0.0, 0.030598592, 0.6736371, 0.0, 0.08172019, 0.31700647, 0.093837954, 0.6711966, 1.4214174, 4.2893178E-5, 0.0, 0.071887136, 0.13227056, 0.039969403, 0.0, 1.6274551, 0.0, 2.5856404, 1.0756924, 1.71889, 0.4192711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14452177, 0.09392536, 0.0, 0.0, 0.0, 0.017518774, 1.9486568, 0.0, 0.047302805, 0.53447753, 0.02022137, 2.5442526, 0.016151015, 0.0, 0.029665357, 0.0, 0.3107105, 1.253332, 0.28068203, 0.0, 0.0, 0.77025735, 0.0, 0.8352429, 1.8649298, 0.0, 0.01579964, 0.0, 0.020290827, 0.98120177, 1.207783, 0.26055443, 0.0, 0.75835794, 0.019138379, 0.25950754, 0.17669874, 0.0, 0.0, 0.0, 0.031095529, 0.0, 0.0, 0.20039527, 1.8222599, 0.6035293, 0.119700916, 0.33104387, 0.0, 0.8309524, 0.0, 0.58687276, 0.0, 0.0, 0.0, 1.7410889, 0.004302991, 0.0, 0.03529153, 0.0058283187, 0.12142627, 0.0, 0.5077715, 0.10027652, 0.0, 0.0424073, 0.0, 0.0, 0.017881647, 1.5819032, 0.0, 0.06616566, 2.1444461, 0.003454657, 0.054609425, 2.7677696, 0.1951668, 0.0019583239, 2.5281124, 0.0, 0.0, 0.35433578, 0.28380182, 0.0, 2.1273859, 0.0, 0.0, 0.0, 0.0, 1.6314946, 0.0, 0.0, 0.012582806, 1.1870722, 0.0, 0.0, 0.0, 0.022486068, 0.0, 0.9327919, 0.62428916, 0.484322, 0.0016837275, 0.037596516, 2.079641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12626049, 0.059690416, 0.0, 0.0, 0.0, 0.0, 1.7700744, 0.06549911, 0.13434917, 0.0134244235, 0.0, 0.0, 0.0, 0.011089634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.063619435, 0.0, 0.057620466, 0.18299673, 0.14487197, 4.979578E-5, 1.6035028, 0.0, 0.14578405, 0.0, 0.13757317, 0.02827925, 0.13028628, 0.0, 2.9857998, 0.21710509, 0.3118101, 0.36732447, 1.9774405, 0.0, 0.0, 0.31042916, 0.0, 0.0, 1.7352709, 0.0, 0.0, 0.15972212, 0.0, 1.2505121, 0.0, 0.4141604, 0.0, 0.0715255, 1.068411, 0.076709606, 0.0, 0.029618803, 0.0, 0.0, 0.0055717714, 2.331074, 0.9918659, 2.3063416, 0.0, 0.039530776, 2.1931088, 0.24609381, 0.0, 0.15236062, 0.0, 0.090570666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04760321, 1.1857606, 0.1254619, 0.008925222, 0.0, 3.4470263, 0.06825834, 0.21448779, 0.056734614, 0.44874635, 0.0, 0.0, 0.0, 0.04229018, 0.040744983, 5.081321E-4, 2.1127093, 0.0, 0.03322712, 0.1633169, 0.20698142, 0.0, 0.05255142, 0.032283302, 1.2243501, 0.0, 0.03457958, 0.013743115, 0.12729993, 0.0, 0.16390032, 0.0, 0.21832754, 0.5096423, 0.0, 0.0, 0.0, 1.3155594, 0.09683024, 0.3987531, 0.0, 0.0, 0.8510999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49012718, 0.009110652, 0.02079743, 0.0, 0.24696478, 0.0, 8.67422E-5, 0.57815504, 1.61509, 0.0, 0.04092712, 0.12794547, 0.34364092, 0.0, 1.4007239, 0.0, 0.0, 0.0, 0.0, 0.7087033, 0.02434478, 3.8630526, 2.0311248, 0.080432184, 0.49349344, 0.0, 0.0, 0.5703642, 0.0, 0.0, 0.05087331, 0.0, 0.9196239, 0.0, 0.045666978, 0.005627771, 0.006617109, 0.061984852, 0.02962377, 0.0, 0.0, 0.13457252, 0.3959956, 0.0, 0.10327479, 0.0, 0.033043638, 0.30242375, 0.0, 0.015105791, 0.0, 0.0, 1.2191045, 0.12164145, 0.7066525, 0.042382214, 3.3314686, 0.0, 0.0, 0.0, 0.0, 0.23252937, 0.0, 0.21076426, 0.0, 0.04226614, 0.0, 0.0, 0.0, 1.2505777, 1.3216413E-4, 0.0, 0.010718862, 0.0, 0.19109976, 0.017288102, 0.13253224, 0.0, 0.0, 0.0, 0.20188919, 0.0, 1.4361484, 0.0, 0.33936235, 0.0, 0.0, 1.3187073, 0.0, 0.0, 0.64549035, 0.039343797, 0.8400993, 0.0062204334, 0.0013004483, 0.1903343, 0.27224874, 0.69943434, 0.3068086, 0.0, 3.230162, 0.010887421, 0.007203214, 0.006608973, 0.17202388, 0.8010575, 0.0, 0.0, 0.100981645, 0.27578235, 0.0, 0.002521813, 0.0, 0.0, 2.1001003, 0.34803495, 0.037693463, 0.0, 0.7096922, 0.13531849, 0.42589378, 2.0571954, 0.36680233, 0.0, 1.8586193, 0.0, 0.06417069, 0.0, 0.0, 0.0, 0.6440097, 0.009186037, 0.0, 0.0, 0.030250004, 0.2172198, 0.0, 0.0, 0.063808344, 2.4768276, 0.0, 0.056823798, 1.1588899, 0.7614965, 0.4529229, 0.24455464, 0.0, 0.12038192, 0.7624398, 0.08319499, 0.0, 0.0, 3.6444073, 0.44169715, 0.0, 3.0941129, 0.0, 0.0, 0.15876056, 0.0, 0.22005025, 0.0, 0.0, 0.4031392, 0.0, 0.49689123, 0.6359941, 0.3279357, 0.65571314, 0.09191299, 0.0, 0.0, 0.78074306, 1.7405305, 0.0, 1.5988499, 0.03182167, 0.0, 0.0, 0.06941525, 1.2841523, 0.008146623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03024032, 0.16689436, 0.06960962, 0.71298575, 0.1939143, 0.14379413, 0.48828292, 0.0, 0.0, 0.0, 0.0, 1.1886692, 0.0, 0.016858779, 0.0, 0.06255117, 0.0, 0.0, 0.46229693, 0.5559238, 0.51155317, 0.0, 0.14467438, 0.0, 0.0, 0.27531588, 0.5305987, 0.020032153, 0.0, 0.24349473, 0.0015266626, 0.0, 0.012121776, 0.0, 0.0, 0.0, 0.8380895, 1.3646969, 0.0, 0.0, 0.03973251, 0.0133443875, 0.19582868, 0.011948288, 0.0, 0.82985187, 0.0, 0.80916923, 0.9889526, 0.0, 0.023991127, 0.22030044, 0.17324011, 0.0, 0.20908992, 0.1036241, 0.17729197, 0.67100203, 0.0147745125, 0.038775824, 0.2108948, 0.0, 0.402781, 2.9070733, 0.0, 0.0, 0.23851751, 0.20915234, 0.0, 0.18473391, 0.0025683595, 1.1606668, 0.019064432, 0.0, 0.0, 0.0, 0.012396844, 0.0, 0.0042952723, 0.0, 0.51441264, 0.26877394, 0.0, 0.0, 2.3985648, 0.053336494, 0.0, 0.0027491066, 0.0, 0.0078673735, 0.05956601, 1.2900666, 0.0, 3.3602672, 1.1620958, 0.0, 0.0, 0.0, 0.47315708, 0.29009187, 0.0, 0.41255087, 0.21371226, 0.7008338, 0.0, 0.0, 0.31401327, 0.0, 0.7805723, 0.019623479, 0.0, 0.0, 0.14659788, 0.6122637, 1.3814468, 0.0, 0.3923416, 0.0, 0.0, 0.0, 0.0, 0.009605773, 2.1769638, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1372337, 2.2282922, 0.055729564, 0.0, 0.0, 0.15900229, 0.0, 0.0015559762, 0.0, 0.0, 0.0, 0.13261953, 0.0, 0.0, 0.018245779, 0.0, 0.0, 0.0, 0.07714474, 0.022080684, 0.0, 0.0, 0.061220344, 0.06963081, 0.010069329, 0.16003247, 0.0, 0.004903266, 0.0, 0.0047776354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3447394, 0.0, 0.0, 3.5747433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11610436, 0.0, 0.0, 0.0, 0.11035243, 0.05063928, 0.2922098, 0.013663762, 0.04343503, 0.0, 0.0, 0.0, 0.011272271, 2.1120519E-5, 0.13339938, 0.0, 0.0, 0.027997771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15612613, 0.0, 0.014415845, 0.6041918, 0.2039314, 1.1731424, 0.08551141, 0.27725387, 2.2011218, 0.31403586, 0.41594863, 0.0, 0.081218906, 1.7892827, 0.36488065, 0.027362103, 0.0, 1.4830927, 0.0, 1.4802617, 7.34427E-4, 0.001864493, 0.16394264, 0.0, 0.0, 0.07219496, 0.13123786, 0.0, 0.02625941, 1.145229, 0.96760863, 0.0, 0.0019196247, 0.0, 0.0, 0.108588286, 0.0, 2.2461896, 0.19469446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9751637, 0.0, 0.2367882, 0.034133058, 0.026280507, 0.5601003, 0.0, 1.6559321, 0.0, 0.42934954, 0.0, 0.0, 0.0, 0.105829716, 0.1470436, 0.0, 0.0, 2.0626915, 0.0013437044, 0.27921808, 0.3682866, 0.07068634, 0.03537353, 1.2184469, 0.0, 0.0, 0.0, 0.0, 0.0, 7.898835E-4, 0.2893614, 0.061843447, 0.0, 0.0, 0.047481317, 0.0, 0.0, 0.0, 0.0, 0.5335827, 0.08059034, 0.79741466, 0.0, 0.0, 0.0, 0.0, 0.25616443, 0.18138298, 0.0, 0.0, 0.0, 1.7204213, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1267688, 0.0, 0.0, 0.0, 3.0728261, 0.0, 0.03035524, 0.0, 0.0074109235, 0.1771202, 1.9272964, 0.0, 0.0, 0.0, 0.44441068, 0.0, 0.0, 0.58195794, 0.09282822, 0.22178067, 0.77247524, 0.0, 0.047423627, 0.0, 0.016501565, 0.0, 2.3687587, 0.008580892, 0.0, 0.0, 0.040170018, 0.9050133, 0.0, 0.031757187, 0.0, 1.9013127, 0.29312402, 0.0, 0.526882, 0.0, 0.0, 2.4500034, 0.0, 2.9333937, 0.23819375, 0.0, 0.8970413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03211776, 0.0, 0.0, 0.5105836, 0.0, 0.0, 0.0, 0.44285613, 0.032491565, 0.0, 0.11795498, 0.0, 0.0, 0.0026840516, 0.008849813, 0.7799275, 0.15340634, 0.031841498, 0.12085757, 0.0, 0.0, 0.70996773, 0.0, 0.0, 0.033951994, 0.6187198, 0.0, 0.0076767644, 0.0, 0.8154783, 0.0, 1.2417775, 0.0, 0.52014273, 0.0, 1.3904809, 0.0, 0.11491482, 1.0144368, 0.0, 0.2940324, 0.041132383, 0.007198187, 0.0, 1.8439407E-4, 0.0, 0.64181525, 0.0, 0.0, 0.42395914, 0.13183863, 0.0, 0.12365189, 0.0, 0.0, 0.04095006, 0.021281322, 2.4017482, 0.01044883, 0.0, 0.0, 0.23598035, 0.43191338, 0.47756433, 0.016987285, 0.0, 0.07880468, 0.0, 0.0, 2.8940735, 0.07408471, 0.0, 0.43430266, 0.64619315, 0.0, 1.0440971, 0.019516133, 0.03877888, 0.0, 0.59092754, 0.018705433, 0.0, 0.42657673, 0.0016070013, 0.22003989, 0.0, 1.9042121, 0.6365126, 0.0, 0.0, 0.34216678, 0.0, 0.08773793, 0.0, 0.0, 0.0, 0.566358, 0.0, 0.015613382, 3.2319527E-4, 0.2103236, 0.48532972, 0.0, 0.90651405, 0.0052500986, 2.5225294, 0.5170838, 0.028861973, 0.72219425, 5.356033, 0.052925408, 0.0, 0.0, 0.55663955, 0.0, 0.0, 0.046028085, 1.2333887, 0.7882495, 0.0, 0.0, 0.03889059, 0.0, 0.017582702, 0.0, 0.0, 0.2702407, 0.0, 0.052950595, 0.10684058, 0.0, 0.0, 0.024253298, 0.0, 0.0, 0.0, 1.3591604, 0.21576023, 1.0247922, 0.0, 0.0, 0.0, 0.0050537125, 1.960882, 0.0, 0.041323625, 0.12109228, 0.0, 0.022363417, 0.0, 0.0, 0.18496613, 0.43859553, 0.0, 0.12224273, 0.0, 0.33625132, 0.11652041, 0.0040823612, 0.0, 0.029542401, 0.012017676, 1.0399998, 0.0, 0.0077326032, 0.0, 0.0, 0.0, 1.0515693, 0.0, 1.1626804, 0.0, 0.20666859, 0.0, 0.0, 0.0, 0.22977278, 0.0, 0.11813209, 0.05703241, 0.19888511, 0.5971366, 0.0, 0.27818274, 0.41408512, 3.5222757, 0.13372988, 0.0, 0.0, 0.0, 0.09823548, 0.0, 0.0, 0.15760624, 0.11861611, 0.0, 0.92628783, 0.0062077707, 0.1746978, 0.018844211, 0.25712436, 0.0, 0.90418696, 0.0632718, 0.0, 0.0, 0.09014499, 0.0, 0.0, 0.0, 0.061071765, 0.034711856, 0.0, 0.20844509, 0.09779434, 1.1602771, 0.048371185, 0.0, 0.0, 0.0, 3.0178566, 0.101884045, 0.42372236, 0.011395424, 0.0, 0.0, 0.0, 0.14869672, 0.6707924, 0.39857826, 0.0, 0.0, 0.0010234066, 0.0, 0.109817155, 0.0, 0.1371358, 0.1601883, 0.08271593, 1.298473, 0.8200563, 0.0, 0.06757575, 0.45785093, 0.0, 0.0, 0.0, 0.0, 0.07366779, 0.04923169, 0.0, 0.0, 0.12916428, 0.0, 0.032179527, 0.0, 0.0, 0.79748183, 0.5798295, 0.0, 0.0, 0.0729042, 0.9839663, 0.0, 0.3302291, 0.0, 0.0, 0.053442527, 0.9952955, 0.0, 1.5428923, 0.0, 2.1205468, 3.0057237, 0.0, 0.9629583, 0.0, 0.0, 0.8242372, 0.32140714, 0.0, 0.022749469, 0.0, 0.0, 0.0, 0.0, 0.13208172, 0.0, 0.5801937, 0.3761809, 1.2794063, 0.0, 1.961031, 0.0, 0.0, 0.0, 0.058970813, 0.04274524, 0.41528627, 0.0, 0.0042277924, 0.0, 0.0, 0.0, 0.2542735, 0.0, 0.061367463, 0.0, 0.29734242, 0.04412864, 0.0, 0.007175877, 0.0, 0.0, 0.0, 0.0, 0.27740678, 0.0, 0.31656444, 0.026083075, 0.35690138, 0.0, 0.054293077, 0.051763922, 0.0, 0.50024533, 0.2600216, 0.0, 1.067171, 0.21089342, 0.035803832, 0.244992, 0.0, 0.0, 0.14424002, 0.0, 1.7020295, 0.7889733, 2.040755, 1.9358826, 0.02462148, 0.19637942, 0.0, 3.7288435, 0.15710019, 0.051521305, 1.9459827, 0.0, 0.0, 0.0, 0.0, 0.012948981, 0.0010053521, 0.0, 0.18217435, 0.23700917, 0.0, 0.306694, 0.0, 0.070944175, 0.45054716, 0.20782249, 0.7624807, 0.0, 0.18917161, 0.0, 0.12303507, 0.0, 0.0, 0.0, 0.0074083116, 1.7568649, 0.06723773, 0.6883172, 0.0, 0.0, 1.4386863, 0.008948498, 0.00841812, 0.083015695, 0.17627445, 0.0, 0.46834567, 0.06691215, 1.1020769, 0.0, 0.07026677, 0.0, 0.0, 1.2083505, 0.016100401, 0.16124864, 0.235621, 0.009391522, 0.0, 0.13986416, 0.0, 0.5109121, 0.14263579, 0.0, 0.19092268, 0.04162895, 0.0, 0.0, 0.0, 0.9132966, 0.0, 0.0, 0.65823305, 0.7491772, 0.16568553, 0.0, 0.0, 0.018883374, 0.0, 0.3024824]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Pineapple Mini/293_100.jpg|Pineapple Mini|[0.0, 4.803104, 0.021533662, 0.0, 0.0, 0.0, 0.18353444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2546321, 0.06608473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1480869, 0.0, 0.0, 0.04184982, 0.0, 0.0, 0.0, 0.0, 0.025365775, 0.16350104, 0.0, 0.0, 0.04827768, 0.0, 2.90131, 0.0, 1.403802, 0.06995951, 0.009026162, 0.1621215, 0.0, 0.0, 0.027500844, 0.0, 0.0, 0.9770567, 0.0, 0.10638097, 0.0, 0.47250938, 0.32274428, 0.19045798, 0.17796375, 0.0, 0.0, 0.10011422, 0.46146545, 0.0, 0.0, 0.41942963, 0.0, 0.1717766, 0.106099375, 0.2596932, 0.73327607, 0.99593556, 0.050537147, 0.0, 0.7070229, 8.3947263E-4, 1.041152, 0.0, 1.0715778, 0.0, 2.9474657, 0.6692035, 1.7323654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35184017, 0.0, 0.0, 0.0, 0.00654027, 2.1632726, 0.022805104, 0.8795659, 0.5103145, 0.037841335, 2.5567908, 0.01787025, 0.0, 0.0, 0.0, 1.5065502, 0.93261313, 0.15630902, 0.0, 0.124729656, 0.105075195, 0.0, 0.655051, 1.2920048, 0.0, 0.25225547, 0.0, 0.008178628, 0.0, 2.2035444, 0.0, 0.0, 0.13697003, 0.0, 0.0049710204, 0.0, 0.004328457, 0.25398138, 0.0, 0.11408502, 0.0, 0.0, 0.02488048, 2.4747517, 0.014553744, 0.052378714, 0.21855488, 0.0, 0.63461095, 0.0, 0.15033527, 0.0, 0.0, 0.0, 0.017929902, 0.010701943, 0.0, 0.0, 0.0, 0.009615645, 0.0, 0.19359913, 0.2107266, 0.0, 0.020729948, 0.0, 0.0, 0.5497274, 0.902594, 0.0, 0.023102282, 0.69719154, 0.13509095, 0.0072593135, 2.8790896, 0.08276902, 0.0, 1.71977, 0.0, 0.050499443, 0.0, 0.5241387, 0.0, 2.2512715, 0.01366396, 0.0, 0.0, 0.3113239, 0.0, 0.0, 0.0, 0.0, 2.1640053, 0.0, 0.0, 0.063816845, 0.0, 0.0, 0.2290928, 0.033745073, 0.019348813, 0.0, 0.0, 2.3441799, 0.0, 0.0, 0.0, 0.0, 0.44979978, 0.010697167, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4887717, 0.030227829, 0.3573924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07384332, 0.0, 0.015905607, 0.20129298, 0.1791217, 0.0, 1.3754233, 0.0, 0.0059984145, 0.0, 0.14247432, 0.2875644, 0.069906205, 0.0, 2.431245, 0.0, 1.549315, 0.23536834, 2.0880241, 0.0, 0.0, 0.46005848, 0.0, 0.0, 1.0483074, 0.0, 0.0, 0.7298821, 0.0, 0.35674033, 0.0, 0.028093865, 0.0, 0.005465222, 0.3758841, 0.0, 0.0, 0.010788314, 0.16812357, 0.0, 0.0, 1.1949605, 0.31646293, 1.4658291, 0.0, 0.0, 0.8467033, 0.0881162, 0.0, 0.045783773, 0.011305228, 0.0, 0.0, 0.0016454172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0047851806, 0.21415257, 0.34439325, 0.0, 0.04028138, 1.2322218, 0.0, 0.5519917, 0.17073655, 0.0, 0.0, 0.104253665, 0.0, 1.2361469, 0.0046804054, 0.0, 1.6403077, 0.0, 0.0, 0.010902097, 0.10842697, 0.0, 0.0, 0.0, 1.0369166, 0.0021948665, 0.0, 0.019959603, 0.27810273, 0.0, 0.54651195, 0.0, 0.0342003, 0.53974193, 0.0, 0.0, 0.0, 0.036062013, 0.21207117, 0.0, 0.0, 0.08350774, 0.60533345, 0.04266624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3289167, 0.011486154, 0.0, 0.0, 0.03400535, 0.0, 0.0, 0.51838255, 1.0466635, 0.0, 0.0, 0.22915635, 0.2701935, 0.0, 2.241247, 0.01620664, 0.0, 0.0, 0.0, 0.044253413, 0.0, 2.4302886, 1.1078371, 0.0, 1.0344827, 0.0, 0.0, 0.021327583, 0.0, 0.0, 0.0, 0.0, 1.0234361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16395447, 0.0, 0.0, 0.0, 0.87039053, 0.0, 0.11671028, 0.0, 0.0, 0.0017122297, 0.0, 0.0, 0.07006051, 0.010259342, 0.05951208, 0.028508602, 0.08852368, 0.0, 2.179004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.04486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6789505, 0.0, 0.57895887, 0.0, 0.0, 0.6496176, 0.0, 0.0, 1.6477703, 0.091572724, 1.2000825, 0.0, 0.102656804, 0.09882123, 0.001806591, 0.2804808, 0.30294764, 0.0, 3.18673, 0.0, 0.074184366, 0.0, 0.012793723, 1.1893528, 0.0, 0.0, 0.18619895, 0.09584966, 0.0, 0.0, 0.0, 0.0, 1.6566966, 0.07618526, 0.076810844, 0.0, 0.04812446, 0.045018084, 0.03525733, 0.31243852, 0.31391317, 9.35511E-4, 1.744952, 0.0, 0.0035800864, 0.012171874, 0.0, 0.0, 0.0987799, 0.024621362, 0.0, 0.0, 0.0, 0.1270274, 0.04998541, 0.0, 0.48760107, 2.0102997, 0.0, 0.037231505, 1.0885621, 0.95635116, 0.0, 0.54836565, 0.0, 0.0106395455, 1.2604908, 0.06623824, 0.0, 0.0, 2.0456932, 0.14569469, 0.0, 2.4636512, 0.0, 0.021693587, 0.10147422, 0.0, 0.0, 0.0, 0.019104984, 0.10550184, 0.0, 0.20677122, 0.6423597, 0.0, 0.50105494, 0.0, 0.0, 0.0, 0.18102702, 0.42063063, 0.0, 1.8848451, 0.0137382625, 0.0, 0.0, 0.07606989, 0.7832417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42941436, 0.085714154, 0.023013933, 0.04152954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054956324, 0.0, 0.0, 4.8069614E-5, 0.15267538, 0.08185511, 0.0, 0.115580104, 0.0, 0.0, 0.027497686, 0.7731254, 0.062454626, 0.0, 0.062668286, 0.0, 0.022220252, 0.0, 0.0, 0.0, 0.0, 0.723435, 0.45838657, 0.0, 0.0, 0.6166537, 0.18388247, 0.0372632, 0.0, 0.0, 1.4492105, 0.0, 1.2208908, 0.9714895, 0.0, 0.0, 0.017559249, 0.11065781, 0.0, 0.09641082, 0.044633597, 0.015582093, 0.23025264, 0.039229438, 0.049043197, 0.0057802713, 0.0, 0.033676166, 3.5174255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.50720483, 0.0, 0.6172647, 0.109099716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13289933, 0.0, 0.98467326, 0.5435124, 0.0, 0.0, 1.6390008, 0.4875079, 0.0, 0.0835414, 0.0, 0.0, 0.0, 0.6436921, 0.0, 2.626363, 0.6679613, 0.0, 0.0, 0.0, 0.3474312, 0.07768071, 0.0, 0.89653826, 0.6043336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021127965, 0.11285534, 0.0, 0.0, 0.0, 0.62017, 0.38616514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7042437, 0.05294684, 0.0, 0.0, 0.0, 0.0, 1.6703897, 2.050033, 0.0, 0.01096619, 0.0, 0.072003864, 0.0, 0.13922387, 0.0, 0.0, 0.0, 0.007662889, 0.15643083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11195474, 0.028628996, 0.0, 0.0, 0.008604823, 0.0, 0.1500351, 0.5738562, 0.0, 0.11851108, 0.0, 0.0, 0.0, 0.0, 0.026245413, 0.0, 0.0, 0.0, 2.1204734, 0.0, 0.0, 3.843866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15757069, 0.2166806, 0.0, 0.0, 0.16787845, 0.0, 0.0, 0.0, 0.0, 0.032310884, 0.015876764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009460079, 0.0, 0.0, 0.33463478, 0.43371388, 0.07979238, 0.0, 0.4169562, 0.81863195, 0.43680525, 0.15285678, 0.0, 0.0, 0.9953204, 0.022208324, 0.0, 0.0, 0.566019, 0.0, 0.93201363, 0.0, 0.0025248444, 0.002219515, 0.05899396, 0.0, 0.0, 0.003520645, 0.0, 0.013773248, 0.59390724, 0.19844717, 0.0, 0.47004315, 0.0, 0.003904949, 0.025622424, 0.0, 1.069172, 0.0, 0.049856316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8856537, 0.0, 0.0, 5.7644374E-4, 0.0, 0.10862476, 0.0, 1.1888648, 0.06890013, 4.9001776E-4, 0.0, 0.0, 0.0, 0.26144877, 0.35400835, 0.0, 0.0, 2.2124035, 0.0, 0.0, 0.0027950217, 0.0, 0.10302327, 0.3469602, 0.0, 0.0, 0.5518691, 0.0, 0.0, 0.09069976, 0.5284668, 0.3313583, 0.0, 0.0, 0.06995539, 0.0, 0.0, 0.0, 0.0, 0.7591678, 0.011335341, 0.20857784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7634085, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0370821, 0.0, 0.0, 0.0, 1.2333714, 0.0, 0.014362363, 0.0, 0.0, 0.14511387, 0.89187056, 0.0, 0.0, 0.0, 0.023660367, 0.0, 0.0, 0.3958112, 0.11514905, 0.20020004, 0.00487008, 0.087871306, 0.013537921, 0.0, 0.06030266, 0.0, 2.4162443, 0.5221094, 0.0, 0.0, 0.0, 1.2102088, 0.0, 0.0, 0.0, 2.1216602, 0.5889166, 0.0, 1.3767186, 0.0, 0.0, 3.2892473, 0.0, 3.6098375, 0.42524588, 0.0, 0.4760972, 0.0, 0.0, 0.0, 0.0, 0.077609316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.81556576, 0.0, 9.743876E-6, 0.0, 0.0614357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027307002, 0.032840826, 0.45097786, 0.8826538, 0.058056973, 0.28749532, 0.0, 0.0, 0.23935872, 0.027281167, 0.0, 0.025747642, 0.4613458, 0.0, 0.047413137, 0.0, 0.8820607, 0.0, 0.49462438, 0.0037796525, 2.3108878, 0.0, 0.76692146, 0.0, 0.19130887, 0.1114188, 0.0, 0.0, 0.06689318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06778953, 0.0, 0.60260177, 0.0, 0.0, 0.01005617, 0.020163326, 0.0, 0.0, 0.0, 2.379716, 0.035534833, 0.0, 0.0, 0.0, 0.555574, 0.53518754, 0.0, 0.0, 0.0252302, 0.0, 0.0, 2.6572213, 0.15568961, 0.0, 0.51395637, 0.10896295, 0.0, 0.22702624, 0.0, 0.23229039, 0.0, 0.13784805, 0.8396745, 0.0, 0.10188786, 0.018974071, 0.053369936, 0.0076750033, 1.1767981, 0.3400673, 0.0, 0.0, 0.1098367, 0.003581032, 0.070957266, 0.0, 0.0, 0.0, 0.1127801, 0.0, 0.0, 0.0011424816, 0.5593601, 0.17673399, 0.0, 0.48269984, 0.0, 2.807483, 0.30847514, 0.1490725, 0.3185252, 4.0210667, 0.026748719, 0.0, 0.0, 0.024376187, 0.0, 0.0, 0.1540739, 0.4686284, 0.007323839, 0.0, 0.0, 0.28447065, 0.0, 0.62879443, 0.0, 0.0, 0.030771011, 0.011455044, 0.0076029296, 0.022033462, 0.051511288, 0.0, 0.025047837, 0.0, 0.0, 0.0, 0.88384306, 1.5550731, 1.4482955, 0.0, 3.001598E-4, 0.0, 0.06479715, 1.1280886, 0.0, 0.0, 0.05838491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15807892, 0.0, 0.011316682, 0.0, 0.40603104, 0.2521191, 0.0, 0.0, 0.03269461, 0.0, 1.2275165, 0.0, 0.030284403, 0.0069284486, 0.0, 0.0, 1.1173501, 0.006772111, 0.22860464, 0.19418432, 0.09335464, 0.0, 0.0, 0.011829358, 0.3761695, 0.0, 0.06450575, 0.0051876907, 0.389499, 0.67537206, 0.0, 0.32928848, 0.80636114, 3.182617, 0.0, 0.0, 0.0, 0.0, 0.20109075, 0.0, 0.013034011, 0.0, 0.48664084, 0.15501225, 1.0136207, 0.0, 0.0, 0.054483514, 0.047606632, 0.0, 1.3047125, 0.0, 0.01569716, 0.0, 1.2189509, 0.0, 0.0, 0.0, 0.79019785, 0.0, 0.0, 0.272599, 0.24281113, 0.28980118, 0.019452168, 0.0, 0.0, 0.0, 2.8714643, 0.0, 0.24618365, 0.0, 0.0, 0.0, 0.0, 0.010695474, 0.118098326, 0.002262845, 0.0, 0.0, 0.036470164, 0.0, 0.0, 0.0, 0.0, 0.17949423, 0.04436105, 0.886418, 0.34936744, 0.0, 0.021844618, 0.0, 0.0, 0.04255227, 0.0, 0.0, 3.0554406E-4, 0.09297184, 0.0, 0.0, 0.68603104, 0.0, 0.21578825, 0.0, 0.0, 0.46119234, 0.54280627, 0.0, 0.0, 0.0, 0.61685985, 0.0, 0.20951116, 0.0, 0.0, 0.0, 0.2206037, 0.0, 1.1449268, 0.0, 0.48564985, 3.1416187, 0.0, 0.17053594, 0.0, 0.22393273, 0.09310073, 0.024272379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01127677, 0.0, 0.3379881, 0.36367548, 0.053632636, 0.0, 1.188909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05867835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.72094464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014922853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05589317, 0.0, 0.5866736, 0.0, 0.024834212, 0.0, 0.0, 0.7268984, 0.16279858, 0.0, 1.3147066, 0.0044880654, 0.004897158, 0.0, 0.0, 0.0, 0.6070775, 0.0, 1.5866438, 0.8300765, 2.0891466, 1.4051225, 0.026738174, 0.12531596, 0.0, 3.6709373, 0.0, 0.2367096, 0.7476726, 0.0, 0.0, 0.0, 0.0, 0.021572193, 0.08090439, 0.0, 0.100399785, 0.034840494, 0.0, 0.24119638, 0.0, 0.0042358628, 0.23348413, 0.0, 0.20709078, 0.0, 0.0030004927, 0.0, 0.2472417, 0.0, 0.0, 0.0, 0.0, 0.5339337, 0.004339317, 0.38202807, 0.0, 0.0, 0.8804352, 0.0, 0.0, 0.021333506, 0.025973335, 0.0, 0.5769692, 0.048277088, 0.21478336, 0.0, 0.01667508, 0.0, 0.0, 0.042503055, 0.0114205545, 0.0060839816, 0.11031613, 0.0, 0.0, 0.06678015, 0.0, 1.2750092, 0.036304653, 0.0, 0.10643152, 0.03422137, 0.0, 0.0, 0.027663082, 0.4653952, 0.0, 0.011522974, 0.06364837, 0.06021345, 0.05332835, 0.0, 0.0, 0.0, 0.0, 1.0968358E-4]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/244_100.jpg    |Watermelon    |[8.3662715E-4, 0.015711863, 0.0, 0.0, 1.3770399, 0.0092023, 2.2927275, 0.17242004, 0.0, 0.0, 0.26512742, 0.47811663, 0.065152764, 2.214724, 0.09131404, 0.14684786, 0.0, 0.0, 0.5760697, 0.20559679, 0.18897331, 0.0, 0.0, 0.0, 0.0, 0.12623979, 0.35163164, 0.0, 0.0, 1.7819304, 0.0, 0.08950546, 0.017092729, 0.9051361, 0.0, 0.21794109, 0.25822282, 0.5499575, 0.022851713, 0.0, 0.0, 0.0, 1.8697392, 0.0, 0.12502003, 0.0, 0.31458414, 0.18007414, 1.5350868, 0.20678629, 0.0, 0.38218462, 0.21990202, 0.0, 0.0, 0.8309103, 0.007991638, 1.3234395, 0.0, 0.009026381, 1.7496089, 0.86460876, 0.065309055, 0.0, 1.9142544, 1.7053019, 2.441424, 0.056518905, 0.014167288, 0.0, 0.0, 0.0395306, 0.0036269457, 0.4540357, 0.17458801, 1.2773751, 0.018496107, 0.45680696, 0.1525292, 0.054777667, 0.0, 1.2555861, 0.0, 0.01096296, 0.12516925, 0.0, 0.0, 0.4635091, 1.0061543, 0.37121892, 1.0199548, 0.0, 0.5398405, 0.0, 1.0454195, 0.02076026, 0.0, 0.0, 1.3694578, 1.0452308E-4, 0.006314504, 0.1998848, 0.0, 0.0195673, 0.36568412, 0.0, 0.0, 0.4519845, 0.0, 1.7503747, 0.19143482, 0.0, 0.0, 0.0, 0.0, 0.046719976, 0.38793904, 0.0, 0.017843768, 0.04993788, 0.18369445, 0.0, 0.0, 0.690878, 0.0, 0.91700906, 1.7897205, 0.82174355, 1.4635642, 0.47902104, 0.0, 0.96322477, 0.77389026, 0.011570027, 0.0291605, 0.0, 0.0, 0.0, 0.012491245, 0.20589556, 0.0, 0.0, 0.029278118, 0.05164046, 0.0, 0.0, 0.72461414, 1.5044624, 0.062124748, 0.9009694, 0.0, 0.0, 0.0, 0.0, 0.00594134, 0.32615352, 0.0, 0.0, 1.6590905, 0.004587136, 0.0, 0.0, 0.0, 0.002846368, 1.5542274, 1.5904138, 0.737571, 0.19895603, 1.8842047, 1.4232854, 0.02976577, 0.010039638, 0.43811247, 0.0, 0.0, 0.06304755, 0.54876274, 0.17122038, 0.040193804, 0.1028875, 2.6377566, 0.0, 1.1481841, 0.0, 0.38693187, 0.54148823, 0.75628644, 0.042731985, 0.0, 0.0, 0.2601152, 0.07612753, 1.719941, 1.9320179, 0.25204134, 0.0, 0.0, 0.0, 0.0, 0.008494631, 0.42580372, 0.0, 0.2848162, 0.06804442, 1.4666009, 0.007468003, 0.0, 0.0, 0.15815201, 0.36117855, 0.0, 0.0, 0.0, 0.1018934, 0.40962917, 0.645758, 0.0, 0.0, 0.30408093, 0.0, 0.19484608, 0.0, 0.058592606, 0.22965808, 0.16168891, 0.23209897, 0.044028915, 0.0, 0.8030932, 0.09673698, 1.5823699, 0.27803677, 0.06226066, 0.21916616, 0.6046241, 0.1532872, 0.0, 0.0, 0.0, 1.2565022, 2.3712406, 0.09772632, 0.0, 0.0020958413, 0.05270104, 0.0, 1.3632593, 0.667015, 0.4654837, 0.060978323, 0.1235926, 0.15290362, 1.7773619, 0.0, 1.4127843, 2.1610801, 2.1126564, 0.3393632, 0.0, 0.8111779, 0.0, 2.5186594, 0.028127335, 1.2873363, 0.010165303, 0.16660644, 0.0, 0.0, 0.0, 0.21214631, 0.2748206, 0.0, 1.6799957, 0.0, 0.3609022, 0.062311687, 0.045908064, 0.0, 0.18180236, 0.3902144, 1.323786, 0.0, 0.13371399, 0.011614176, 1.7034603, 0.0, 0.0, 3.5375913E-4, 1.501272, 1.1974359, 0.06030975, 0.0985201, 0.0, 0.0, 0.0, 1.6110582, 0.08080157, 0.21340816, 0.20309962, 0.056969117, 0.0, 0.0, 0.6032942, 0.0012858454, 0.28038365, 0.0, 0.0, 0.0, 0.0, 0.78337157, 0.5026566, 0.017411457, 0.34119973, 0.008520425, 0.22401792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3606734, 1.3433908, 0.92037964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06389051, 0.0, 0.141893, 2.4000685, 0.0, 0.0, 0.7680155, 0.0, 0.0, 0.17353986, 0.5631609, 0.0, 0.0, 0.18908551, 0.31093264, 0.10848693, 0.5958897, 0.7636644, 0.0, 0.05037223, 0.0, 0.0, 0.12916261, 0.0, 1.3457831, 0.0, 0.050200745, 0.0, 0.0, 0.78997886, 1.3776236, 0.2030115, 0.4203441, 0.14494646, 1.1942799, 0.0, 0.017844396, 0.24330571, 0.0, 0.0, 0.0856533, 0.0, 0.18811266, 0.009173751, 0.0, 3.7039852, 0.0, 0.25252402, 0.07494432, 0.22825527, 0.0, 0.0, 1.4725897, 0.17264059, 0.0, 0.037550423, 0.0, 0.7541268, 0.0, 0.0, 0.61538374, 1.886105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3754919, 0.0, 0.039944995, 0.66033447, 0.89124477, 0.105268985, 0.0, 0.0, 0.0, 0.29661182, 0.046552144, 0.1507915, 0.17761762, 0.0, 3.4617558, 3.0867643, 0.0, 0.22479281, 0.11042735, 0.008352944, 0.028037095, 0.8703801, 0.04438647, 3.921824, 0.00925757, 2.083324, 0.80897725, 0.060318008, 0.04217763, 0.038571727, 1.6154815, 0.007027248, 0.0, 0.12506992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09595638, 0.0, 0.0096316505, 0.017704064, 0.0, 0.0, 0.14987968, 1.3381275, 2.0777977, 2.0600216, 0.07660503, 0.025834853, 0.00887889, 0.011449315, 0.0, 0.0, 0.8167799, 0.26847982, 0.27726907, 1.8449564, 0.1201397, 0.0, 0.030834904, 0.0, 0.010026175, 1.2448508, 0.0, 0.0, 0.06410279, 0.7775672, 0.0, 2.1876395, 0.27225763, 1.2568969, 0.0, 0.23796713, 0.0, 0.0, 3.4054167, 0.7021548, 0.17468137, 0.08436212, 0.0, 0.0, 3.8163755, 0.109007046, 0.3886823, 0.0, 2.0050032, 0.64975697, 0.018884165, 0.83932054, 2.713165, 0.025469834, 0.72714597, 1.6084981, 0.0, 0.0, 2.3549924, 2.4962678, 0.0, 0.0, 0.0734648, 0.8927923, 0.0, 1.957799E-4, 0.20227742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3780997, 0.561945, 0.57235, 0.0, 0.0, 0.17275898, 0.06486152, 0.0, 0.21203242, 0.06368624, 0.0, 0.0, 0.78717923, 0.0, 0.23984586, 0.0, 0.0, 0.03841797, 0.0, 1.691138, 0.23074, 0.0, 0.71426815, 0.0, 0.0, 0.4491554, 0.55584294, 0.0, 0.0, 0.11472011, 0.0, 0.042825934, 0.0, 0.9157033, 0.0028498378, 0.043828104, 0.0, 0.13384397, 0.18572511, 0.16618498, 1.0040814, 0.94470847, 0.0, 0.0, 0.0, 0.1568703, 0.22144045, 0.09817259, 0.111478016, 1.4707096, 2.272351, 0.032946922, 0.0, 2.0359094, 0.26825324, 0.12342403, 0.0, 0.28920606, 0.0, 0.27437478, 0.0, 0.036822718, 0.021350304, 0.0, 0.0, 0.78705543, 0.0052993097, 0.9293612, 0.50995165, 0.0, 1.550533, 0.0, 0.0, 0.0, 0.0, 0.026535397, 0.0, 0.22256115, 0.0, 0.96426064, 0.8281031, 2.0991457, 0.8911227, 0.0, 1.9109329, 0.010641671, 0.0, 0.0, 2.7807417, 0.21142177, 0.0012233832, 0.13933972, 0.0, 0.32870102, 0.07977975, 0.0, 0.0088616675, 0.0, 0.8042427, 0.0, 1.3600254, 1.2765747, 0.733785, 0.0, 0.0, 2.245805, 0.41983634, 2.0794158, 0.3353298, 0.43107376, 0.0, 0.04102271, 3.4807322, 0.22677986, 0.11243039, 0.039047875, 0.0, 1.1601853, 0.0, 0.09597832, 0.0, 0.2645484, 0.007585414, 0.5463738, 0.0, 0.0, 0.48835182, 0.7441722, 0.08156421, 0.29395157, 1.5781037, 0.0, 0.0, 2.9776044, 0.707873, 0.0, 0.44250795, 0.0, 0.13564487, 1.6732905, 0.0, 0.0068600336, 0.14106165, 0.0, 0.0, 0.9199658, 0.0, 0.5135799, 0.2674493, 0.0, 0.0, 0.61932987, 2.3784368, 0.0, 0.0, 0.017055955, 0.7501538, 0.0, 0.0, 0.29216695, 1.7510909, 1.7011689, 0.0, 2.6558633, 1.1886071, 0.23420066, 0.08524772, 0.1576929, 0.059722237, 0.10909624, 0.0, 0.0024458296, 0.06164703, 0.0, 0.36769584, 0.010858246, 0.42379597, 0.11370233, 0.11839199, 0.6935422, 1.8085943, 1.6286026, 0.0, 0.0, 0.0, 2.8387754, 0.0, 0.0, 0.019000465, 0.0, 0.039382838, 0.0, 0.007842691, 0.28599307, 0.0, 0.0, 0.017512225, 1.6333221, 0.34579197, 0.0, 0.0, 0.0, 0.5055126, 2.2386339, 0.42307457, 0.510144, 1.2266176, 0.0, 0.18720432, 0.18970042, 0.62278616, 0.27993056, 0.0379497, 0.10272717, 0.0, 0.19646172, 2.2323527, 1.553459, 0.0, 0.0, 0.96100956, 0.0, 1.7370001, 0.5216097, 0.0, 0.0, 0.23126085, 0.63907814, 0.0, 0.20322399, 0.0, 3.2754273, 0.5053076, 0.40918162, 0.112253614, 0.13614017, 0.08571231, 0.0, 0.82032984, 0.0046730745, 0.0, 0.0, 0.0, 0.060771115, 1.9638871, 0.9892906, 0.26676467, 2.1902523, 0.4121604, 1.6771975, 0.0065625673, 0.0, 0.0, 2.0826037, 0.0, 0.0, 0.2009864, 0.20033902, 0.31823465, 1.3040637, 0.0, 0.0024969713, 0.17104593, 0.044637714, 0.5355692, 0.0, 0.15579514, 0.3372495, 0.8109187, 0.0, 0.042210486, 1.6282201, 0.0, 0.09179946, 0.41300833, 0.017963428, 0.0, 0.0, 0.0, 0.44820657, 0.0, 0.30592534, 1.6591183, 0.33446443, 0.31994882, 0.031506233, 0.0, 0.0, 0.0, 0.078971855, 0.0623713, 0.5570304, 0.0, 0.0, 0.0127893025, 0.0, 0.01529855, 0.0, 0.014577484, 0.0, 0.064349934, 0.047530334, 0.0110018775, 0.0, 0.106265865, 0.19377777, 0.15805064, 0.0, 0.0, 0.0, 0.0, 0.097774476, 0.004868377, 0.0, 0.006109324, 0.83332783, 0.9191136, 0.0, 3.2174032, 0.61928713, 0.20861478, 0.53733504, 0.09822484, 0.040624216, 0.04936811, 0.0, 0.065612376, 0.048086695, 0.0, 1.491153, 0.4611013, 0.013639546, 0.119233154, 0.42938167, 1.7998983, 0.23037034, 0.132913, 0.0, 0.19373575, 0.031585537, 0.0, 0.03156744, 2.8204598, 0.0, 0.0, 0.0, 0.0, 2.9643228, 0.0, 0.0, 1.275795E-4, 0.006464062, 0.0, 0.04171984, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0782008, 0.32238197, 0.0, 0.0, 0.27866957, 0.06615115, 0.008791493, 0.0, 0.0, 0.0, 0.0, 0.11421998, 0.017038176, 0.0, 1.3285236, 0.01618125, 0.4820155, 0.0, 1.2369137, 0.0, 0.0, 0.04240002, 0.0, 0.0, 0.0, 0.6232469, 0.21705247, 0.0, 0.0, 0.074659534, 0.0, 0.0, 0.161778, 0.934698, 0.114355415, 0.0, 0.63643974, 0.04004741, 0.0, 0.0, 0.0, 0.0029364964, 0.0, 0.0, 0.0, 0.23431894, 0.18847288, 0.0, 4.4604376E-4, 0.49686164, 0.0, 0.0, 0.0, 0.18923533, 0.7605144, 2.8863098E-5, 0.023529723, 0.3535598, 0.229219, 0.0, 0.0, 0.016455201, 0.0, 0.0, 0.05097702, 0.65011495, 0.0, 0.088541485, 0.75322604, 0.0723857, 0.0, 0.0, 0.0, 0.58174986, 0.0, 0.40309817, 0.21907824, 0.071962446, 2.9729135, 0.0, 0.5234335, 0.012470543, 0.46751988, 0.5360433, 0.5898091, 0.0, 0.6674558, 1.9127356, 2.7053835, 0.06084779, 0.00947357, 0.18458222, 0.0, 0.048677906, 0.0, 0.07620039, 1.0546721, 0.0, 0.006115208, 0.9836508, 0.0, 0.0, 0.012468534, 0.42609566, 0.76092476, 2.5803003, 0.42663437, 0.0, 0.1236642, 1.1692039, 0.2687871, 2.2362096, 0.0, 0.34828788, 1.6800381, 0.038194995, 0.21501896, 0.05775612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.69412506, 0.0, 1.4745371, 0.05118362, 0.0, 0.12240889, 0.994692, 0.0, 1.5793321, 0.0, 0.1698153, 0.35444272, 0.0, 0.121690474, 1.3355467, 0.24800237, 0.26435187, 0.0, 0.08681303, 0.0, 0.15979183, 0.0, 0.7673392, 0.6969269, 0.40166828, 0.99131924, 0.25841016, 0.8196082, 0.0, 0.6684459, 2.1576233, 0.0, 0.015981069, 0.014199169, 0.08276828, 0.27947932, 0.5595245, 0.46360826, 0.20209514, 0.0, 0.14416023, 0.68640476, 0.25434786, 1.3513132, 0.0, 0.0, 0.0, 0.09509296, 0.0, 0.89140904, 0.0, 0.024949377, 0.0, 1.6431952, 0.050194234, 0.0, 1.3172059, 0.0, 0.85883814, 0.25252697, 0.0, 0.00304586, 1.449613, 2.750109, 0.2020146, 0.5354561, 3.2336025, 0.0, 0.0, 1.09279, 0.0038697661, 0.21306853, 0.0, 1.0870936E-4, 0.0, 1.6743841, 0.0, 1.1395382, 0.6773055, 0.16563168, 0.32859355, 0.0, 0.5364541, 0.0, 0.0056118066, 0.0, 1.6971307, 0.1075964, 0.0, 0.6882568, 0.042482298, 0.0, 0.01995199, 0.26291758, 0.0, 0.0, 0.6159171, 1.5889434, 0.0028208815, 0.5749528, 0.8185686, 0.03742852, 1.5848917, 0.0, 0.0, 0.0, 0.72221524, 0.002763742, 0.18572725, 0.0, 0.5464126, 1.7567028, 1.4788979, 0.0, 0.0094955815, 0.0, 0.16939412, 0.0, 0.0, 0.2627089, 0.0, 0.2124279, 1.1744745, 0.83352536, 0.07694031, 0.047815613, 0.26480594, 1.4506012, 0.0, 0.0, 0.021494117, 1.424283, 0.0, 0.0, 0.018566782, 0.65967655, 0.111659676, 0.028652174, 1.4206839, 0.70476764, 0.0, 0.005688618, 0.034010887, 1.0453382, 0.0, 2.1158803, 0.8485272, 0.0, 0.0, 0.0, 0.0, 2.6021008, 1.3005893, 0.005560746, 1.8512722, 0.0, 0.0, 0.021432687, 0.0, 1.8456031, 0.9253566, 0.34118, 0.07464686, 0.2636976, 0.04436447, 2.121355, 0.013659974, 0.36579093, 0.33803126, 0.3212177, 0.11377027, 0.026823424, 0.0, 0.0130560445, 0.41339555, 0.0, 0.0, 0.0, 0.0, 0.25227848, 0.0, 0.9071547, 0.0, 0.0, 0.09821131, 0.5947338, 1.7502218, 0.0, 0.0, 0.13788743, 0.5282349, 1.1406027, 0.061752476, 0.07574302, 0.073337786, 0.0, 0.59226894, 0.37619758, 0.4433099, 0.13978088, 0.0, 0.007231043, 0.26582605, 0.14470984, 1.2851282, 0.77653116, 0.0, 0.08974195, 0.4861604, 0.3792524, 0.0, 0.6020089, 0.9421618, 0.39824906, 0.0, 0.0, 0.017469948, 0.7722046, 0.25923672, 0.014451623, 0.13299358, 0.0, 1.7402115, 0.0, 0.0, 0.1982083, 0.048607536, 0.3267642, 0.54809946, 0.0, 1.2375113, 0.14744219, 0.49997416, 0.031002818, 0.0, 0.3556543, 0.111776255, 1.4463273, 0.062567174, 0.5307375, 0.00719054, 0.0, 0.47804907, 2.6871574, 0.18601137, 0.3898767, 0.0, 0.0, 0.13534145, 0.9149937, 0.32143015, 0.4426257, 0.150359, 0.0, 0.0, 0.0, 0.47552478, 0.11450294, 0.0, 0.015297528, 0.1536799, 0.016052531, 0.03722304, 0.0090441005, 0.93392605, 0.30559027, 0.34565896, 0.0, 0.02923858, 0.0, 0.39518487, 0.0, 1.1354051, 0.7821414, 0.003032467, 0.15989363, 0.0, 0.0, 1.1974777, 0.091584705, 0.0, 0.34342447, 0.12510632, 0.040224276, 0.18256791, 0.041662753, 0.014991097, 0.14232534, 0.08098297]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n|s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/178_100.jpg    |Watermelon    |[0.0055620596, 0.0, 0.0, 0.015787305, 1.3267833, 0.020941649, 2.5567777, 0.23360655, 0.0, 0.0, 0.1490422, 0.0, 1.2424741, 1.6102657, 0.0, 0.17160822, 0.0, 0.016411582, 0.3659181, 0.13346687, 0.06380865, 0.0, 0.0, 0.036585838, 0.0031127473, 0.026346913, 0.04004029, 0.058073506, 0.025248628, 1.1004956, 0.21087411, 0.0, 0.0, 1.1996046, 0.0, 0.24155362, 0.2044682, 0.29046598, 0.0, 0.08547704, 0.0, 0.0, 2.5188925, 0.0, 0.27422652, 0.0, 0.7456207, 0.4495368, 1.2398483, 0.5623734, 0.0, 0.71463317, 0.4089268, 0.0, 0.21434417, 0.29647288, 6.247453E-4, 1.8318678, 0.4000765, 0.4222855, 1.7958893, 0.4601219, 0.0, 0.0, 2.7030575, 2.9799335, 1.1220286, 0.041676667, 0.010619465, 0.0, 0.018534973, 0.0, 0.0, 0.9548531, 0.01744842, 0.6296658, 0.7437128, 0.31225404, 0.303481, 0.119844474, 0.0, 1.0128633, 3.1692733E-4, 0.12728922, 0.10817473, 0.0, 0.0, 0.11228248, 1.0333223, 0.82865465, 0.5981587, 0.47010934, 0.60168314, 0.0, 2.2263024, 0.91826504, 0.20307936, 0.10650305, 0.9876936, 0.0, 0.21910036, 0.38538423, 0.0, 0.16671306, 1.161479, 0.0, 0.0, 0.04696293, 0.0, 1.487684, 0.0, 0.021514345, 0.0, 0.3332321, 0.0, 0.0069045015, 0.64759105, 0.03347114, 0.0, 0.0, 0.009591948, 0.0, 0.0, 0.5072346, 0.1599906, 1.0249447, 1.4195974, 1.4707602, 1.4637082, 0.0, 0.0, 0.12734154, 0.96768755, 0.0, 0.43059912, 0.0, 0.0, 0.110383034, 0.2417445, 0.21640848, 0.0, 0.0, 0.26772323, 0.054731093, 0.0, 0.0107309595, 0.95572054, 0.7836167, 0.01260951, 0.23239553, 0.0, 0.0, 0.0, 0.0, 0.03786505, 2.3410163, 0.0, 0.009083869, 0.6759985, 0.07696929, 0.14213051, 0.86229116, 0.0, 0.0, 1.6936438, 1.7936261, 0.009712474, 0.4866656, 2.8404691, 1.4690459, 0.11225644, 0.0, 0.3613008, 0.17959237, 0.0, 0.0, 2.0860004, 0.06853263, 0.008516831, 7.323719E-4, 3.3718424, 0.0, 0.8343348, 0.028787734, 0.8683495, 0.77161276, 0.95069396, 0.14032216, 0.049706258, 0.0, 0.20330192, 1.2145582, 1.1272314, 1.5754073, 0.07890337, 0.0, 0.0, 0.0, 0.010725668, 0.1610688, 0.5888194, 0.0, 0.02277275, 0.043988317, 0.6494464, 0.0, 0.0, 0.0, 0.3369429, 0.38285205, 0.0, 0.025134938, 0.03745355, 0.7506587, 0.76003605, 0.6047511, 0.9449102, 0.0, 1.3526455, 0.0, 0.52644724, 0.0, 0.07433152, 0.0, 0.3206383, 0.0, 0.0, 0.0, 0.7629875, 0.4092051, 1.7677876, 0.004653888, 0.0, 0.77381104, 0.10199699, 0.10875604, 0.0, 0.0, 0.0, 2.194747, 1.9886855, 5.39873E-4, 0.0, 0.0, 0.78002954, 0.0, 1.7780628, 0.0, 0.3013585, 0.23476924, 0.34481108, 0.0151198935, 1.0170186, 0.0, 0.82968575, 3.4826245, 1.6581353, 0.44036305, 0.0033484797, 0.23957582, 0.0, 2.6354566, 0.7437813, 3.0650606, 0.0, 0.0, 0.0, 0.0, 0.17913206, 0.0, 0.011583574, 0.44736743, 1.9572424, 0.20181847, 0.38206127, 0.07996072, 0.27302626, 0.0, 0.64937544, 0.28160262, 1.9444276, 0.0, 0.0093366895, 0.25469318, 1.9684651, 0.0, 6.314984E-5, 0.27322838, 0.64007515, 0.71683824, 0.29245436, 0.007623993, 0.0, 0.0, 0.0, 1.8064493, 0.058137413, 0.043299515, 0.14789715, 0.091366895, 0.0, 0.073270634, 0.18772864, 0.038806196, 0.58242595, 0.55968624, 0.0, 0.0, 0.0, 0.0, 0.31074464, 0.9646011, 0.09778468, 0.0, 0.3413245, 0.0, 0.0, 0.0, 0.08382352, 0.016942898, 0.0, 1.8931729, 1.0201733, 0.30417153, 0.027199259, 0.0, 0.002695015, 0.0, 0.0, 0.28449214, 0.015493898, 0.3619559, 3.4433708, 0.01987767, 0.0, 0.54147446, 0.0, 0.0, 0.0, 0.60456526, 0.0, 0.0, 0.37276608, 0.15983424, 0.1720951, 0.7998612, 0.8212777, 0.0, 0.007894216, 0.0, 0.0, 0.3417637, 0.0, 1.9734386, 0.0, 0.0, 0.0046878415, 0.0, 0.0, 0.31419975, 0.020620288, 0.5889316, 0.013386589, 1.2873572, 0.026453694, 0.0, 0.41613677, 0.19710323, 0.0, 0.0, 0.010236511, 0.0, 0.0, 0.18070899, 4.50641, 0.0046042954, 0.299121, 0.06566134, 0.2603748, 0.090048276, 0.0, 1.9388144, 0.28818482, 0.0, 0.21781385, 0.0, 0.4619137, 0.0, 0.0, 0.068514615, 3.406955, 0.0, 0.06394483, 0.0, 0.7947261, 0.19006215, 0.025196865, 0.0059045134, 0.0, 0.8646469, 1.0713762, 0.19906192, 0.0, 0.0, 0.0, 0.3194045, 0.7174902, 0.40705118, 0.7541033, 0.0, 3.5008054, 4.056454, 0.0, 0.14224288, 0.0, 0.0, 0.0, 0.24066454, 0.45933604, 2.9650757, 0.107532814, 1.1409677, 0.6167185, 0.013725436, 0.0040739896, 0.5818918, 0.36237255, 0.02169376, 0.0, 0.023737447, 0.0, 0.0, 0.068360746, 0.0, 0.0, 0.01866363, 0.0, 0.0063880826, 0.14408682, 0.0, 0.0, 0.2538454, 0.2796256, 2.5571344, 1.3538777, 0.5071432, 0.0, 0.0, 0.14279212, 0.0, 0.17644699, 0.22213301, 0.22811185, 0.48062617, 1.5196003, 0.09923939, 0.2877848, 0.0, 0.0, 0.0, 2.0290635, 0.0, 0.0, 0.4056997, 0.15182604, 0.0, 1.6987997, 0.6970148, 1.0197203, 0.0, 0.1234755, 0.0, 0.0, 3.4225075, 0.24134064, 0.0, 0.0816969, 0.0029491277, 0.0, 4.39801, 0.011115673, 0.6801037, 0.0017927433, 2.9471138, 0.06660022, 0.046922196, 0.47309455, 2.7962668, 0.0, 0.1557833, 1.5094339, 0.11497839, 0.0, 1.1721516, 2.8247511, 0.0, 0.15703623, 0.040962152, 0.096129596, 6.949233E-4, 0.0, 0.672713, 0.049756262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07751216, 0.0, 0.30732745, 0.9119154, 0.0337409, 0.026929293, 0.050074246, 0.020275172, 0.0, 0.0, 0.2160209, 0.10285841, 0.0, 0.79889214, 0.0, 0.0, 0.0, 0.0, 0.08339161, 0.068028994, 1.3324404, 0.6312066, 0.0, 0.010067694, 0.0, 0.15779327, 0.20594576, 0.1252322, 0.0, 0.0, 0.008066081, 0.0, 0.65701616, 0.0, 1.4535339, 0.19801933, 0.35769886, 0.4912529, 0.042270914, 0.0132212965, 0.016913086, 0.45006955, 1.8744358, 0.0, 0.0, 0.0, 0.674097, 0.023737345, 0.029974785, 0.13345064, 2.361191, 1.8424861, 0.2269467, 0.0, 2.245232, 0.0, 0.83944297, 0.45906088, 0.24971846, 0.0025355073, 0.46302342, 0.0, 0.1381319, 0.23929596, 0.0, 0.124818444, 2.155243, 0.6810787, 0.8558514, 0.23933625, 0.0, 1.9389791, 0.0, 0.05046072, 0.0, 0.0, 0.1898213, 0.010528257, 0.40713832, 0.0, 0.9596679, 0.035466816, 0.5813452, 0.48969588, 0.0, 1.7283534, 0.0, 0.0, 0.0, 2.1895134, 0.1674563, 0.010379891, 0.041980505, 0.05977349, 0.46636775, 0.0, 0.0, 0.0, 0.120463125, 0.0, 0.0, 0.44320396, 0.26265198, 1.6127605, 0.0, 0.02063722, 2.1893039, 0.043588955, 1.8691996, 0.82429683, 0.0, 0.0, 0.0, 3.7906303, 0.8936127, 0.04953062, 0.18633589, 0.005750943, 1.2634575, 0.0, 0.33236957, 0.0, 0.67619115, 0.0, 0.38520715, 0.026446614, 0.0, 1.1222763, 1.1497911, 0.34708723, 0.30509073, 0.5006244, 0.0, 0.031807244, 0.4893334, 0.2989165, 0.0, 0.10092542, 0.0, 0.055160522, 1.1893835, 0.0, 0.14040841, 0.05969794, 0.0, 0.0, 0.0, 0.0, 0.5378247, 0.5758786, 0.0, 0.0, 0.13155843, 1.8974915, 0.05689818, 0.0, 0.020384485, 0.379488, 0.0, 0.0, 0.12895858, 0.65002775, 1.1663234, 0.0, 4.2163973, 1.4960967, 0.06649864, 0.057943784, 0.477186, 0.0, 0.24992764, 0.0, 0.0, 0.019613523, 0.0, 0.25404742, 0.0, 0.24137954, 0.08287779, 0.22082525, 0.06309801, 2.5020022, 1.2604095, 0.0, 0.0, 0.0, 2.0395458, 0.0, 0.015081826, 0.40322915, 0.0, 0.0, 0.022183584, 0.0, 0.16318406, 0.0, 0.0, 0.0, 0.7859752, 0.8329382, 0.0, 0.0, 0.0, 0.5681029, 1.4546828, 0.60150427, 0.31176773, 1.3738717, 0.0019069407, 0.30016318, 0.49155036, 0.38675728, 1.243175, 0.0861722, 0.06739331, 0.0, 0.93283486, 2.3573575, 0.92975134, 0.0, 0.0, 1.4406167, 0.012802077, 1.7241043, 0.0, 0.0017755588, 0.019531155, 0.35428748, 1.2618775, 0.0, 0.37735087, 0.0, 3.1748161, 0.31657273, 0.09182858, 0.16578482, 0.0819575, 0.22062987, 0.0, 0.4994152, 0.0052363044, 0.0, 0.0, 0.0, 0.096226655, 3.7434838, 0.4465368, 0.07866175, 2.4757, 0.6259867, 0.71269786, 0.06312449, 0.08744272, 0.42234242, 1.4603186, 0.0, 0.0, 0.07247508, 0.3965443, 0.023759056, 0.36498654, 0.0, 0.0, 0.15856867, 0.44031385, 0.009471044, 0.0, 0.019747961, 1.7201796, 0.6277436, 0.0, 0.354364, 0.92433494, 0.0, 0.008655392, 0.06586204, 0.12480606, 0.0, 0.0, 0.0, 0.7102041, 0.0036913776, 0.26095062, 1.4617625, 0.47176352, 0.12920865, 0.0075326147, 0.07688871, 0.0, 0.0, 0.0, 0.12756696, 0.059049353, 0.0, 0.0, 0.032438982, 0.0, 0.0, 0.0, 0.0915406, 0.0, 0.0, 0.6284708, 0.22397123, 0.0, 0.1725668, 0.21805342, 0.14061126, 0.0, 0.0, 0.0, 0.007228091, 0.2492417, 0.26555923, 0.0, 0.0, 1.9571341, 0.90845203, 0.0, 2.9992201, 0.7415051, 0.1894973, 0.09821777, 0.03838039, 0.0, 0.0, 0.0, 0.60690254, 0.8820124, 0.0043173116, 1.4080158, 0.016135106, 0.0, 0.0, 0.49232024, 0.83162355, 0.47761163, 0.16299811, 0.031551413, 0.6113311, 0.0794033, 0.0, 5.3360616E-4, 2.7620292, 0.0, 0.14577976, 0.0741295, 0.0, 2.729847, 0.076059364, 0.0, 0.0, 0.017670223, 0.0, 0.0, 0.0, 0.0, 0.023483634, 0.0, 0.0, 0.8336484, 0.0, 0.0, 0.0, 0.044341706, 0.46746466, 0.0014491922, 0.0, 0.0, 0.0, 0.06272027, 0.63430053, 0.0092364205, 0.0, 2.030789, 0.5837888, 0.5748825, 0.008755878, 0.59186435, 0.0, 0.06733036, 0.0, 0.013095585, 0.0, 0.0036145537, 0.61862797, 0.016814018, 0.13345139, 0.039979123, 0.045201622, 0.0, 0.08978857, 0.076292, 0.8863967, 0.18033321, 0.0, 0.6823574, 0.024840537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32289687, 0.10643186, 0.0, 0.11618709, 0.5866294, 0.0, 0.0, 0.0, 0.97778225, 0.49063057, 0.0, 0.0, 0.9339373, 0.07681755, 0.02434349, 0.0, 0.0, 0.18864033, 3.7628564E-4, 0.0, 0.32392856, 0.0, 0.026614038, 1.3741828, 0.1635448, 0.0, 0.0, 0.087918244, 0.5894649, 0.0, 0.3402677, 0.5635188, 0.05605443, 3.4011436, 0.0060369987, 0.4847202, 0.0, 0.46890923, 0.3479904, 0.63538843, 0.02687055, 1.0468403, 1.2055218, 2.2978315, 0.0, 0.6603926, 0.0, 0.058241654, 0.12918338, 0.0, 0.0, 0.52799815, 0.0, 0.0, 0.48201075, 0.0, 0.07491932, 7.425021E-4, 0.7032232, 1.970553, 2.982199, 0.0365902, 0.0, 0.42165586, 0.64175516, 0.39113596, 0.8131051, 0.022940319, 0.077199884, 2.7927735, 0.059069682, 0.50012887, 0.0, 0.0, 0.013347716, 0.0, 0.0, 0.02072766, 1.4867783, 0.0, 0.89014614, 0.08490309, 0.17659223, 0.12210507, 0.2003664, 0.0, 0.24322066, 0.0, 0.11032523, 0.1484582, 0.0, 0.5786801, 1.749294, 0.29163742, 0.35401574, 0.028247181, 0.038613606, 0.0, 0.1320027, 0.0, 0.26232895, 0.20975678, 0.8131067, 0.6155275, 0.42952666, 0.6224663, 0.0, 0.5382937, 0.4350655, 0.024045393, 0.010339237, 0.0, 0.0, 0.6363609, 0.77595466, 0.7830886, 0.99004, 0.0, 0.0, 1.2604309, 0.17659277, 0.023537304, 0.0, 0.0, 0.0, 0.536182, 0.06896029, 1.827159, 0.0, 0.0, 0.0, 2.7710755, 0.11864205, 0.0, 1.3900092, 0.0, 1.6694932, 0.54018575, 0.0, 0.094761424, 1.0492297, 1.5394182, 0.11247043, 0.5313418, 2.7944908, 0.010230529, 0.0, 1.9714274, 0.0, 0.069766104, 0.0, 0.030091299, 0.0, 0.4129604, 0.18467356, 0.92534196, 1.5269969, 0.6074433, 0.59658116, 0.0, 1.925825, 0.06695292, 0.01621382, 0.046550237, 0.7656487, 0.33131447, 0.1919774, 1.8311167, 0.2830409, 0.0, 0.10425959, 0.25481725, 0.008078437, 0.0, 0.351484, 2.0047412, 0.092692874, 0.95790815, 0.41921487, 0.16522583, 0.75418746, 0.0, 0.0, 0.03537143, 0.77025527, 0.07646421, 0.003407106, 0.35940573, 0.38676375, 2.241045, 1.3159566, 0.0, 0.057573285, 0.0, 0.3399422, 0.0, 0.0, 0.04298491, 0.0, 0.32193044, 0.6249468, 0.10015789, 0.22541305, 0.36943483, 0.4508967, 2.3491943, 0.085606314, 0.0033158935, 0.17053822, 0.27758524, 0.0, 0.0, 0.0, 0.9320783, 0.025238797, 0.0038229334, 0.2490394, 0.23901579, 0.0, 0.051851463, 0.36476487, 1.1110831, 0.0, 2.0730064, 1.765471, 0.20882735, 0.0, 0.5521925, 0.0, 2.3667636, 0.7341262, 0.0, 1.382717, 0.09108849, 0.0797706, 0.0615728, 0.033067003, 0.82366055, 0.45880836, 0.34147048, 0.121035516, 0.11141113, 0.23531397, 2.4246447, 0.0, 0.009579787, 0.06877294, 0.49784762, 0.31095114, 0.32553396, 0.0, 0.3486285, 0.095151745, 0.18345346, 0.0, 0.0, 0.0, 0.12255365, 0.0, 1.3495482, 0.0, 0.0, 0.150975, 0.40359423, 1.3242635, 0.019468477, 0.0, 0.0, 0.70119935, 2.876723, 0.0, 0.20947158, 0.004374767, 0.0, 0.29308507, 0.1766481, 0.15095302, 0.1460556, 0.0, 0.0, 1.6641872, 0.0518216, 1.0345674, 0.6409136, 0.070295595, 0.0, 0.772373, 1.0109552, 0.023566041, 1.6516804, 0.6756996, 0.30557805, 0.09789124, 0.0, 0.33675596, 0.438255, 0.35791904, 0.01746324, 0.03636204, 0.0, 0.276931, 0.020645672, 0.0, 0.003042716, 0.023045136, 1.2218413, 0.87149256, 0.0, 0.82780355, 0.0, 0.026889859, 0.6254524, 0.011015369, 1.5282369, 0.06993652, 1.9146225, 0.0924966, 0.90712154, 0.4582751, 0.29360574, 0.81084883, 2.4932494, 0.009896477, 0.02415712, 0.781057, 0.0, 0.62368983, 1.1201209, 0.014567799, 0.977355, 0.26149526, 0.0, 0.01602361, 0.0, 0.008987438, 0.3317869, 0.0, 0.1298341, 0.43711585, 0.14460774, 0.0098823495, 0.46909818, 0.85856205, 0.54259413, 0.29255316, 4.4330963E-4, 0.02892608, 0.0, 1.8738408, 0.0, 0.48460895, 0.7650159, 0.0033223939, 0.14806724, 0.0, 0.010601003, 0.080498256, 0.08718259, 0.0, 0.9675291, 0.5368497, 0.09558324, 0.4798053, 0.37042457, 0.045153525, 0.005050359, 0.0]                                                                                                                                                                                                                                                                                        |\n+-------------------------------------------------------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "pdf = df.limit(10).toPandas()\nprint(pdf.columns)\nprint(pdf.head())\n", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Index(['path', 'label', 'features'], dtype='object')\n                                                path  ...                                           features\n0  s3a://p8-data-djamel/jupyter/hadoop/data/Test1...  ...  [0.1886027455329895, 0.3506745398044586, 0.066...\n1  s3a://p8-data-djamel/jupyter/hadoop/data/Test1...  ...  [0.0, 4.519897937774658, 0.0, 0.0, 0.0, 0.0, 0...\n2  s3a://p8-data-djamel/jupyter/hadoop/data/Test1...  ...  [0.0, 4.803103923797607, 0.0215336624532938, 0...\n3  s3a://p8-data-djamel/jupyter/hadoop/data/Test1...  ...  [0.0008366271504200995, 0.015711862593889236, ...\n4  s3a://p8-data-djamel/jupyter/hadoop/data/Test1...  ...  [0.005562059581279755, 0.0, 0.0, 0.01578730531...\n\n[5 rows x 3 columns]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "id": "db18a784", "cell_type": "code", "source": "df.head(5)\n", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "[Row(path='s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/r_104_100.jpg', label='Watermelon', features=[0.1886027455329895, 0.3506745398044586, 0.0665275901556015, 0.0, 0.6470840573310852, 0.08696356415748596, 0.1553661823272705, 0.9120900630950928, 0.0, 0.0, 1.187207818031311, 0.3226737082004547, 0.01872444339096546, 0.0, 0.04219409450888634, 0.3972683846950531, 0.0, 0.0, 0.0, 0.4430456757545471, 0.0, 0.05283413082361221, 0.0, 0.0, 0.03510154411196709, 0.796669602394104, 1.418474793434143, 0.0, 0.0, 1.90265691280365, 0.0, 0.0, 0.13683995604515076, 0.34912949800491333, 0.0, 0.16854462027549744, 0.3036250174045563, 1.7479803562164307, 0.04897065460681915, 0.0, 0.015576452948153019, 0.0, 0.9187617301940918, 0.1627257615327835, 0.31893467903137207, 0.0, 0.470981627702713, 0.2016228437423706, 1.6303528547286987, 0.00999639555811882, 0.0, 0.0, 0.04909751936793327, 0.0, 0.894706130027771, 1.6532434225082397, 0.0, 1.2668737173080444, 0.0, 0.005108188837766647, 0.30489659309387207, 0.015381712466478348, 0.0, 0.0, 1.3083223104476929, 2.4649832248687744, 1.7693583965301514, 0.05340356379747391, 0.0104965940117836, 0.00833883322775364, 0.0, 0.04095347225666046, 0.0, 0.7510548830032349, 0.7630546689033508, 1.548875331878662, 0.08774638921022415, 0.15404382348060608, 0.0, 0.0, 0.0, 0.6082488894462585, 0.10375075787305832, 0.0009063722682185471, 0.0, 0.0, 0.041977036744356155, 0.8837575912475586, 1.3686954975128174, 3.1628541946411133, 0.46568819880485535, 0.0, 0.0, 0.0, 1.1738829612731934, 0.2860091030597687, 0.42444470524787903, 0.0, 1.3722844123840332, 0.0, 0.21044650673866272, 0.3364413380622864, 0.00513972993940115, 0.0, 0.8498884439468384, 0.10613863170146942, 0.0, 0.1872013956308365, 0.020695604383945465, 0.04723330959677696, 0.0, 0.0, 0.016028158366680145, 0.6937305927276611, 0.0012192699359729886, 1.4071584939956665, 1.239015817642212, 0.15445412695407867, 0.0, 0.5670968890190125, 0.6551061272621155, 0.010019732639193535, 0.09454961866140366, 0.4512856900691986, 0.0, 1.2326326370239258, 1.2978763580322266, 2.184443473815918, 2.5169100761413574, 0.12850619852542877, 0.0, 2.7823874950408936, 0.1133221909403801, 0.0, 1.1220788955688477, 0.0, 0.5266950726509094, 0.06213640794157982, 0.8303406238555908, 1.2865837812423706, 0.7763707637786865, 0.00822767149657011, 0.3189333975315094, 0.32338234782218933, 0.0, 0.14850999414920807, 0.0, 0.7108945846557617, 0.05965669825673103, 0.5615178346633911, 0.0223013237118721, 0.0, 0.35269638895988464, 0.0, 0.36663636565208435, 1.2391903400421143, 0.007662696298211813, 0.0002619069709908217, 0.47963032126426697, 0.5152247548103333, 0.0, 0.02663145773112774, 0.0, 0.24233511090278625, 1.1855320930480957, 2.1371734142303467, 1.2755094766616821, 1.0157759189605713, 1.0955023765563965, 0.22124938666820526, 0.09128376096487045, 0.0, 0.055413756519556046, 0.009472423233091831, 0.0, 0.6109291911125183, 0.1535293161869049, 0.5137228965759277, 0.00623487401753664, 0.6790155172348022, 2.51188063621521, 0.2992866337299347, 0.03833821788430214, 0.0, 0.9906535744667053, 1.351815104484558, 0.989290714263916, 0.0, 0.0, 0.2346910536289215, 0.04634939879179001, 1.0531847476959229, 0.031096505001187325, 1.9110091924667358, 0.09800790995359421, 0.0, 0.0, 0.0, 0.060673635452985764, 0.16453929245471954, 0.7163864970207214, 0.04667522385716438, 0.0, 0.41702184081077576, 1.0440964698791504, 0.0034843713510781527, 0.0, 0.0, 0.0, 1.0266878604888916, 0.0, 0.0, 0.2135554552078247, 0.036826491355895996, 0.0, 0.9350901246070862, 0.00618624035269022, 0.026416882872581482, 0.44469398260116577, 0.0, 0.8191946148872375, 0.020478200167417526, 0.0, 0.2697215676307678, 0.0, 0.0, 0.03441404923796654, 0.0, 1.6733149290084839, 0.3629748225212097, 0.16260528564453125, 0.2412809133529663, 0.8413727283477783, 0.3018110394477844, 0.19555670022964478, 0.2683480679988861, 0.039803646504879, 0.052205875515937805, 0.17132802307605743, 0.9752821922302246, 1.707830786705017, 0.3584757149219513, 0.0005880923708900809, 0.0, 1.6724852323532104, 0.12787169218063354, 2.1786086559295654, 0.0, 1.436453938484192, 0.2335488200187683, 1.538002610206604, 0.0, 0.4112201929092407, 0.00023857549240346998, 0.8902254104614258, 3.027623414993286, 3.2001688480377197, 0.45642635226249695, 0.27744272351264954, 1.1793036460876465, 0.0, 0.5673877000808716, 0.13352501392364502, 0.5506842732429504, 0.0, 0.0008942577405832708, 0.0, 0.0, 0.0, 0.15086747705936432, 0.005486597307026386, 0.0031715701334178448, 1.3441389799118042, 0.35211512446403503, 0.22546133399009705, 0.520662248134613, 0.6365771293640137, 0.0, 0.02480607107281685, 0.0, 0.28502869606018066, 0.0, 0.18276585638523102, 0.6953855156898499, 0.9182312488555908, 0.6495375633239746, 0.0, 0.09106703102588654, 0.6956802606582642, 0.0, 0.7170332074165344, 0.04794829338788986, 0.0, 0.0, 0.0, 0.6666868329048157, 0.0, 0.0, 0.03513339161872864, 0.0, 0.0, 0.0, 0.14583063125610352, 0.04570439085364342, 0.052529700100421906, 0.0, 0.0, 0.13782382011413574, 0.0, 0.37293103337287903, 0.9726045727729797, 0.359142005443573, 0.0, 0.03295214846730232, 1.4228672981262207, 0.8010249137878418, 0.0, 0.0, 0.0, 0.06569162011146545, 0.44534021615982056, 1.5201120376586914, 0.49618279933929443, 0.5916789174079895, 0.0, 0.0, 0.0, 0.01964842714369297, 0.0, 0.06726528704166412, 0.0004610374744515866, 0.0, 0.629285991191864, 2.029414176940918, 0.0, 0.8406585454940796, 0.04743638634681702, 0.0, 0.017928889021277428, 1.411454677581787, 0.0, 0.0, 0.2658196985721588, 0.0791698545217514, 0.07196975499391556, 0.9624552726745605, 0.0, 0.0, 0.7352846264839172, 0.4169831871986389, 0.012253625318408012, 0.11152680218219757, 0.0, 1.5058715343475342, 0.0, 0.028307771310210228, 0.020641697570681572, 0.06244366616010666, 1.0258045196533203, 0.0687655657529831, 0.009281203150749207, 2.237429618835449, 0.276721715927124, 1.9391796588897705, 0.2582414448261261, 0.0, 1.6106083393096924, 0.05100209265947342, 0.0, 0.0, 0.08178310841321945, 0.0, 0.0, 0.00841950997710228, 2.8840086460113525, 0.0, 0.011073872447013855, 0.9391288757324219, 0.20196062326431274, 0.0, 0.0, 0.1690344363451004, 0.08002176880836487, 0.0, 0.05389116331934929, 0.0, 0.41799724102020264, 0.0, 0.0, 0.7170038819313049, 2.292431592941284, 0.04576132819056511, 0.0, 0.0, 0.0, 0.015331286936998367, 0.2627107799053192, 0.03540092706680298, 0.07295070588588715, 0.059219442307949066, 0.04684583842754364, 1.6900734901428223, 0.0, 0.003591066226363182, 0.0, 1.2735408544540405, 0.031163522973656654, 0.41341906785964966, 0.8410190939903259, 0.03348749876022339, 2.580178737640381, 2.146766424179077, 0.0, 0.05148569867014885, 0.4736996591091156, 0.5865453481674194, 0.0, 1.432578206062317, 0.5009795427322388, 2.250120162963867, 0.5467655658721924, 2.282665729522705, 0.538169264793396, 0.0, 0.04679234325885773, 0.5375586748123169, 0.2783620357513428, 0.0, 0.0, 0.0, 0.6747503280639648, 0.002289260271936655, 0.0, 0.0, 0.010466761887073517, 0.18163765966892242, 0.03561750054359436, 0.1495322585105896, 0.0, 0.04535296559333801, 0.0, 0.0, 2.1350901126861572, 1.8920096158981323, 1.608465552330017, 1.3017936944961548, 0.3131197690963745, 0.0794113278388977, 0.0, 0.0, 0.5585495829582214, 0.1444169133901596, 0.5055666565895081, 0.0697917491197586, 1.8355463743209839, 0.8659685254096985, 0.0, 0.0, 0.27599623799324036, 0.0, 1.1230348348617554, 0.0, 0.0, 0.0, 1.4875428676605225, 0.0, 2.2180070877075195, 0.0013354896800592542, 2.3638811111450195, 0.24035289883613586, 0.12298085540533066, 0.0, 0.0, 0.9819076657295227, 0.3677373230457306, 0.2268112599849701, 0.0061660767532885075, 0.0, 0.0, 2.0834145545959473, 0.0, 0.14097268879413605, 0.001767934882082045, 0.11575660109519958, 0.7306683659553528, 0.11645007878541946, 0.2413448840379715, 1.4678994417190552, 0.0, 1.285849690437317, 0.3107392191886902, 0.03095122054219246, 0.0, 2.3340256214141846, 0.9773120284080505, 0.0, 0.6548616290092468, 0.47111207246780396, 0.2599545121192932, 1.3917028903961182, 0.0, 0.2920796573162079, 0.0, 0.0, 0.06739620119333267, 0.0, 0.0, 0.0, 0.0, 0.10084270685911179, 0.7269368767738342, 0.712898850440979, 0.1729082614183426, 1.049368977546692, 0.32312798500061035, 0.7222617864608765, 0.0, 0.07818221300840378, 0.22066566348075867, 0.22542551159858704, 0.0, 1.9686850309371948, 0.0, 0.463802695274353, 0.11761588603258133, 0.0, 0.3072841167449951, 0.5132017135620117, 1.8733363151550293, 0.0, 0.005277108401060104, 2.290928840637207, 0.0, 0.11051905155181885, 0.2695962190628052, 0.09859912097454071, 0.49248838424682617, 0.00012092843826394528, 0.18922346830368042, 0.06297140568494797, 0.0396343469619751, 0.0, 1.1188483238220215, 0.10802303999662399, 0.2905540466308594, 0.0, 0.0, 0.09734729677438736, 0.1789473444223404, 1.1162277460098267, 1.0876293182373047, 0.0, 0.0, 0.0, 0.14010411500930786, 0.0, 0.8399586081504822, 1.780472993850708, 1.8555494546890259, 2.387380838394165, 0.353270947933197, 0.0, 1.9959118366241455, 0.0, 0.24635930359363556, 0.10128317028284073, 0.7448561787605286, 0.19977343082427979, 0.0959094911813736, 0.0, 0.027678878977894783, 1.0039712190628052, 0.0, 0.167425274848938, 1.0336220264434814, 0.8427531123161316, 0.020999964326620102, 0.20926538109779358, 0.0, 0.7028679847717285, 0.0, 0.0, 0.0, 0.0, 0.019252190366387367, 0.010792284272611141, 0.9152643084526062, 0.0, 0.1642162948846817, 0.09464757144451141, 0.6485379934310913, 1.502997875213623, 0.08629108220338821, 2.691204071044922, 0.08504543453454971, 0.09012240171432495, 0.0, 1.6139719486236572, 0.1165379136800766, 0.0, 0.5885406136512756, 0.08604109287261963, 0.8661343455314636, 0.3169430196285248, 0.0, 0.0, 0.34347009658813477, 0.06784824281930923, 0.43612122535705566, 0.16132740676403046, 1.5946991443634033, 0.6197906136512756, 0.05211607366800308, 0.0, 2.9699819087982178, 0.8371668457984924, 1.3910022974014282, 0.6978477239608765, 0.1242709681391716, 0.0, 0.010922678746283054, 1.5761111974716187, 1.1301965713500977, 0.39055007696151733, 0.199827179312706, 0.0, 0.4595130681991577, 0.0, 0.0, 0.0, 0.2691166400909424, 0.1425749659538269, 0.32357966899871826, 0.0, 0.02328236773610115, 0.87149578332901, 1.4652482271194458, 1.7559804916381836, 0.338027685880661, 1.6636123657226562, 0.0, 0.5736365914344788, 1.974852442741394, 0.6074935793876648, 0.0, 1.646809458732605, 0.0, 0.0, 1.1372510194778442, 0.0480816625058651, 0.08807118237018585, 0.14512725174427032, 0.0, 0.006437670439481735, 1.270707130432129, 0.13718143105506897, 0.24273912608623505, 0.019619645550847054, 0.0, 0.0, 0.5364859700202942, 0.44150644540786743, 0.0, 0.0, 0.16047202050685883, 0.5571747422218323, 0.0, 0.0, 0.07298009097576141, 0.6759312748908997, 1.8692429065704346, 0.2027880847454071, 3.618563175201416, 2.3473000526428223, 0.24111828207969666, 0.7152234315872192, 0.154311865568161, 1.5043526887893677, 0.0, 0.42054644227027893, 0.2007761150598526, 0.3042701482772827, 0.04547146335244179, 0.9846882224082947, 0.0, 0.9981757998466492, 0.3188621401786804, 0.17502281069755554, 1.2080541849136353, 2.2584800720214844, 0.030941873788833618, 0.09800081700086594, 0.0, 0.0, 0.7354365587234497, 0.0, 0.0, 0.6472228169441223, 0.24470534920692444, 0.01714472658932209, 0.0, 0.6891769170761108, 0.3777451515197754, 0.0, 0.54818195104599, 0.0, 0.97360759973526, 0.04005284607410431, 0.0, 0.0, 0.0, 1.1333013772964478, 1.2968361377716064, 0.0, 1.1116998195648193, 0.27348068356513977, 1.1055355072021484, 0.41058236360549927, 0.06473303586244583, 1.7296520471572876, 0.5026610493659973, 0.06243176758289337, 1.0768264532089233, 0.0, 1.1444342136383057, 0.5709043741226196, 1.5611368417739868, 0.08610815554857254, 1.1167784929275513, 0.5362629294395447, 0.002567172981798649, 2.003937005996704, 1.0204625129699707, 0.0, 0.11168305575847626, 0.02716403268277645, 2.3204805850982666, 0.0, 0.07553007453680038, 0.0, 1.0773916244506836, 0.43044233322143555, 0.7903299331665039, 0.14349736273288727, 0.010794448666274548, 0.055958762764930725, 0.21480002999305725, 0.8142557144165039, 0.14399302005767822, 0.0, 0.0, 0.0, 0.008873775601387024, 1.241748332977295, 0.7975207567214966, 0.0, 0.8333579301834106, 0.10369433462619781, 1.1226413249969482, 0.022324364632368088, 0.030076028779149055, 0.0, 0.7852897644042969, 0.0009889076463878155, 0.0, 1.079172134399414, 0.9028332829475403, 0.26179343461990356, 0.7982046008110046, 0.0, 0.08672674000263214, 0.0, 0.31300193071365356, 0.9400447010993958, 0.0, 2.4918525218963623, 1.3858907222747803, 0.001583266188390553, 0.03428902104496956, 1.3574168682098389, 0.001594316097907722, 0.06732615828514099, 0.0, 0.048206280916929245, 0.5370393991470337, 0.12834490835666656, 0.013316894881427288, 0.07433172315359116, 0.019102321937680244, 0.0, 0.21280039846897125, 1.1651960611343384, 1.046663522720337, 0.16123665869235992, 0.8229545950889587, 0.8068289756774902, 0.0, 0.0, 0.0, 0.0, 0.4609852135181427, 0.0, 0.04903979226946831, 0.05571703985333443, 0.31547775864601135, 0.009685495868325233, 0.3354608714580536, 0.000993338879197836, 0.008733895607292652, 0.047764141112565994, 0.6324692368507385, 0.6393859386444092, 0.1677010953426361, 0.16952826082706451, 0.09188105165958405, 0.3807236850261688, 0.0, 0.0, 0.43981003761291504, 0.5699545741081238, 0.44342684745788574, 0.002309345407411456, 0.0, 0.27442285418510437, 0.6551631093025208, 2.3841142654418945, 0.0, 3.484572172164917, 0.029696602374315262, 0.21619345247745514, 0.8721218705177307, 0.02670525573194027, 0.0, 0.0, 0.0, 0.03292931243777275, 0.6659805178642273, 0.0, 0.7226234078407288, 0.017285503447055817, 0.012313504703342915, 0.0, 0.07078605890274048, 2.1361172199249268, 0.45105645060539246, 0.013157837092876434, 0.0, 0.40135204792022705, 0.1858818680047989, 0.0, 0.0, 2.4775209426879883, 0.2748582363128662, 0.08816204965114594, 0.016116097569465637, 0.025787832215428352, 0.9960645437240601, 0.006226640194654465, 0.0, 0.0, 1.1137757301330566, 0.011691346764564514, 0.017076989635825157, 0.4552057683467865, 0.04840954393148422, 0.0, 0.24868081510066986, 0.0, 0.13288633525371552, 0.5570855140686035, 0.007528690155595541, 0.0, 0.16759537160396576, 0.0, 0.0, 0.0, 0.0, 0.7994451522827148, 0.028174016624689102, 2.056774616241455, 0.0, 0.0, 1.1106302738189697, 0.9385846853256226, 0.24830572307109833, 0.09164625406265259, 1.272408127784729, 0.0, 0.12010770291090012, 0.0, 0.12582434713840485, 0.0, 0.07113773375749588, 0.12111570686101913, 0.02462020516395569, 0.0, 0.21898719668388367, 0.07086219638586044, 0.0, 0.0, 0.03034091927111149, 1.3232386112213135, 0.49403491616249084, 0.0, 0.388650119304657, 0.2578478753566742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026747576892375946, 0.00520490575581789, 0.0, 0.0, 0.0, 0.0, 0.07643304020166397, 0.04998418688774109, 0.0, 0.0, 0.008904831483960152, 0.7970069646835327, 0.0, 0.0, 1.0509573221206665, 0.16951026022434235, 0.0, 0.0, 0.0, 0.0, 0.005886791739612818, 0.08206798881292343, 0.6597719192504883, 0.0, 0.05424598231911659, 0.23482009768486023, 0.5388212203979492, 0.013745196163654327, 0.925342857837677, 0.0, 0.581222653388977, 0.0, 0.42008262872695923, 1.4196195602416992, 1.316081166267395, 3.3058907985687256, 0.10032930970191956, 0.407737135887146, 0.0, 0.22563624382019043, 0.02594812773168087, 0.15381108224391937, 0.0, 0.0, 0.029058661311864853, 0.7905715703964233, 0.0, 0.4702169895172119, 0.2925759553909302, 0.05409247428178787, 0.0, 0.0, 0.0, 0.9583269357681274, 0.0, 0.014188558794558048, 0.7109336853027344, 0.0, 1.7416975498199463, 0.022440649569034576, 2.1286990642547607, 1.586775541305542, 3.008840799331665, 0.041006918996572495, 0.24435539543628693, 1.8591361045837402, 0.546319842338562, 0.0, 0.7209807634353638, 0.11798866093158722, 0.4884684085845947, 0.8989738821983337, 0.005895829759538174, 0.5421711206436157, 0.17515766620635986, 0.08760851621627808, 0.0, 0.0, 0.0, 0.013566415756940842, 0.07420262694358826, 0.0, 0.5873652696609497, 0.642720639705658, 0.015531189739704132, 1.2367653846740723, 0.05550699681043625, 0.006398236379027367, 0.7814838886260986, 0.058961737900972366, 0.523226797580719, 0.0, 0.21092142164707184, 0.23166294395923615, 1.9271221160888672, 0.031136352568864822, 0.0, 0.0, 0.16761553287506104, 0.11690733581781387, 0.0, 0.0, 1.8799647092819214, 0.1611797958612442, 0.04037698358297348, 1.1037282943725586, 0.9625173211097717, 0.49389320611953735, 0.09541774541139603, 0.0, 0.4955744743347168, 1.71285080909729, 0.057364124804735184, 0.33667701482772827, 0.0, 0.0012904664035886526, 0.0091624166816473, 1.2315784692764282, 0.5781101584434509, 0.09154806286096573, 0.0, 1.6519500017166138, 0.5487903356552124, 0.7854034304618835, 0.017313264310359955, 0.0, 0.05353878065943718, 1.325962781906128, 1.3490673303604126, 0.6983523368835449, 0.0, 0.2967592775821686, 0.20056666433811188, 0.05929787456989288, 0.06200248748064041, 0.0, 1.8892632722854614, 0.0, 0.1551666110754013, 0.007775071542710066, 0.013430526480078697, 0.9317397475242615, 0.7815629839897156, 1.1873334646224976, 0.6818453073501587, 1.6972942352294922, 2.391857385635376, 0.20376275479793549, 0.0, 0.8717427849769592, 0.0, 1.3299462795257568, 0.23528295755386353, 0.011621599085628986, 0.0, 0.3612794280052185, 0.0, 1.4237887859344482, 0.11913973093032837, 0.38122493028640747, 0.8408053517341614, 0.0, 0.37696099281311035, 0.23454821109771729, 0.8122755289077759, 0.0, 1.5606416463851929, 0.1408940851688385, 0.0, 0.4639773368835449, 0.0, 0.1719782054424286, 0.003594442969188094, 0.5258248448371887, 0.13689307868480682, 0.0, 0.6179642081260681, 0.35375332832336426, 0.1053810864686966, 0.0, 0.27465128898620605, 0.05866195634007454, 1.3853224515914917, 0.0189424529671669, 0.0, 0.2732997238636017, 0.46358656883239746, 0.21075224876403809, 0.2392149120569229, 0.0008646214846521616, 0.47761765122413635, 0.7575981616973877, 0.03593806177377701, 0.19403885304927826, 0.0, 1.2272284030914307, 0.010226341895759106, 0.0, 0.0, 0.11498784273862839, 0.14380332827568054, 0.010224862955510616, 0.4585880637168884, 0.17675477266311646, 0.17270897328853607, 0.24169760942459106, 0.6047677993774414, 0.2994721531867981, 0.0, 0.13507692515850067, 0.0, 0.0, 0.047692518681287766, 0.41075414419174194, 0.025913316756486893, 0.7744041681289673, 0.035695068538188934, 0.45992499589920044, 0.8330047726631165, 1.864147424697876, 0.0, 0.2199782133102417, 0.12464408576488495, 3.4598541259765625, 0.0, 1.7700939178466797, 1.090272068977356, 0.013166788034141064, 0.0, 0.0, 0.38197818398475647, 0.48948362469673157, 0.0965237244963646, 0.0, 0.8808481693267822, 0.025961732491850853, 0.0, 0.0, 0.02227139286696911, 1.5077428817749023, 0.4169865548610687, 0.559237003326416, 0.1558879315853119, 1.1897231340408325, 0.0, 1.080043911933899, 0.0, 1.5406900644302368, 0.0251830592751503, 2.0602190494537354, 0.027862967923283577, 0.09116772562265396, 0.016085591167211533, 0.0, 0.3127700388431549, 0.12269899994134903, 0.09527533501386642, 0.0, 0.0, 0.0, 0.0, 1.6253762245178223, 0.0, 0.0, 1.3756293058395386, 0.16066744923591614, 0.7971398234367371, 0.524808406829834, 0.0, 0.025311706587672234, 0.15399400889873505, 1.1030702590942383, 0.0, 0.8354547619819641, 0.2296832948923111, 0.0, 2.183093547821045, 0.1859292984008789, 1.6060887575149536, 0.4681675136089325, 0.139712855219841, 0.3114844262599945, 0.1799774318933487, 0.03965463116765022, 1.366058349609375, 0.027291996404528618, 0.45073214173316956, 0.41580086946487427, 1.9513983726501465, 0.3161907494068146, 1.0913105010986328, 0.3887447714805603, 0.2432369738817215, 1.202509880065918, 0.0, 0.0, 0.5930002331733704, 0.1399790644645691, 0.055102717131376266, 0.42766815423965454, 0.2147146314382553, 0.0, 0.33720868825912476, 0.023558124899864197, 0.0, 0.12268950045108795, 0.0, 0.7174274921417236, 0.08863688260316849, 0.0, 0.7771430611610413, 0.43435850739479065, 0.0, 0.5949431657791138, 1.4624004364013672, 0.4250849187374115, 0.18546852469444275, 2.5850045680999756, 0.0, 0.33837151527404785, 0.40405112504959106, 0.006051577627658844, 0.0, 1.4630939960479736, 0.6996785998344421, 0.06906410306692123, 0.43203774094581604, 0.0, 0.7841474413871765, 0.17743776738643646, 0.03337666764855385, 0.3293021023273468, 0.10326909273862839, 0.0, 0.015223128721117973, 0.0, 0.16587798297405243, 0.9368257522583008, 0.0, 0.0, 0.1045522466301918, 0.0, 0.5968433618545532, 0.013749365694820881, 0.008756952360272408, 0.2741289436817169, 0.024755891412496567, 0.41315674781799316, 0.05454389378428459, 0.0, 0.0, 0.0, 0.5823159217834473, 0.5895667672157288, 0.020815409719944, 0.08226528018712997, 0.0, 0.14998582005500793, 0.674720048904419, 0.08389563113451004, 0.0, 0.14357110857963562, 0.9545806050300598, 0.8100276589393616, 0.2762205898761749, 0.0, 0.4176058769226074, 0.3616805672645569, 0.0]), Row(path='s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Pineapple Mini/306_100.jpg', label='Pineapple Mini', features=[0.0, 4.519897937774658, 0.0, 0.0, 0.0, 0.0, 0.3275098204612732, 0.0, 0.0, 0.17494837939739227, 0.0, 0.0, 1.0715562105178833, 0.36303871870040894, 0.0, 0.0, 0.0, 0.05326088145375252, 0.0, 1.126463770866394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.306179404258728, 0.10020910203456879, 0.2900383174419403, 0.0, 0.0, 0.0, 0.010098489932715893, 3.40616774559021, 0.0, 0.45659756660461426, 0.4573262631893158, 0.30560481548309326, 0.060856956988573074, 0.006627168972045183, 0.0, 0.0, 0.0, 0.0, 0.912872850894928, 0.0, 1.375340223312378, 0.7507320046424866, 1.0006153583526611, 0.6533891558647156, 0.3336597681045532, 0.0, 0.0, 0.0, 0.36631789803504944, 1.3029354810714722, 0.0, 0.03059859201312065, 0.6736370921134949, 0.0, 0.08172018826007843, 0.3170064687728882, 0.09383795410394669, 0.6711965799331665, 1.4214173555374146, 4.289317803340964e-05, 0.0, 0.07188713550567627, 0.13227055966854095, 0.03996940329670906, 0.0, 1.6274551153182983, 0.0, 2.5856404304504395, 1.0756924152374268, 1.7188899517059326, 0.4192711114883423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1445217728614807, 0.0939253568649292, 0.0, 0.0, 0.0, 0.017518773674964905, 1.9486567974090576, 0.0, 0.04730280488729477, 0.5344775319099426, 0.020221369341015816, 2.544252634048462, 0.01615101471543312, 0.0, 0.029665356501936913, 0.0, 0.31071048974990845, 1.2533320188522339, 0.2806820273399353, 0.0, 0.0, 0.7702573537826538, 0.0, 0.8352429270744324, 1.8649297952651978, 0.0, 0.015799639746546745, 0.0, 0.020290827378630638, 0.9812017679214478, 1.2077829837799072, 0.2605544328689575, 0.0, 0.7583579421043396, 0.019138379022479057, 0.25950753688812256, 0.1766987442970276, 0.0, 0.0, 0.0, 0.031095528975129128, 0.0, 0.0, 0.20039527118206024, 1.8222599029541016, 0.6035292744636536, 0.11970091611146927, 0.33104386925697327, 0.0, 0.8309524059295654, 0.0, 0.5868727564811707, 0.0, 0.0, 0.0, 1.7410888671875, 0.004302991088479757, 0.0, 0.035291530191898346, 0.005828318651765585, 0.12142626941204071, 0.0, 0.5077714920043945, 0.10027652233839035, 0.0, 0.04240730032324791, 0.0, 0.0, 0.017881646752357483, 1.5819032192230225, 0.0, 0.06616566330194473, 2.1444461345672607, 0.0034546570386737585, 0.054609425365924835, 2.7677695751190186, 0.19516679644584656, 0.0019583238754421473, 2.5281124114990234, 0.0, 0.0, 0.3543357849121094, 0.2838018238544464, 0.0, 2.1273858547210693, 0.0, 0.0, 0.0, 0.0, 1.6314946413040161, 0.0, 0.0, 0.012582805939018726, 1.1870721578598022, 0.0, 0.0, 0.0, 0.022486068308353424, 0.0, 0.9327918887138367, 0.6242891550064087, 0.4843220114707947, 0.0016837274888530374, 0.03759651631116867, 2.079641103744507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12626048922538757, 0.05969041585922241, 0.0, 0.0, 0.0, 0.0, 1.7700743675231934, 0.06549911201000214, 0.13434916734695435, 0.013424423523247242, 0.0, 0.0, 0.0, 0.011089634150266647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06361943483352661, 0.0, 0.057620465755462646, 0.1829967349767685, 0.14487196505069733, 4.9795780796557665e-05, 1.6035027503967285, 0.0, 0.14578405022621155, 0.0, 0.13757316768169403, 0.028279250487685204, 0.13028627634048462, 0.0, 2.985799789428711, 0.21710509061813354, 0.31181010603904724, 0.36732447147369385, 1.9774404764175415, 0.0, 0.0, 0.3104291558265686, 0.0, 0.0, 1.7352708578109741, 0.0, 0.0, 0.15972211956977844, 0.0, 1.2505121231079102, 0.0, 0.4141604006290436, 0.0, 0.07152549922466278, 1.0684109926223755, 0.07670960575342178, 0.0, 0.029618803411722183, 0.0, 0.0, 0.005571771413087845, 2.3310739994049072, 0.991865873336792, 2.3063416481018066, 0.0, 0.03953077644109726, 2.1931087970733643, 0.24609380960464478, 0.0, 0.15236061811447144, 0.0, 0.09057066589593887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04760320857167244, 1.1857606172561646, 0.1254619061946869, 0.008925221860408783, 0.0, 3.447026252746582, 0.06825833767652512, 0.21448779106140137, 0.056734614074230194, 0.44874635338783264, 0.0, 0.0, 0.0, 0.042290180921554565, 0.04074498265981674, 0.0005081320996396244, 2.1127092838287354, 0.0, 0.03322711959481239, 0.16331690549850464, 0.20698142051696777, 0.0, 0.05255141854286194, 0.03228330239653587, 1.224350094795227, 0.0, 0.034579578787088394, 0.013743114657700062, 0.1272999346256256, 0.0, 0.16390031576156616, 0.0, 0.21832753717899323, 0.5096423029899597, 0.0, 0.0, 0.0, 1.3155593872070312, 0.09683024138212204, 0.3987531065940857, 0.0, 0.0, 0.8510999083518982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49012717604637146, 0.009110651910305023, 0.020797429606318474, 0.0, 0.24696478247642517, 0.0, 8.674219861859456e-05, 0.5781550407409668, 1.615090012550354, 0.0, 0.04092711955308914, 0.12794546782970428, 0.34364092350006104, 0.0, 1.400723934173584, 0.0, 0.0, 0.0, 0.0, 0.7087032794952393, 0.024344779551029205, 3.8630526065826416, 2.0311248302459717, 0.08043218404054642, 0.4934934377670288, 0.0, 0.0, 0.5703641772270203, 0.0, 0.0, 0.05087330937385559, 0.0, 0.9196239113807678, 0.0, 0.045666977763175964, 0.005627770908176899, 0.006617108825594187, 0.06198485195636749, 0.029623769223690033, 0.0, 0.0, 0.13457252085208893, 0.3959955871105194, 0.0, 0.10327479243278503, 0.0, 0.03304363787174225, 0.30242374539375305, 0.0, 0.01510579138994217, 0.0, 0.0, 1.219104528427124, 0.12164144963026047, 0.7066525220870972, 0.04238221421837807, 3.3314685821533203, 0.0, 0.0, 0.0, 0.0, 0.23252937197685242, 0.0, 0.21076425909996033, 0.0, 0.04226614162325859, 0.0, 0.0, 0.0, 1.250577688217163, 0.00013216413208283484, 0.0, 0.01071886159479618, 0.0, 0.19109976291656494, 0.017288101837038994, 0.1325322389602661, 0.0, 0.0, 0.0, 0.20188918709754944, 0.0, 1.4361484050750732, 0.0, 0.33936235308647156, 0.0, 0.0, 1.3187073469161987, 0.0, 0.0, 0.6454903483390808, 0.03934379667043686, 0.8400992751121521, 0.00622043339535594, 0.0013004483189433813, 0.19033430516719818, 0.2722487449645996, 0.6994343400001526, 0.30680859088897705, 0.0, 3.2301619052886963, 0.010887420736253262, 0.00720321387052536, 0.006608972791582346, 0.17202387750148773, 0.8010575175285339, 0.0, 0.0, 0.10098164528608322, 0.27578234672546387, 0.0, 0.002521812915802002, 0.0, 0.0, 2.10010027885437, 0.34803494811058044, 0.037693463265895844, 0.0, 0.7096921801567078, 0.13531848788261414, 0.42589378356933594, 2.0571954250335693, 0.3668023347854614, 0.0, 1.8586193323135376, 0.0, 0.06417068839073181, 0.0, 0.0, 0.0, 0.6440097093582153, 0.009186036884784698, 0.0, 0.0, 0.030250003561377525, 0.21721979975700378, 0.0, 0.0, 0.06380834430456161, 2.476827621459961, 0.0, 0.05682379752397537, 1.158889889717102, 0.7614964842796326, 0.45292291045188904, 0.24455463886260986, 0.0, 0.1203819215297699, 0.7624397873878479, 0.08319499343633652, 0.0, 0.0, 3.644407272338867, 0.4416971504688263, 0.0, 3.0941128730773926, 0.0, 0.0, 0.15876056253910065, 0.0, 0.22005024552345276, 0.0, 0.0, 0.40313920378685, 0.0, 0.49689123034477234, 0.6359940767288208, 0.32793569564819336, 0.6557131409645081, 0.09191299229860306, 0.0, 0.0, 0.7807430624961853, 1.7405304908752441, 0.0, 1.598849892616272, 0.03182166814804077, 0.0, 0.0, 0.06941524893045425, 1.2841522693634033, 0.008146623149514198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030240319669246674, 0.1668943613767624, 0.0696096196770668, 0.7129857540130615, 0.1939142942428589, 0.14379413425922394, 0.4882829189300537, 0.0, 0.0, 0.0, 0.0, 1.188669204711914, 0.0, 0.0168587788939476, 0.0, 0.06255117058753967, 0.0, 0.0, 0.4622969329357147, 0.5559238195419312, 0.511553168296814, 0.0, 0.1446743756532669, 0.0, 0.0, 0.27531588077545166, 0.5305987000465393, 0.02003215253353119, 0.0, 0.24349473416805267, 0.001526662614196539, 0.0, 0.01212177611887455, 0.0, 0.0, 0.0, 0.8380895256996155, 1.3646968603134155, 0.0, 0.0, 0.03973250836133957, 0.013344387523829937, 0.19582867622375488, 0.011948288418352604, 0.0, 0.8298518657684326, 0.0, 0.8091692328453064, 0.9889525771141052, 0.0, 0.02399112656712532, 0.22030043601989746, 0.17324011027812958, 0.0, 0.20908991992473602, 0.10362409800291061, 0.17729197442531586, 0.6710020303726196, 0.014774512499570847, 0.03877582401037216, 0.21089479327201843, 0.0, 0.40278100967407227, 2.9070732593536377, 0.0, 0.0, 0.23851750791072845, 0.20915234088897705, 0.0, 0.18473391234874725, 0.002568359486758709, 1.160666823387146, 0.01906443201005459, 0.0, 0.0, 0.0, 0.01239684410393238, 0.0, 0.004295272286981344, 0.0, 0.5144126415252686, 0.2687739431858063, 0.0, 0.0, 2.3985648155212402, 0.0533364936709404, 0.0, 0.002749106613919139, 0.0, 0.007867373526096344, 0.059566009789705276, 1.2900665998458862, 0.0, 3.360267162322998, 1.1620957851409912, 0.0, 0.0, 0.0, 0.4731570780277252, 0.290091872215271, 0.0, 0.4125508666038513, 0.21371226012706757, 0.700833797454834, 0.0, 0.0, 0.31401327252388, 0.0, 0.7805722951889038, 0.01962347887456417, 0.0, 0.0, 0.14659787714481354, 0.6122636795043945, 1.3814468383789062, 0.0, 0.39234161376953125, 0.0, 0.0, 0.0, 0.0, 0.009605772793293, 2.1769638061523438, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1372337341308594, 2.228292226791382, 0.055729564279317856, 0.0, 0.0, 0.15900228917598724, 0.0, 0.0015559762250632048, 0.0, 0.0, 0.0, 0.13261952996253967, 0.0, 0.0, 0.01824577897787094, 0.0, 0.0, 0.0, 0.07714474201202393, 0.022080684080719948, 0.0, 0.0, 0.06122034415602684, 0.06963080912828445, 0.010069329291582108, 0.1600324660539627, 0.0, 0.004903266206383705, 0.0, 0.00477763544768095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.3447394371032715, 0.0, 0.0, 3.5747432708740234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.116104356944561, 0.0, 0.0, 0.0, 0.11035242676734924, 0.050639279186725616, 0.29220980405807495, 0.013663762249052525, 0.043435029685497284, 0.0, 0.0, 0.0, 0.011272271163761616, 2.1120518795214593e-05, 0.1333993822336197, 0.0, 0.0, 0.02799777127802372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15612612664699554, 0.0, 0.014415845274925232, 0.604191780090332, 0.20393140614032745, 1.173142433166504, 0.08551140874624252, 0.2772538661956787, 2.2011218070983887, 0.3140358626842499, 0.41594862937927246, 0.0, 0.0812189057469368, 1.7892826795578003, 0.36488065123558044, 0.027362102642655373, 0.0, 1.4830926656723022, 0.0, 1.4802616834640503, 0.0007344270125031471, 0.001864493009634316, 0.1639426350593567, 0.0, 0.0, 0.07219496369361877, 0.13123786449432373, 0.0, 0.02625940926373005, 1.1452289819717407, 0.967608630657196, 0.0, 0.001919624744914472, 0.0, 0.0, 0.10858828574419022, 0.0, 2.246189594268799, 0.19469445943832397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.975163698196411, 0.0, 0.23678819835186005, 0.03413305804133415, 0.026280507445335388, 0.5601003170013428, 0.0, 1.655932068824768, 0.0, 0.42934954166412354, 0.0, 0.0, 0.0, 0.10582971572875977, 0.1470436006784439, 0.0, 0.0, 2.0626914501190186, 0.00134370441082865, 0.27921807765960693, 0.3682866096496582, 0.07068634033203125, 0.03537353128194809, 1.2184468507766724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0007898834883235395, 0.2893613874912262, 0.061843447387218475, 0.0, 0.0, 0.047481317073106766, 0.0, 0.0, 0.0, 0.0, 0.5335826873779297, 0.08059033751487732, 0.7974146604537964, 0.0, 0.0, 0.0, 0.0, 0.25616443157196045, 0.18138298392295837, 0.0, 0.0, 0.0, 1.720421314239502, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1267688274383545, 0.0, 0.0, 0.0, 3.0728261470794678, 0.0, 0.030355239287018776, 0.0, 0.007410923484712839, 0.17712019383907318, 1.9272964000701904, 0.0, 0.0, 0.0, 0.44441068172454834, 0.0, 0.0, 0.5819579362869263, 0.09282822161912918, 0.2217806726694107, 0.7724752426147461, 0.0, 0.047423627227544785, 0.0, 0.016501564532518387, 0.0, 2.3687586784362793, 0.008580892346799374, 0.0, 0.0, 0.04017001762986183, 0.9050133228302002, 0.0, 0.031757187098264694, 0.0, 1.9013127088546753, 0.2931240200996399, 0.0, 0.526881992816925, 0.0, 0.0, 2.4500033855438232, 0.0, 2.933393716812134, 0.23819375038146973, 0.0, 0.8970413208007812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03211776167154312, 0.0, 0.0, 0.5105835795402527, 0.0, 0.0, 0.0, 0.4428561329841614, 0.03249156475067139, 0.0, 0.11795497685670853, 0.0, 0.0, 0.002684051636606455, 0.008849812671542168, 0.7799274921417236, 0.15340633690357208, 0.031841497868299484, 0.12085756659507751, 0.0, 0.0, 0.7099677324295044, 0.0, 0.0, 0.03395199403166771, 0.6187198162078857, 0.0, 0.007676764391362667, 0.0, 0.8154783248901367, 0.0, 1.2417775392532349, 0.0, 0.5201427340507507, 0.0, 1.390480875968933, 0.0, 0.11491481959819794, 1.0144368410110474, 0.0, 0.29403239488601685, 0.04113238304853439, 0.007198187056928873, 0.0, 0.00018439406994730234, 0.0, 0.6418152451515198, 0.0, 0.0, 0.4239591360092163, 0.1318386346101761, 0.0, 0.1236518919467926, 0.0, 0.0, 0.04095005989074707, 0.021281322464346886, 2.4017481803894043, 0.01044883020222187, 0.0, 0.0, 0.2359803467988968, 0.4319133758544922, 0.47756433486938477, 0.016987284645438194, 0.0, 0.07880467921495438, 0.0, 0.0, 2.894073486328125, 0.07408470660448074, 0.0, 0.4343026578426361, 0.6461931467056274, 0.0, 1.0440970659255981, 0.01951613277196884, 0.0387788787484169, 0.0, 0.5909275412559509, 0.01870543323457241, 0.0, 0.42657673358917236, 0.001607001293450594, 0.22003988921642303, 0.0, 1.9042121171951294, 0.6365125775337219, 0.0, 0.0, 0.3421667814254761, 0.0, 0.08773793280124664, 0.0, 0.0, 0.0, 0.5663579702377319, 0.0, 0.015613381750881672, 0.0003231952723581344, 0.21032360196113586, 0.4853297173976898, 0.0, 0.906514048576355, 0.005250098649412394, 2.522529363632202, 0.5170838236808777, 0.02886197343468666, 0.722194254398346, 5.356032848358154, 0.05292540788650513, 0.0, 0.0, 0.556639552116394, 0.0, 0.0, 0.04602808505296707, 1.2333886623382568, 0.7882494926452637, 0.0, 0.0, 0.03889058902859688, 0.0, 0.01758270151913166, 0.0, 0.0, 0.2702406942844391, 0.0, 0.05295059457421303, 0.106840580701828, 0.0, 0.0, 0.024253297597169876, 0.0, 0.0, 0.0, 1.3591604232788086, 0.2157602310180664, 1.024792194366455, 0.0, 0.0, 0.0, 0.005053712520748377, 1.9608819484710693, 0.0, 0.041323624551296234, 0.1210922822356224, 0.0, 0.022363416850566864, 0.0, 0.0, 0.18496613204479218, 0.4385955333709717, 0.0, 0.12224272638559341, 0.0, 0.33625131845474243, 0.11652041226625443, 0.004082361236214638, 0.0, 0.029542401432991028, 0.012017675675451756, 1.0399998426437378, 0.0, 0.0077326032333076, 0.0, 0.0, 0.0, 1.0515693426132202, 0.0, 1.1626803874969482, 0.0, 0.20666858553886414, 0.0, 0.0, 0.0, 0.22977277636528015, 0.0, 0.1181320920586586, 0.05703241005539894, 0.19888511300086975, 0.5971366167068481, 0.0, 0.2781827449798584, 0.41408511996269226, 3.522275686264038, 0.13372987508773804, 0.0, 0.0, 0.0, 0.09823548048734665, 0.0, 0.0, 0.15760624408721924, 0.11861611157655716, 0.0, 0.926287829875946, 0.0062077706679701805, 0.17469780147075653, 0.018844211474061012, 0.2571243643760681, 0.0, 0.9041869640350342, 0.06327179819345474, 0.0, 0.0, 0.09014499187469482, 0.0, 0.0, 0.0, 0.061071764677762985, 0.03471185639500618, 0.0, 0.20844508707523346, 0.09779433906078339, 1.1602771282196045, 0.04837118461728096, 0.0, 0.0, 0.0, 3.0178565979003906, 0.10188404470682144, 0.42372235655784607, 0.011395423673093319, 0.0, 0.0, 0.0, 0.14869672060012817, 0.6707924008369446, 0.3985782563686371, 0.0, 0.0, 0.0010234066285192966, 0.0, 0.10981715470552444, 0.0, 0.1371358036994934, 0.16018830239772797, 0.08271592855453491, 1.2984730005264282, 0.8200563192367554, 0.0, 0.06757575273513794, 0.45785093307495117, 0.0, 0.0, 0.0, 0.0, 0.07366778701543808, 0.04923168942332268, 0.0, 0.0, 0.12916427850723267, 0.0, 0.03217952698469162, 0.0, 0.0, 0.7974818348884583, 0.5798295140266418, 0.0, 0.0, 0.07290419936180115, 0.9839662909507751, 0.0, 0.33022910356521606, 0.0, 0.0, 0.05344252660870552, 0.995295524597168, 0.0, 1.542892336845398, 0.0, 2.120546817779541, 3.005723714828491, 0.0, 0.9629582762718201, 0.0, 0.0, 0.8242372274398804, 0.32140713930130005, 0.0, 0.022749468684196472, 0.0, 0.0, 0.0, 0.0, 0.13208171725273132, 0.0, 0.5801936984062195, 0.37618088722229004, 1.2794063091278076, 0.0, 1.9610309600830078, 0.0, 0.0, 0.0, 0.05897081270813942, 0.04274524003267288, 0.41528627276420593, 0.0, 0.004227792378515005, 0.0, 0.0, 0.0, 0.25427350401878357, 0.0, 0.0613674633204937, 0.0, 0.2973424196243286, 0.04412864148616791, 0.0, 0.007175877224653959, 0.0, 0.0, 0.0, 0.0, 0.27740678191185, 0.0, 0.3165644407272339, 0.026083074510097504, 0.3569013774394989, 0.0, 0.05429307743906975, 0.05176392197608948, 0.0, 0.5002453327178955, 0.2600215971469879, 0.0, 1.0671709775924683, 0.2108934223651886, 0.03580383211374283, 0.24499200284481049, 0.0, 0.0, 0.14424002170562744, 0.0, 1.7020294666290283, 0.7889732718467712, 2.040755033493042, 1.935882568359375, 0.024621479213237762, 0.1963794231414795, 0.0, 3.7288434505462646, 0.15710018575191498, 0.05152130499482155, 1.9459826946258545, 0.0, 0.0, 0.0, 0.0, 0.012948980554938316, 0.0010053521255031228, 0.0, 0.18217435479164124, 0.2370091676712036, 0.0, 0.30669400095939636, 0.0, 0.0709441751241684, 0.45054715871810913, 0.20782248675823212, 0.7624806761741638, 0.0, 0.18917161226272583, 0.0, 0.12303507328033447, 0.0, 0.0, 0.0, 0.00740831159055233, 1.7568649053573608, 0.0672377273440361, 0.6883171796798706, 0.0, 0.0, 1.4386862516403198, 0.008948498405516148, 0.008418120443820953, 0.08301569521427155, 0.17627444863319397, 0.0, 0.46834567189216614, 0.06691215187311172, 1.1020768880844116, 0.0, 0.07026676833629608, 0.0, 0.0, 1.2083505392074585, 0.016100401058793068, 0.16124863922595978, 0.23562100529670715, 0.009391522035002708, 0.0, 0.13986416161060333, 0.0, 0.5109121203422546, 0.1426357924938202, 0.0, 0.19092267751693726, 0.04162894934415817, 0.0, 0.0, 0.0, 0.9132965803146362, 0.0, 0.0, 0.6582330465316772, 0.7491772174835205, 0.1656855344772339, 0.0, 0.0, 0.018883373588323593, 0.0, 0.30248239636421204]), Row(path='s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Pineapple Mini/293_100.jpg', label='Pineapple Mini', features=[0.0, 4.803103923797607, 0.0215336624532938, 0.0, 0.0, 0.0, 0.1835344433784485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2546320855617523, 0.06608472764492035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14808690547943115, 0.0, 0.0, 0.04184982180595398, 0.0, 0.0, 0.0, 0.0, 0.02536577545106411, 0.16350103914737701, 0.0, 0.0, 0.048277679830789566, 0.0, 2.9013099670410156, 0.0, 1.4038020372390747, 0.06995950639247894, 0.009026162326335907, 0.1621215045452118, 0.0, 0.0, 0.02750084362924099, 0.0, 0.0, 0.9770566821098328, 0.0, 0.10638096928596497, 0.0, 0.47250938415527344, 0.3227442800998688, 0.19045798480510712, 0.1779637485742569, 0.0, 0.0, 0.10011421889066696, 0.461465448141098, 0.0, 0.0, 0.41942963004112244, 0.0, 0.17177659273147583, 0.10609937459230423, 0.2596932053565979, 0.7332760691642761, 0.9959355592727661, 0.050537146627902985, 0.0, 0.7070229053497314, 0.0008394726319238544, 1.041152000427246, 0.0, 1.071577787399292, 0.0, 2.947465658187866, 0.669203519821167, 1.732365369796753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35184016823768616, 0.0, 0.0, 0.0, 0.006540270056575537, 2.1632726192474365, 0.02280510403215885, 0.8795658946037292, 0.5103145241737366, 0.03784133493900299, 2.556790828704834, 0.01787024922668934, 0.0, 0.0, 0.0, 1.5065501928329468, 0.9326131343841553, 0.15630902349948883, 0.0, 0.12472965568304062, 0.10507519543170929, 0.0, 0.6550509929656982, 1.2920048236846924, 0.0, 0.25225546956062317, 0.0, 0.00817862804979086, 0.0, 2.2035443782806396, 0.0, 0.0, 0.13697002828121185, 0.0, 0.0049710203893482685, 0.0, 0.004328457172960043, 0.2539813816547394, 0.0, 0.11408501863479614, 0.0, 0.0, 0.024880480021238327, 2.4747517108917236, 0.014553744345903397, 0.052378714084625244, 0.21855488419532776, 0.0, 0.6346109509468079, 0.0, 0.15033526718616486, 0.0, 0.0, 0.0, 0.01792990230023861, 0.010701943188905716, 0.0, 0.0, 0.0, 0.009615644812583923, 0.0, 0.193599134683609, 0.21072660386562347, 0.0, 0.020729947835206985, 0.0, 0.0, 0.5497273802757263, 0.9025939702987671, 0.0, 0.023102281615138054, 0.6971915364265442, 0.13509094715118408, 0.007259313482791185, 2.879089593887329, 0.08276902139186859, 0.0, 1.7197699546813965, 0.0, 0.05049944296479225, 0.0, 0.5241386890411377, 0.0, 2.2512714862823486, 0.013663959689438343, 0.0, 0.0, 0.3113239109516144, 0.0, 0.0, 0.0, 0.0, 2.1640052795410156, 0.0, 0.0, 0.0638168454170227, 0.0, 0.0, 0.2290928065776825, 0.03374507278203964, 0.019348813220858574, 0.0, 0.0, 2.34417986869812, 0.0, 0.0, 0.0, 0.0, 0.4497997760772705, 0.010697167366743088, 0.0, 0.0, 0.0, 0.0, 0.0, 3.488771677017212, 0.03022782877087593, 0.35739240050315857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0738433226943016, 0.0, 0.015905607491731644, 0.2012929767370224, 0.1791217029094696, 0.0, 1.3754233121871948, 0.0, 0.005998414475470781, 0.0, 0.14247432351112366, 0.28756439685821533, 0.06990620493888855, 0.0, 2.4312450885772705, 0.0, 1.5493149757385254, 0.23536834120750427, 2.088024139404297, 0.0, 0.0, 0.4600584805011749, 0.0, 0.0, 1.0483074188232422, 0.0, 0.0, 0.7298821210861206, 0.0, 0.3567403256893158, 0.0, 0.028093865141272545, 0.0, 0.005465222056955099, 0.375884085893631, 0.0, 0.0, 0.010788314044475555, 0.16812357306480408, 0.0, 0.0, 1.1949604749679565, 0.3164629340171814, 1.4658291339874268, 0.0, 0.0, 0.846703290939331, 0.08811619877815247, 0.0, 0.04578377306461334, 0.011305227875709534, 0.0, 0.0, 0.0016454171855002642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0047851805575191975, 0.21415257453918457, 0.344393253326416, 0.0, 0.04028138145804405, 1.2322218418121338, 0.0, 0.5519917011260986, 0.17073655128479004, 0.0, 0.0, 0.10425366461277008, 0.0, 1.2361469268798828, 0.004680405370891094, 0.0, 1.6403076648712158, 0.0, 0.0, 0.010902097448706627, 0.10842697322368622, 0.0, 0.0, 0.0, 1.0369166135787964, 0.0021948665380477905, 0.0, 0.019959602504968643, 0.27810272574424744, 0.0, 0.5465119481086731, 0.0, 0.03420029953122139, 0.5397419333457947, 0.0, 0.0, 0.0, 0.03606201335787773, 0.21207116544246674, 0.0, 0.0, 0.08350773900747299, 0.6053334474563599, 0.0426662415266037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3289166986942291, 0.011486154049634933, 0.0, 0.0, 0.03400535136461258, 0.0, 0.0, 0.5183825492858887, 1.046663522720337, 0.0, 0.0, 0.22915634512901306, 0.270193487405777, 0.0, 2.2412469387054443, 0.016206640750169754, 0.0, 0.0, 0.0, 0.04425341263413429, 0.0, 2.430288553237915, 1.1078370809555054, 0.0, 1.034482717514038, 0.0, 0.0, 0.021327583119273186, 0.0, 0.0, 0.0, 0.0, 1.0234360694885254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1639544665813446, 0.0, 0.0, 0.0, 0.8703905344009399, 0.0, 0.11671028286218643, 0.0, 0.0, 0.0017122296849265695, 0.0, 0.0, 0.07006050646305084, 0.01025934237986803, 0.05951207876205444, 0.02850860171020031, 0.08852367848157883, 0.0, 2.179003953933716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0448600053787231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6789504885673523, 0.0, 0.5789588689804077, 0.0, 0.0, 0.649617612361908, 0.0, 0.0, 1.6477702856063843, 0.09157272428274155, 1.200082540512085, 0.0, 0.10265680402517319, 0.0988212302327156, 0.001806591055355966, 0.2804808020591736, 0.30294764041900635, 0.0, 3.186729907989502, 0.0, 0.0741843655705452, 0.0, 0.012793722562491894, 1.1893527507781982, 0.0, 0.0, 0.18619894981384277, 0.0958496630191803, 0.0, 0.0, 0.0, 0.0, 1.6566965579986572, 0.07618526369333267, 0.07681084424257278, 0.0, 0.04812445864081383, 0.04501808434724808, 0.03525732830166817, 0.3124385178089142, 0.31391316652297974, 0.0009355110232718289, 1.7449519634246826, 0.0, 0.003580086398869753, 0.012171873822808266, 0.0, 0.0, 0.09877990186214447, 0.02462136186659336, 0.0, 0.0, 0.0, 0.12702740728855133, 0.049985408782958984, 0.0, 0.48760107159614563, 2.0102996826171875, 0.0, 0.037231504917144775, 1.0885621309280396, 0.9563511610031128, 0.0, 0.5483656525611877, 0.0, 0.010639545507729053, 1.2604907751083374, 0.06623823940753937, 0.0, 0.0, 2.0456931591033936, 0.14569468796253204, 0.0, 2.463651180267334, 0.0, 0.02169358730316162, 0.10147421807050705, 0.0, 0.0, 0.0, 0.019104983657598495, 0.10550183802843094, 0.0, 0.20677122473716736, 0.6423596739768982, 0.0, 0.5010549426078796, 0.0, 0.0, 0.0, 0.18102702498435974, 0.42063063383102417, 0.0, 1.8848451375961304, 0.013738262467086315, 0.0, 0.0, 0.0760698914527893, 0.7832416892051697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4294143617153168, 0.08571415394544601, 0.02301393263041973, 0.041529539972543716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05495632439851761, 0.0, 0.0, 4.8069614422274753e-05, 0.15267537534236908, 0.08185511082410812, 0.0, 0.11558010429143906, 0.0, 0.0, 0.027497686445713043, 0.773125410079956, 0.062454625964164734, 0.0, 0.06266828626394272, 0.0, 0.022220252081751823, 0.0, 0.0, 0.0, 0.0, 0.7234349846839905, 0.4583865702152252, 0.0, 0.0, 0.6166536808013916, 0.183882474899292, 0.03726319968700409, 0.0, 0.0, 1.449210524559021, 0.0, 1.220890760421753, 0.9714894890785217, 0.0, 0.0, 0.017559248954057693, 0.11065781116485596, 0.0, 0.09641081839799881, 0.04463359713554382, 0.01558209303766489, 0.23025263845920563, 0.039229437708854675, 0.0490431971848011, 0.005780271254479885, 0.0, 0.03367616608738899, 3.517425537109375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5072048306465149, 0.0, 0.6172646880149841, 0.10909971594810486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13289932906627655, 0.0, 0.984673261642456, 0.5435124039649963, 0.0, 0.0, 1.6390007734298706, 0.4875079095363617, 0.0, 0.0835414007306099, 0.0, 0.0, 0.0, 0.6436920762062073, 0.0, 2.6263630390167236, 0.6679612994194031, 0.0, 0.0, 0.0, 0.3474312126636505, 0.07768070697784424, 0.0, 0.896538257598877, 0.6043335795402527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021127965301275253, 0.11285533756017685, 0.0, 0.0, 0.0, 0.620169997215271, 0.38616514205932617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7042436599731445, 0.05294683948159218, 0.0, 0.0, 0.0, 0.0, 1.6703896522521973, 2.0500330924987793, 0.0, 0.01096619013696909, 0.0, 0.07200386375188828, 0.0, 0.1392238736152649, 0.0, 0.0, 0.0, 0.007662889081984758, 0.15643082559108734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11195474117994308, 0.028628995642066002, 0.0, 0.0, 0.008604822680354118, 0.0, 0.150035098195076, 0.5738561749458313, 0.0, 0.11851108074188232, 0.0, 0.0, 0.0, 0.0, 0.026245413348078728, 0.0, 0.0, 0.0, 2.1204733848571777, 0.0, 0.0, 3.8438661098480225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15757068991661072, 0.2166806012392044, 0.0, 0.0, 0.16787844896316528, 0.0, 0.0, 0.0, 0.0, 0.032310884445905685, 0.015876764431595802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009460078552365303, 0.0, 0.0, 0.33463478088378906, 0.4337138831615448, 0.07979238033294678, 0.0, 0.41695618629455566, 0.8186319470405579, 0.43680524826049805, 0.15285678207874298, 0.0, 0.0, 0.9953203797340393, 0.02220832370221615, 0.0, 0.0, 0.5660189986228943, 0.0, 0.9320136308670044, 0.0, 0.0025248443707823753, 0.0022195149213075638, 0.05899396166205406, 0.0, 0.0, 0.0035206449683755636, 0.0, 0.013773247599601746, 0.5939072370529175, 0.19844716787338257, 0.0, 0.4700431525707245, 0.0, 0.003904948942363262, 0.025622423738241196, 0.0, 1.0691720247268677, 0.0, 0.049856316298246384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8856537342071533, 0.0, 0.0, 0.000576443737372756, 0.0, 0.10862475633621216, 0.0, 1.188864827156067, 0.06890013068914413, 0.0004900177591480315, 0.0, 0.0, 0.0, 0.26144877076148987, 0.35400834679603577, 0.0, 0.0, 2.2124035358428955, 0.0, 0.0, 0.0027950217481702566, 0.0, 0.10302326828241348, 0.346960186958313, 0.0, 0.0, 0.5518690943717957, 0.0, 0.0, 0.09069976210594177, 0.5284668207168579, 0.33135831356048584, 0.0, 0.0, 0.06995539367198944, 0.0, 0.0, 0.0, 0.0, 0.7591677904129028, 0.01133534125983715, 0.20857784152030945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7634085416793823, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0370820760726929, 0.0, 0.0, 0.0, 1.233371376991272, 0.0, 0.014362363144755363, 0.0, 0.0, 0.14511387050151825, 0.8918705582618713, 0.0, 0.0, 0.0, 0.023660367354750633, 0.0, 0.0, 0.39581120014190674, 0.11514905095100403, 0.20020003616809845, 0.0048700799234211445, 0.08787130564451218, 0.013537921011447906, 0.0, 0.06030265986919403, 0.0, 2.4162442684173584, 0.5221093893051147, 0.0, 0.0, 0.0, 1.210208773612976, 0.0, 0.0, 0.0, 2.1216602325439453, 0.5889165997505188, 0.0, 1.3767186403274536, 0.0, 0.0, 3.2892472743988037, 0.0, 3.609837532043457, 0.42524588108062744, 0.0, 0.4760971963405609, 0.0, 0.0, 0.0, 0.0, 0.07760931551456451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8155657649040222, 0.0, 9.743876034917776e-06, 0.0, 0.061435699462890625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027307001873850822, 0.032840825617313385, 0.4509778618812561, 0.8826537728309631, 0.05805697292089462, 0.28749531507492065, 0.0, 0.0, 0.23935872316360474, 0.02728116698563099, 0.0, 0.025747641921043396, 0.4613457918167114, 0.0, 0.047413136810064316, 0.0, 0.882060706615448, 0.0, 0.49462437629699707, 0.003779652528464794, 2.3108878135681152, 0.0, 0.7669214606285095, 0.0, 0.1913088709115982, 0.11141879856586456, 0.0, 0.0, 0.06689318269491196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06778953224420547, 0.0, 0.6026017665863037, 0.0, 0.0, 0.01005616970360279, 0.02016332559287548, 0.0, 0.0, 0.0, 2.379715919494629, 0.03553483262658119, 0.0, 0.0, 0.0, 0.5555739998817444, 0.5351875424385071, 0.0, 0.0, 0.025230199098587036, 0.0, 0.0, 2.6572213172912598, 0.15568961203098297, 0.0, 0.5139563679695129, 0.10896295309066772, 0.0, 0.22702623903751373, 0.0, 0.2322903871536255, 0.0, 0.13784804940223694, 0.8396744728088379, 0.0, 0.10188785940408707, 0.018974071368575096, 0.05336993560194969, 0.007675003260374069, 1.1767981052398682, 0.3400672972202301, 0.0, 0.0, 0.10983669757843018, 0.0035810319241136312, 0.07095726579427719, 0.0, 0.0, 0.0, 0.11278010159730911, 0.0, 0.0, 0.0011424815747886896, 0.5593600869178772, 0.17673398554325104, 0.0, 0.48269984126091003, 0.0, 2.807482957839966, 0.308475136756897, 0.14907249808311462, 0.31852519512176514, 4.021066665649414, 0.026748718693852425, 0.0, 0.0, 0.024376187473535538, 0.0, 0.0, 0.15407389402389526, 0.4686284065246582, 0.007323838770389557, 0.0, 0.0, 0.28447064757347107, 0.0, 0.6287944316864014, 0.0, 0.0, 0.030771011486649513, 0.011455044150352478, 0.007602929603308439, 0.022033462300896645, 0.051511287689208984, 0.0, 0.02504783682525158, 0.0, 0.0, 0.0, 0.8838430643081665, 1.5550731420516968, 1.4482954740524292, 0.0, 0.00030015979427844286, 0.0, 0.06479714810848236, 1.1280885934829712, 0.0, 0.0, 0.058384910225868225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15807892382144928, 0.0, 0.01131668221205473, 0.0, 0.4060310423374176, 0.2521190941333771, 0.0, 0.0, 0.03269461169838905, 0.0, 1.227516531944275, 0.0, 0.030284402891993523, 0.006928448565304279, 0.0, 0.0, 1.1173501014709473, 0.006772111169993877, 0.22860464453697205, 0.1941843181848526, 0.09335464239120483, 0.0, 0.0, 0.011829357594251633, 0.37616950273513794, 0.0, 0.06450574845075607, 0.00518769072368741, 0.3894990086555481, 0.6753720641136169, 0.0, 0.3292884826660156, 0.8063611388206482, 3.182616949081421, 0.0, 0.0, 0.0, 0.0, 0.2010907530784607, 0.0, 0.013034011237323284, 0.0, 0.4866408407688141, 0.15501224994659424, 1.0136207342147827, 0.0, 0.0, 0.05448351427912712, 0.047606632113456726, 0.0, 1.3047125339508057, 0.0, 0.015697160735726357, 0.0, 1.218950867652893, 0.0, 0.0, 0.0, 0.7901978492736816, 0.0, 0.0, 0.2725990116596222, 0.24281112849712372, 0.2898011803627014, 0.0194521676748991, 0.0, 0.0, 0.0, 2.871464252471924, 0.0, 0.24618364870548248, 0.0, 0.0, 0.0, 0.0, 0.010695474222302437, 0.11809832602739334, 0.0022628449369221926, 0.0, 0.0, 0.036470163613557816, 0.0, 0.0, 0.0, 0.0, 0.1794942319393158, 0.04436105117201805, 0.8864179849624634, 0.3493674397468567, 0.0, 0.021844618022441864, 0.0, 0.0, 0.042552269995212555, 0.0, 0.0, 0.0003055440611205995, 0.09297183901071548, 0.0, 0.0, 0.6860310435295105, 0.0, 0.21578824520111084, 0.0, 0.0, 0.4611923396587372, 0.5428062677383423, 0.0, 0.0, 0.0, 0.6168598532676697, 0.0, 0.2095111608505249, 0.0, 0.0, 0.0, 0.22060370445251465, 0.0, 1.1449267864227295, 0.0, 0.48564985394477844, 3.1416187286376953, 0.0, 0.17053593695163727, 0.0, 0.22393272817134857, 0.09310072660446167, 0.024272378534078598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011276770383119583, 0.0, 0.33798810839653015, 0.36367547512054443, 0.05363263562321663, 0.0, 1.1889090538024902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05867835134267807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7209446430206299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014922852627933025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055893171578645706, 0.0, 0.5866736173629761, 0.0, 0.02483421191573143, 0.0, 0.0, 0.7268983721733093, 0.16279858350753784, 0.0, 1.314706563949585, 0.004488065373152494, 0.0048971581272780895, 0.0, 0.0, 0.0, 0.6070774793624878, 0.0, 1.5866438150405884, 0.8300765156745911, 2.089146614074707, 1.4051225185394287, 0.026738174259662628, 0.12531596422195435, 0.0, 3.6709372997283936, 0.0, 0.2367095947265625, 0.7476726174354553, 0.0, 0.0, 0.0, 0.0, 0.021572193130850792, 0.08090438693761826, 0.0, 0.10039978474378586, 0.03484049439430237, 0.0, 0.2411963790655136, 0.0, 0.0042358627542853355, 0.23348413407802582, 0.0, 0.20709078013896942, 0.0, 0.0030004926957190037, 0.0, 0.24724170565605164, 0.0, 0.0, 0.0, 0.0, 0.533933699131012, 0.004339316859841347, 0.38202807307243347, 0.0, 0.0, 0.8804352283477783, 0.0, 0.0, 0.02133350633084774, 0.025973334908485413, 0.0, 0.5769692063331604, 0.04827708750963211, 0.21478335559368134, 0.0, 0.016675079241394997, 0.0, 0.0, 0.042503055185079575, 0.011420554481446743, 0.006083981599658728, 0.11031612753868103, 0.0, 0.0, 0.06678014993667603, 0.0, 1.2750091552734375, 0.03630465269088745, 0.0, 0.1064315214753151, 0.03422136977314949, 0.0, 0.0, 0.027663081884384155, 0.4653952121734619, 0.0, 0.011522973887622356, 0.06364837288856506, 0.06021345034241676, 0.05332835018634796, 0.0, 0.0, 0.0, 0.0, 0.00010968357673846185]), Row(path='s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/244_100.jpg', label='Watermelon', features=[0.0008366271504200995, 0.015711862593889236, 0.0, 0.0, 1.377039909362793, 0.009202299639582634, 2.292727470397949, 0.17242003977298737, 0.0, 0.0, 0.26512742042541504, 0.47811663150787354, 0.06515276432037354, 2.214724063873291, 0.09131404012441635, 0.14684785902500153, 0.0, 0.0, 0.576069712638855, 0.20559678971767426, 0.1889733076095581, 0.0, 0.0, 0.0, 0.0, 0.12623979151248932, 0.35163164138793945, 0.0, 0.0, 1.7819304466247559, 0.0, 0.08950545638799667, 0.01709272898733616, 0.9051361083984375, 0.0, 0.21794109046459198, 0.2582228183746338, 0.5499575138092041, 0.022851713001728058, 0.0, 0.0, 0.0, 1.8697391748428345, 0.0, 0.12502002716064453, 0.0, 0.3145841360092163, 0.18007414042949677, 1.535086750984192, 0.20678628981113434, 0.0, 0.38218462467193604, 0.21990202367305756, 0.0, 0.0, 0.830910325050354, 0.007991638034582138, 1.3234394788742065, 0.0, 0.009026381187140942, 1.7496088743209839, 0.8646087646484375, 0.0653090551495552, 0.0, 1.9142544269561768, 1.7053018808364868, 2.4414238929748535, 0.056518904864788055, 0.014167288318276405, 0.0, 0.0, 0.03953060135245323, 0.003626945661380887, 0.4540356993675232, 0.17458800971508026, 1.2773751020431519, 0.018496107310056686, 0.4568069577217102, 0.15252919495105743, 0.05477766692638397, 0.0, 1.2555861473083496, 0.0, 0.010962960310280323, 0.12516924738883972, 0.0, 0.0, 0.46350911259651184, 1.0061542987823486, 0.3712189197540283, 1.019954800605774, 0.0, 0.5398405194282532, 0.0, 1.045419454574585, 0.02076026052236557, 0.0, 0.0, 1.3694578409194946, 0.00010452308197272941, 0.006314503960311413, 0.1998848021030426, 0.0, 0.019567299634218216, 0.3656841218471527, 0.0, 0.0, 0.4519844949245453, 0.0, 1.750374674797058, 0.1914348155260086, 0.0, 0.0, 0.0, 0.0, 0.046719975769519806, 0.3879390358924866, 0.0, 0.017843768000602722, 0.04993788152933121, 0.18369445204734802, 0.0, 0.0, 0.6908779740333557, 0.0, 0.9170090556144714, 1.7897205352783203, 0.8217435479164124, 1.463564157485962, 0.4790210425853729, 0.0, 0.9632247686386108, 0.7738902568817139, 0.011570027098059654, 0.029160499572753906, 0.0, 0.0, 0.0, 0.012491244822740555, 0.2058955579996109, 0.0, 0.0, 0.029278118163347244, 0.05164045840501785, 0.0, 0.0, 0.724614143371582, 1.5044623613357544, 0.06212474778294563, 0.900969386100769, 0.0, 0.0, 0.0, 0.0, 0.005941339768469334, 0.3261535167694092, 0.0, 0.0, 1.659090518951416, 0.004587136209011078, 0.0, 0.0, 0.0, 0.0028463678900152445, 1.554227352142334, 1.5904138088226318, 0.7375710010528564, 0.19895602762699127, 1.8842047452926636, 1.4232853651046753, 0.029765769839286804, 0.010039637796580791, 0.4381124675273895, 0.0, 0.0, 0.06304755061864853, 0.5487627387046814, 0.17122037708759308, 0.04019380360841751, 0.10288749635219574, 2.637756586074829, 0.0, 1.148184061050415, 0.0, 0.3869318664073944, 0.5414882302284241, 0.7562864422798157, 0.042731985449790955, 0.0, 0.0, 0.26011520624160767, 0.07612752914428711, 1.7199410200119019, 1.9320179224014282, 0.2520413398742676, 0.0, 0.0, 0.0, 0.0, 0.008494631387293339, 0.4258037209510803, 0.0, 0.2848162055015564, 0.06804441660642624, 1.4666008949279785, 0.00746800284832716, 0.0, 0.0, 0.1581520140171051, 0.36117854714393616, 0.0, 0.0, 0.0, 0.10189340263605118, 0.4096291661262512, 0.6457579731941223, 0.0, 0.0, 0.30408093333244324, 0.0, 0.19484607875347137, 0.0, 0.05859260633587837, 0.2296580821275711, 0.1616889089345932, 0.23209896683692932, 0.04402891546487808, 0.0, 0.8030931949615479, 0.09673698246479034, 1.5823699235916138, 0.27803677320480347, 0.06226066127419472, 0.21916615962982178, 0.6046240925788879, 0.15328720211982727, 0.0, 0.0, 0.0, 1.2565021514892578, 2.3712406158447266, 0.09772632271051407, 0.0, 0.0020958413369953632, 0.05270104110240936, 0.0, 1.3632593154907227, 0.667015016078949, 0.465483695268631, 0.060978323221206665, 0.12359260022640228, 0.15290361642837524, 1.7773618698120117, 0.0, 1.4127843379974365, 2.1610801219940186, 2.112656354904175, 0.3393631875514984, 0.0, 0.8111779093742371, 0.0, 2.5186593532562256, 0.028127335011959076, 1.2873363494873047, 0.010165303014218807, 0.16660644114017487, 0.0, 0.0, 0.0, 0.2121463119983673, 0.27482059597969055, 0.0, 1.6799956560134888, 0.0, 0.36090219020843506, 0.06231168657541275, 0.045908063650131226, 0.0, 0.18180236220359802, 0.3902144134044647, 1.3237860202789307, 0.0, 0.1337139904499054, 0.011614176444709301, 1.7034603357315063, 0.0, 0.0, 0.0003537591255735606, 1.5012719631195068, 1.1974358558654785, 0.060309749096632004, 0.09852010011672974, 0.0, 0.0, 0.0, 1.611058235168457, 0.0808015689253807, 0.21340815722942352, 0.20309962332248688, 0.05696911737322807, 0.0, 0.0, 0.6032941937446594, 0.0012858454138040543, 0.2803836464881897, 0.0, 0.0, 0.0, 0.0, 0.7833715677261353, 0.5026565790176392, 0.017411457374691963, 0.34119972586631775, 0.008520425297319889, 0.2240179181098938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.360673427581787, 1.3433908224105835, 0.920379638671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06389050930738449, 0.0, 0.14189299941062927, 2.400068521499634, 0.0, 0.0, 0.7680155038833618, 0.0, 0.0, 0.17353986203670502, 0.5631608963012695, 0.0, 0.0, 0.18908551335334778, 0.31093263626098633, 0.10848692804574966, 0.595889687538147, 0.7636644244194031, 0.0, 0.050372231751680374, 0.0, 0.0, 0.12916260957717896, 0.0, 1.3457831144332886, 0.0, 0.05020074546337128, 0.0, 0.0, 0.7899788618087769, 1.3776235580444336, 0.20301149785518646, 0.42034411430358887, 0.14494645595550537, 1.1942799091339111, 0.0, 0.017844395712018013, 0.24330571293830872, 0.0, 0.0, 0.08565329760313034, 0.0, 0.18811266124248505, 0.009173750877380371, 0.0, 3.7039852142333984, 0.0, 0.2525240182876587, 0.07494431734085083, 0.2282552719116211, 0.0, 0.0, 1.4725897312164307, 0.1726405918598175, 0.0, 0.0375504232943058, 0.0, 0.754126787185669, 0.0, 0.0, 0.6153837442398071, 1.886104941368103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3754918873310089, 0.0, 0.03994499519467354, 0.6603344678878784, 0.8912447690963745, 0.10526898503303528, 0.0, 0.0, 0.0, 0.29661181569099426, 0.0465521439909935, 0.1507914960384369, 0.1776176244020462, 0.0, 3.4617557525634766, 3.086764335632324, 0.0, 0.22479280829429626, 0.11042734980583191, 0.008352943696081638, 0.028037095442414284, 0.8703801035881042, 0.04438646882772446, 3.9218239784240723, 0.009257569909095764, 2.0833239555358887, 0.8089772462844849, 0.060318008065223694, 0.042177628725767136, 0.03857172653079033, 1.6154814958572388, 0.007027247920632362, 0.0, 0.12506991624832153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09595637768507004, 0.0, 0.009631650522351265, 0.017704064026474953, 0.0, 0.0, 0.14987967908382416, 1.3381274938583374, 2.0777976512908936, 2.0600216388702393, 0.07660502940416336, 0.02583485282957554, 0.008878890424966812, 0.011449314653873444, 0.0, 0.0, 0.8167799115180969, 0.2684798240661621, 0.27726906538009644, 1.844956398010254, 0.1201397031545639, 0.0, 0.030834903940558434, 0.0, 0.01002617459744215, 1.244850754737854, 0.0, 0.0, 0.06410279124975204, 0.7775672078132629, 0.0, 2.1876394748687744, 0.27225762605667114, 1.2568968534469604, 0.0, 0.2379671335220337, 0.0, 0.0, 3.40541672706604, 0.702154815196991, 0.17468136548995972, 0.08436211943626404, 0.0, 0.0, 3.816375494003296, 0.10900704562664032, 0.3886823058128357, 0.0, 2.0050032138824463, 0.6497569680213928, 0.018884165212512016, 0.8393205404281616, 2.713165044784546, 0.025469833984971046, 0.7271459698677063, 1.6084980964660645, 0.0, 0.0, 2.354992389678955, 2.496267795562744, 0.0, 0.0, 0.07346480339765549, 0.892792284488678, 0.0, 0.00019577989587560296, 0.20227742195129395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3780997097492218, 0.5619450211524963, 0.572350025177002, 0.0, 0.0, 0.17275898158550262, 0.06486152112483978, 0.0, 0.21203242242336273, 0.06368623673915863, 0.0, 0.0, 0.7871792316436768, 0.0, 0.2398458570241928, 0.0, 0.0, 0.03841796889901161, 0.0, 1.6911380290985107, 0.2307399958372116, 0.0, 0.714268147945404, 0.0, 0.0, 0.44915539026260376, 0.555842936038971, 0.0, 0.0, 0.11472011357545853, 0.0, 0.042825933545827866, 0.0, 0.915703296661377, 0.002849837765097618, 0.04382810369133949, 0.0, 0.13384397327899933, 0.1857251077890396, 0.16618497669696808, 1.00408136844635, 0.9447084665298462, 0.0, 0.0, 0.0, 0.1568703055381775, 0.22144044935703278, 0.09817259013652802, 0.11147801578044891, 1.4707095623016357, 2.272351026535034, 0.03294692188501358, 0.0, 2.035909414291382, 0.26825323700904846, 0.12342403084039688, 0.0, 0.28920605778694153, 0.0, 0.274374783039093, 0.0, 0.036822717636823654, 0.021350303664803505, 0.0, 0.0, 0.7870554327964783, 0.0052993097342550755, 0.9293612241744995, 0.509951651096344, 0.0, 1.5505330562591553, 0.0, 0.0, 0.0, 0.0, 0.0265353973954916, 0.0, 0.22256115078926086, 0.0, 0.9642606377601624, 0.8281031250953674, 2.0991456508636475, 0.8911226987838745, 0.0, 1.9109328985214233, 0.010641670785844326, 0.0, 0.0, 2.7807416915893555, 0.21142177283763885, 0.0012233832385390997, 0.13933971524238586, 0.0, 0.3287010192871094, 0.07977975159883499, 0.0, 0.008861667476594448, 0.0, 0.8042426705360413, 0.0, 1.360025405883789, 1.276574730873108, 0.7337849736213684, 0.0, 0.0, 2.245805025100708, 0.4198363423347473, 2.079415798187256, 0.3353298008441925, 0.43107375502586365, 0.0, 0.041022710502147675, 3.4807322025299072, 0.22677986323833466, 0.1124303936958313, 0.03904787451028824, 0.0, 1.1601853370666504, 0.0, 0.09597831964492798, 0.0, 0.2645483911037445, 0.007585414219647646, 0.5463737845420837, 0.0, 0.0, 0.48835182189941406, 0.744172215461731, 0.08156421035528183, 0.2939515709877014, 1.5781036615371704, 0.0, 0.0, 2.977604389190674, 0.7078729867935181, 0.0, 0.44250795245170593, 0.0, 0.13564486801624298, 1.673290491104126, 0.0, 0.006860033608973026, 0.14106164872646332, 0.0, 0.0, 0.9199658036231995, 0.0, 0.5135799050331116, 0.267449289560318, 0.0, 0.0, 0.6193298697471619, 2.378436803817749, 0.0, 0.0, 0.017055954784154892, 0.7501537799835205, 0.0, 0.0, 0.29216694831848145, 1.7510908842086792, 1.7011688947677612, 0.0, 2.6558632850646973, 1.188607096672058, 0.23420065641403198, 0.0852477177977562, 0.15769289433956146, 0.059722237288951874, 0.1090962365269661, 0.0, 0.002445829566568136, 0.06164703145623207, 0.0, 0.3676958382129669, 0.010858246125280857, 0.4237959682941437, 0.11370232701301575, 0.1183919906616211, 0.6935421824455261, 1.8085943460464478, 1.6286026239395142, 0.0, 0.0, 0.0, 2.838775396347046, 0.0, 0.0, 0.0190004650503397, 0.0, 0.03938283771276474, 0.0, 0.00784269068390131, 0.2859930694103241, 0.0, 0.0, 0.01751222461462021, 1.6333221197128296, 0.3457919657230377, 0.0, 0.0, 0.0, 0.5055125951766968, 2.238633871078491, 0.4230745732784271, 0.5101439952850342, 1.2266175746917725, 0.0, 0.18720431625843048, 0.1897004246711731, 0.6227861642837524, 0.27993056178092957, 0.03794969990849495, 0.10272716730833054, 0.0, 0.1964617222547531, 2.2323527336120605, 1.5534590482711792, 0.0, 0.0, 0.9610095620155334, 0.0, 1.7370001077651978, 0.5216097235679626, 0.0, 0.0, 0.23126085102558136, 0.6390781402587891, 0.0, 0.20322398841381073, 0.0, 3.2754273414611816, 0.5053076148033142, 0.4091816246509552, 0.11225361377000809, 0.13614016771316528, 0.08571231365203857, 0.0, 0.8203298449516296, 0.0046730744652450085, 0.0, 0.0, 0.0, 0.060771115124225616, 1.963887095451355, 0.9892905950546265, 0.26676467061042786, 2.1902523040771484, 0.41216039657592773, 1.6771974563598633, 0.006562567315995693, 0.0, 0.0, 2.082603693008423, 0.0, 0.0, 0.20098640024662018, 0.20033901929855347, 0.3182346522808075, 1.3040636777877808, 0.0, 0.002496971283107996, 0.1710459291934967, 0.044637713581323624, 0.5355691909790039, 0.0, 0.1557951420545578, 0.3372494876384735, 0.8109186887741089, 0.0, 0.04221048578619957, 1.6282200813293457, 0.0, 0.09179946035146713, 0.41300833225250244, 0.017963428050279617, 0.0, 0.0, 0.0, 0.4482065737247467, 0.0, 0.3059253394603729, 1.6591182947158813, 0.334464430809021, 0.31994882225990295, 0.03150623291730881, 0.0, 0.0, 0.0, 0.07897185534238815, 0.06237129867076874, 0.5570303797721863, 0.0, 0.0, 0.012789302505552769, 0.0, 0.015298550017178059, 0.0, 0.014577483758330345, 0.0, 0.0643499344587326, 0.04753033444285393, 0.01100187748670578, 0.0, 0.10626586526632309, 0.19377776980400085, 0.15805064141750336, 0.0, 0.0, 0.0, 0.0, 0.09777447581291199, 0.00486837700009346, 0.0, 0.006109323818236589, 0.8333278298377991, 0.9191135764122009, 0.0, 3.2174031734466553, 0.6192871332168579, 0.208614781498909, 0.5373350381851196, 0.09822484105825424, 0.040624216198921204, 0.04936810955405235, 0.0, 0.06561237573623657, 0.04808669537305832, 0.0, 1.4911530017852783, 0.4611012935638428, 0.013639545999467373, 0.1192331537604332, 0.42938166856765747, 1.7998982667922974, 0.23037034273147583, 0.1329129934310913, 0.0, 0.1937357485294342, 0.031585536897182465, 0.0, 0.03156743943691254, 2.8204598426818848, 0.0, 0.0, 0.0, 0.0, 2.964322805404663, 0.0, 0.0, 0.00012757949298247695, 0.006464061792939901, 0.0, 0.041719838976860046, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0782008171081543, 0.32238197326660156, 0.0, 0.0, 0.2786695659160614, 0.06615114957094193, 0.008791493251919746, 0.0, 0.0, 0.0, 0.0, 0.11421997845172882, 0.017038175836205482, 0.0, 1.3285236358642578, 0.016181249171495438, 0.4820154905319214, 0.0, 1.2369136810302734, 0.0, 0.0, 0.042400021106004715, 0.0, 0.0, 0.0, 0.6232469081878662, 0.21705247461795807, 0.0, 0.0, 0.07465953379869461, 0.0, 0.0, 0.16177800297737122, 0.9346979856491089, 0.1143554151058197, 0.0, 0.6364397406578064, 0.04004741087555885, 0.0, 0.0, 0.0, 0.0029364963993430138, 0.0, 0.0, 0.0, 0.23431894183158875, 0.18847288191318512, 0.0, 0.00044604376307688653, 0.49686163663864136, 0.0, 0.0, 0.0, 0.18923532962799072, 0.7605143785476685, 2.886309812311083e-05, 0.023529723286628723, 0.35355979204177856, 0.2292190045118332, 0.0, 0.0, 0.01645520143210888, 0.0, 0.0, 0.05097702145576477, 0.6501149535179138, 0.0, 0.08854148536920547, 0.7532260417938232, 0.07238569855690002, 0.0, 0.0, 0.0, 0.5817498564720154, 0.0, 0.4030981659889221, 0.21907824277877808, 0.07196244597434998, 2.9729135036468506, 0.0, 0.5234335064888, 0.012470543384552002, 0.4675198793411255, 0.5360432863235474, 0.5898091197013855, 0.0, 0.667455792427063, 1.9127355813980103, 2.705383539199829, 0.06084778904914856, 0.009473569691181183, 0.18458221852779388, 0.0, 0.04867790639400482, 0.0, 0.07620038837194443, 1.054672122001648, 0.0, 0.00611520791426301, 0.983650803565979, 0.0, 0.0, 0.012468533590435982, 0.4260956645011902, 0.760924756526947, 2.5803003311157227, 0.42663437128067017, 0.0, 0.12366420030593872, 1.1692038774490356, 0.26878708600997925, 2.2362096309661865, 0.0, 0.3482878804206848, 1.6800380945205688, 0.03819499537348747, 0.21501895785331726, 0.05775611847639084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6941250562667847, 0.0, 1.4745371341705322, 0.05118361860513687, 0.0, 0.12240888923406601, 0.9946920275688171, 0.0, 1.5793321132659912, 0.0, 0.1698153018951416, 0.3544427156448364, 0.0, 0.12169047445058823, 1.3355467319488525, 0.24800236523151398, 0.26435187458992004, 0.0, 0.08681303262710571, 0.0, 0.15979182720184326, 0.0, 0.7673392295837402, 0.6969268918037415, 0.4016682803630829, 0.9913192391395569, 0.25841015577316284, 0.819608211517334, 0.0, 0.668445885181427, 2.157623291015625, 0.0, 0.015981068834662437, 0.014199169352650642, 0.0827682763338089, 0.27947932481765747, 0.5595244765281677, 0.4636082649230957, 0.2020951360464096, 0.0, 0.1441602259874344, 0.6864047646522522, 0.25434786081314087, 1.3513132333755493, 0.0, 0.0, 0.0, 0.09509295970201492, 0.0, 0.8914090394973755, 0.0, 0.02494937740266323, 0.0, 1.6431951522827148, 0.050194233655929565, 0.0, 1.3172059059143066, 0.0, 0.8588381409645081, 0.2525269687175751, 0.0, 0.003045859979465604, 1.4496129751205444, 2.7501089572906494, 0.20201459527015686, 0.535456120967865, 3.233602523803711, 0.0, 0.0, 1.0927900075912476, 0.0038697661366313696, 0.21306852996349335, 0.0, 0.00010870936239371076, 0.0, 1.6743841171264648, 0.0, 1.1395381689071655, 0.6773055195808411, 0.16563168168067932, 0.32859355211257935, 0.0, 0.5364540815353394, 0.0, 0.005611806642264128, 0.0, 1.6971306800842285, 0.10759639739990234, 0.0, 0.6882568001747131, 0.042482297867536545, 0.0, 0.019951989874243736, 0.26291757822036743, 0.0, 0.0, 0.6159170866012573, 1.588943362236023, 0.002820881549268961, 0.5749527812004089, 0.8185685873031616, 0.03742852061986923, 1.584891676902771, 0.0, 0.0, 0.0, 0.7222152352333069, 0.0027637421153485775, 0.18572725355625153, 0.0, 0.5464125871658325, 1.7567027807235718, 1.4788979291915894, 0.0, 0.00949558150023222, 0.0, 0.1693941205739975, 0.0, 0.0, 0.2627089023590088, 0.0, 0.21242789924144745, 1.1744744777679443, 0.8335253596305847, 0.07694031298160553, 0.04781561344861984, 0.26480594277381897, 1.4506012201309204, 0.0, 0.0, 0.021494116634130478, 1.4242830276489258, 0.0, 0.0, 0.018566781654953957, 0.6596765518188477, 0.11165967583656311, 0.028652174398303032, 1.4206838607788086, 0.704767644405365, 0.0, 0.005688617937266827, 0.034010887145996094, 1.0453381538391113, 0.0, 2.115880250930786, 0.848527193069458, 0.0, 0.0, 0.0, 0.0, 2.6021008491516113, 1.3005893230438232, 0.0055607459507882595, 1.8512722253799438, 0.0, 0.0, 0.02143268659710884, 0.0, 1.845603108406067, 0.9253566265106201, 0.3411799967288971, 0.07464686036109924, 0.2636975944042206, 0.04436447098851204, 2.1213550567626953, 0.013659973628818989, 0.3657909333705902, 0.33803126215934753, 0.32121768593788147, 0.1137702688574791, 0.02682342380285263, 0.0, 0.013056044466793537, 0.41339555382728577, 0.0, 0.0, 0.0, 0.0, 0.25227847695350647, 0.0, 0.9071546792984009, 0.0, 0.0, 0.09821131080389023, 0.5947337746620178, 1.750221848487854, 0.0, 0.0, 0.13788743317127228, 0.5282348990440369, 1.140602707862854, 0.061752475798130035, 0.07574301958084106, 0.07333778589963913, 0.0, 0.5922689437866211, 0.37619757652282715, 0.4433099031448364, 0.13978087902069092, 0.0, 0.0072310431860387325, 0.2658260464668274, 0.14470984041690826, 1.2851282358169556, 0.7765311598777771, 0.0, 0.08974195271730423, 0.48616039752960205, 0.3792524039745331, 0.0, 0.6020088791847229, 0.9421617984771729, 0.3982490599155426, 0.0, 0.0, 0.017469948157668114, 0.772204577922821, 0.25923672318458557, 0.01445162296295166, 0.13299357891082764, 0.0, 1.7402114868164062, 0.0, 0.0, 0.1982083022594452, 0.048607535660266876, 0.32676419615745544, 0.5480994582176208, 0.0, 1.2375112771987915, 0.14744219183921814, 0.49997416138648987, 0.031002817675471306, 0.0, 0.3556542992591858, 0.11177625507116318, 1.4463273286819458, 0.06256717443466187, 0.5307375192642212, 0.007190539967268705, 0.0, 0.47804906964302063, 2.687157392501831, 0.18601137399673462, 0.38987669348716736, 0.0, 0.0, 0.13534145057201385, 0.9149937033653259, 0.32143014669418335, 0.4426257014274597, 0.15035900473594666, 0.0, 0.0, 0.0, 0.47552478313446045, 0.1145029366016388, 0.0, 0.015297528356313705, 0.15367990732192993, 0.016052531078457832, 0.03722304105758667, 0.009044100530445576, 0.9339260458946228, 0.30559027194976807, 0.34565895795822144, 0.0, 0.02923857979476452, 0.0, 0.39518487453460693, 0.0, 1.1354050636291504, 0.782141387462616, 0.003032467095181346, 0.15989363193511963, 0.0, 0.0, 1.1974776983261108, 0.0915847048163414, 0.0, 0.3434244692325592, 0.1251063197851181, 0.04022427648305893, 0.18256790935993195, 0.041662752628326416, 0.014991097152233124, 0.14232534170150757, 0.08098296821117401]), Row(path='s3a://p8-data-djamel/jupyter/hadoop/data/Test1/Watermelon/178_100.jpg', label='Watermelon', features=[0.005562059581279755, 0.0, 0.0, 0.015787305310368538, 1.326783299446106, 0.02094164863228798, 2.5567777156829834, 0.23360654711723328, 0.0, 0.0, 0.14904220402240753, 0.0, 1.24247407913208, 1.6102657318115234, 0.0, 0.17160822451114655, 0.0, 0.01641158200800419, 0.3659180998802185, 0.13346686959266663, 0.06380864977836609, 0.0, 0.0, 0.036585837602615356, 0.003112747333943844, 0.02634691260755062, 0.04004029184579849, 0.0580735057592392, 0.025248628109693527, 1.1004955768585205, 0.21087411046028137, 0.0, 0.0, 1.1996046304702759, 0.0, 0.24155361950397491, 0.20446820557117462, 0.29046598076820374, 0.0, 0.08547703921794891, 0.0, 0.0, 2.518892526626587, 0.0, 0.27422651648521423, 0.0, 0.7456207275390625, 0.4495368003845215, 1.239848256111145, 0.5623733997344971, 0.0, 0.7146331667900085, 0.4089268147945404, 0.0, 0.21434417366981506, 0.2964728772640228, 0.000624745327513665, 1.8318678140640259, 0.4000765085220337, 0.4222854971885681, 1.7958892583847046, 0.46012189984321594, 0.0, 0.0, 2.7030575275421143, 2.979933500289917, 1.1220285892486572, 0.04167666658759117, 0.01061946526169777, 0.0, 0.01853497326374054, 0.0, 0.0, 0.9548531174659729, 0.017448419705033302, 0.6296657919883728, 0.7437127828598022, 0.31225404143333435, 0.30348101258277893, 0.1198444738984108, 0.0, 1.012863278388977, 0.00031692732591181993, 0.12728922069072723, 0.10817472636699677, 0.0, 0.0, 0.11228247731924057, 1.0333223342895508, 0.8286546468734741, 0.5981587171554565, 0.47010934352874756, 0.6016831398010254, 0.0, 2.2263023853302, 0.9182650446891785, 0.20307935774326324, 0.10650304704904556, 0.9876936078071594, 0.0, 0.21910035610198975, 0.3853842318058014, 0.0, 0.16671305894851685, 1.1614789962768555, 0.0, 0.0, 0.046962931752204895, 0.0, 1.4876840114593506, 0.0, 0.021514344960451126, 0.0, 0.3332321047782898, 0.0, 0.0069045014679431915, 0.6475910544395447, 0.03347114101052284, 0.0, 0.0, 0.009591948240995407, 0.0, 0.0, 0.5072345733642578, 0.159990593791008, 1.0249446630477905, 1.4195973873138428, 1.4707602262496948, 1.4637081623077393, 0.0, 0.0, 0.12734153866767883, 0.9676875472068787, 0.0, 0.4305991232395172, 0.0, 0.0, 0.1103830337524414, 0.2417445033788681, 0.21640847623348236, 0.0, 0.0, 0.2677232325077057, 0.0547310933470726, 0.0, 0.010730959475040436, 0.9557205438613892, 0.7836167216300964, 0.012609509751200676, 0.23239552974700928, 0.0, 0.0, 0.0, 0.0, 0.037865050137043, 2.3410162925720215, 0.0, 0.009083868935704231, 0.6759985089302063, 0.07696928828954697, 0.142130509018898, 0.862291157245636, 0.0, 0.0, 1.6936438083648682, 1.793626070022583, 0.009712474420666695, 0.48666560649871826, 2.8404691219329834, 1.469045877456665, 0.11225643754005432, 0.0, 0.3613007962703705, 0.17959237098693848, 0.0, 0.0, 2.086000442504883, 0.06853263080120087, 0.008516831323504448, 0.0007323718746192753, 3.371842384338379, 0.0, 0.8343347907066345, 0.028787733986973763, 0.8683494925498962, 0.7716127634048462, 0.9506939649581909, 0.14032216370105743, 0.04970625787973404, 0.0, 0.20330192148685455, 1.2145582437515259, 1.1272313594818115, 1.5754072666168213, 0.07890336960554123, 0.0, 0.0, 0.0, 0.01072566770017147, 0.16106879711151123, 0.5888193845748901, 0.0, 0.02277274988591671, 0.043988317251205444, 0.649446427822113, 0.0, 0.0, 0.0, 0.3369429111480713, 0.38285204768180847, 0.0, 0.025134937837719917, 0.0374535508453846, 0.7506586909294128, 0.760036051273346, 0.6047511100769043, 0.9449102282524109, 0.0, 1.3526455163955688, 0.0, 0.5264472365379333, 0.0, 0.07433152198791504, 0.0, 0.3206382989883423, 0.0, 0.0, 0.0, 0.762987494468689, 0.4092051088809967, 1.7677875757217407, 0.004653887823224068, 0.0, 0.7738110423088074, 0.10199698805809021, 0.10875604301691055, 0.0, 0.0, 0.0, 2.194746971130371, 1.9886854887008667, 0.0005398730281740427, 0.0, 0.0, 0.7800295352935791, 0.0, 1.7780628204345703, 0.0, 0.30135849118232727, 0.23476924002170563, 0.3448110818862915, 0.015119893476366997, 1.0170185565948486, 0.0, 0.8296857476234436, 3.4826245307922363, 1.6581352949142456, 0.4403630495071411, 0.0033484797459095716, 0.2395758181810379, 0.0, 2.6354565620422363, 0.743781328201294, 3.065060615539551, 0.0, 0.0, 0.0, 0.0, 0.17913205921649933, 0.0, 0.011583574116230011, 0.44736742973327637, 1.9572423696517944, 0.20181846618652344, 0.38206127285957336, 0.07996071875095367, 0.2730262577533722, 0.0, 0.6493754386901855, 0.2816026210784912, 1.9444276094436646, 0.0, 0.009336689487099648, 0.2546931803226471, 1.9684650897979736, 0.0, 6.314984057098627e-05, 0.27322837710380554, 0.640075147151947, 0.7168382406234741, 0.2924543619155884, 0.00762399286031723, 0.0, 0.0, 0.0, 1.806449294090271, 0.05813741311430931, 0.043299514800310135, 0.1478971540927887, 0.09136689454317093, 0.0, 0.07327063381671906, 0.1877286434173584, 0.03880619630217552, 0.5824259519577026, 0.5596862435340881, 0.0, 0.0, 0.0, 0.0, 0.31074464321136475, 0.9646010994911194, 0.09778468310832977, 0.0, 0.34132450819015503, 0.0, 0.0, 0.0, 0.08382351696491241, 0.01694289781153202, 0.0, 1.8931728601455688, 1.0201733112335205, 0.30417153239250183, 0.027199259027838707, 0.0, 0.0026950149331241846, 0.0, 0.0, 0.2844921350479126, 0.015493897721171379, 0.3619559109210968, 3.443370819091797, 0.01987767033278942, 0.0, 0.541474461555481, 0.0, 0.0, 0.0, 0.6045652627944946, 0.0, 0.0, 0.37276607751846313, 0.15983423590660095, 0.17209510505199432, 0.7998611927032471, 0.8212776780128479, 0.0, 0.007894216105341911, 0.0, 0.0, 0.3417637050151825, 0.0, 1.9734386205673218, 0.0, 0.0, 0.0046878415159881115, 0.0, 0.0, 0.3141997456550598, 0.02062028832733631, 0.5889316201210022, 0.013386588543653488, 1.287357211112976, 0.026453694328665733, 0.0, 0.416136771440506, 0.19710323214530945, 0.0, 0.0, 0.010236511006951332, 0.0, 0.0, 0.18070898950099945, 4.506410121917725, 0.004604295361787081, 0.2991209924221039, 0.06566134095191956, 0.2603748142719269, 0.09004827588796616, 0.0, 1.938814401626587, 0.2881848216056824, 0.0, 0.21781384944915771, 0.0, 0.46191370487213135, 0.0, 0.0, 0.0685146152973175, 3.4069550037384033, 0.0, 0.06394483149051666, 0.0, 0.7947260737419128, 0.19006215035915375, 0.0251968652009964, 0.005904513411223888, 0.0, 0.8646469116210938, 1.0713762044906616, 0.19906191527843475, 0.0, 0.0, 0.0, 0.3194045126438141, 0.7174901962280273, 0.4070511758327484, 0.7541033029556274, 0.0, 3.500805377960205, 4.056454181671143, 0.0, 0.14224287867546082, 0.0, 0.0, 0.0, 0.240664541721344, 0.4593360424041748, 2.965075731277466, 0.1075328141450882, 1.1409677267074585, 0.6167184710502625, 0.01372543629258871, 0.004073989577591419, 0.5818917751312256, 0.3623725473880768, 0.0216937605291605, 0.0, 0.02373744733631611, 0.0, 0.0, 0.06836074590682983, 0.0, 0.0, 0.01866362988948822, 0.0, 0.006388082634657621, 0.1440868228673935, 0.0, 0.0, 0.2538453936576843, 0.2796255946159363, 2.5571343898773193, 1.3538776636123657, 0.5071431994438171, 0.0, 0.0, 0.14279212057590485, 0.0, 0.17644698917865753, 0.22213301062583923, 0.2281118482351303, 0.4806261658668518, 1.51960027217865, 0.09923938661813736, 0.2877848148345947, 0.0, 0.0, 0.0, 2.0290634632110596, 0.0, 0.0, 0.4056997001171112, 0.15182603895664215, 0.0, 1.698799729347229, 0.6970148086547852, 1.0197203159332275, 0.0, 0.12347549945116043, 0.0, 0.0, 3.4225075244903564, 0.24134063720703125, 0.0, 0.08169689774513245, 0.00294912769459188, 0.0, 4.398009777069092, 0.011115672998130322, 0.6801037192344666, 0.0017927433364093304, 2.9471137523651123, 0.06660021841526031, 0.046922195702791214, 0.47309455275535583, 2.796266794204712, 0.0, 0.1557832956314087, 1.5094338655471802, 0.11497838795185089, 0.0, 1.1721515655517578, 2.824751138687134, 0.0, 0.15703622996807098, 0.04096215218305588, 0.09612959623336792, 0.0006949232774786651, 0.0, 0.6727129817008972, 0.049756262451410294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07751215994358063, 0.0, 0.3073274493217468, 0.9119154214859009, 0.033740900456905365, 0.02692929282784462, 0.050074245780706406, 0.020275171846151352, 0.0, 0.0, 0.21602089703083038, 0.10285840928554535, 0.0, 0.7988921403884888, 0.0, 0.0, 0.0, 0.0, 0.08339160680770874, 0.0680289939045906, 1.3324403762817383, 0.6312065720558167, 0.0, 0.010067693889141083, 0.0, 0.15779326856136322, 0.20594576001167297, 0.12523220479488373, 0.0, 0.0, 0.008066081441938877, 0.0, 0.6570161581039429, 0.0, 1.4535338878631592, 0.19801932573318481, 0.35769885778427124, 0.4912528991699219, 0.04227091372013092, 0.013221296481788158, 0.01691308617591858, 0.4500695466995239, 1.8744357824325562, 0.0, 0.0, 0.0, 0.6740970015525818, 0.0237373448908329, 0.029974784702062607, 0.13345064222812653, 2.3611910343170166, 1.8424861431121826, 0.22694669663906097, 0.0, 2.245232105255127, 0.0, 0.8394429683685303, 0.4590608775615692, 0.24971845746040344, 0.0025355073157697916, 0.46302342414855957, 0.0, 0.13813190162181854, 0.23929595947265625, 0.0, 0.12481844425201416, 2.155242919921875, 0.6810786724090576, 0.855851411819458, 0.23933625221252441, 0.0, 1.938979148864746, 0.0, 0.05046071857213974, 0.0, 0.0, 0.1898213028907776, 0.010528257116675377, 0.40713831782341003, 0.0, 0.9596679210662842, 0.035466816276311874, 0.5813452005386353, 0.48969587683677673, 0.0, 1.7283533811569214, 0.0, 0.0, 0.0, 2.1895134449005127, 0.16745629906654358, 0.010379890911281109, 0.04198050498962402, 0.05977348983287811, 0.4663677513599396, 0.0, 0.0, 0.0, 0.12046312540769577, 0.0, 0.0, 0.44320395588874817, 0.2626519799232483, 1.6127605438232422, 0.0, 0.02063721977174282, 2.1893038749694824, 0.04358895495533943, 1.8691996335983276, 0.8242968320846558, 0.0, 0.0, 0.0, 3.790630340576172, 0.8936126828193665, 0.049530621618032455, 0.18633589148521423, 0.005750942975282669, 1.2634575366973877, 0.0, 0.3323695659637451, 0.0, 0.6761911511421204, 0.0, 0.3852071464061737, 0.026446614414453506, 0.0, 1.1222763061523438, 1.1497911214828491, 0.34708723425865173, 0.3050907254219055, 0.500624418258667, 0.0, 0.03180724382400513, 0.4893333911895752, 0.2989164888858795, 0.0, 0.10092542320489883, 0.0, 0.0551605224609375, 1.1893835067749023, 0.0, 0.14040841162204742, 0.059697940945625305, 0.0, 0.0, 0.0, 0.0, 0.5378246903419495, 0.5758786201477051, 0.0, 0.0, 0.13155843317508698, 1.897491455078125, 0.05689818039536476, 0.0, 0.02038448490202427, 0.3794879913330078, 0.0, 0.0, 0.1289585828781128, 0.6500277519226074, 1.1663234233856201, 0.0, 4.216397285461426, 1.4960967302322388, 0.06649863719940186, 0.057943783700466156, 0.477185994386673, 0.0, 0.24992763996124268, 0.0, 0.0, 0.01961352303624153, 0.0, 0.2540474236011505, 0.0, 0.2413795441389084, 0.08287779241800308, 0.22082525491714478, 0.0630980134010315, 2.502002239227295, 1.2604094743728638, 0.0, 0.0, 0.0, 2.039545774459839, 0.0, 0.015081825666129589, 0.40322914719581604, 0.0, 0.0, 0.022183584049344063, 0.0, 0.1631840616464615, 0.0, 0.0, 0.0, 0.7859752178192139, 0.8329381942749023, 0.0, 0.0, 0.0, 0.5681028962135315, 1.4546828269958496, 0.6015042662620544, 0.31176772713661194, 1.3738716840744019, 0.0019069407135248184, 0.3001631796360016, 0.49155035614967346, 0.3867572844028473, 1.2431750297546387, 0.0861722007393837, 0.06739331036806107, 0.0, 0.9328348636627197, 2.3573575019836426, 0.9297513365745544, 0.0, 0.0, 1.4406167268753052, 0.01280207745730877, 1.7241042852401733, 0.0, 0.0017755588050931692, 0.01953115500509739, 0.3542874753475189, 1.2618775367736816, 0.0, 0.3773508667945862, 0.0, 3.174816131591797, 0.31657272577285767, 0.09182857722043991, 0.1657848209142685, 0.08195749670267105, 0.22062987089157104, 0.0, 0.49941518902778625, 0.005236304365098476, 0.0, 0.0, 0.0, 0.09622665494680405, 3.743483781814575, 0.4465368092060089, 0.07866174727678299, 2.4756999015808105, 0.6259866952896118, 0.7126978635787964, 0.06312449276447296, 0.08744271844625473, 0.4223424196243286, 1.4603185653686523, 0.0, 0.0, 0.07247508317232132, 0.39654430747032166, 0.023759055882692337, 0.3649865388870239, 0.0, 0.0, 0.15856866538524628, 0.44031384587287903, 0.009471043944358826, 0.0, 0.019747961312532425, 1.720179557800293, 0.6277436017990112, 0.0, 0.3543640077114105, 0.9243349432945251, 0.0, 0.00865539163351059, 0.06586203724145889, 0.12480606138706207, 0.0, 0.0, 0.0, 0.7102041244506836, 0.0036913775838911533, 0.26095062494277954, 1.461762547492981, 0.4717635214328766, 0.12920865416526794, 0.007532614748924971, 0.07688871026039124, 0.0, 0.0, 0.0, 0.12756696343421936, 0.05904935300350189, 0.0, 0.0, 0.0324389822781086, 0.0, 0.0, 0.0, 0.09154059737920761, 0.0, 0.0, 0.628470778465271, 0.22397123277187347, 0.0, 0.17256680130958557, 0.2180534154176712, 0.14061126112937927, 0.0, 0.0, 0.0, 0.0072280908934772015, 0.2492416948080063, 0.26555922627449036, 0.0, 0.0, 1.9571341276168823, 0.908452033996582, 0.0, 2.999220132827759, 0.7415050864219666, 0.18949730694293976, 0.09821777045726776, 0.03838038817048073, 0.0, 0.0, 0.0, 0.606902539730072, 0.8820124268531799, 0.004317311570048332, 1.4080158472061157, 0.01613510586321354, 0.0, 0.0, 0.4923202395439148, 0.8316235542297363, 0.47761163115501404, 0.16299811005592346, 0.03155141323804855, 0.6113311052322388, 0.07940330356359482, 0.0, 0.0005336061585694551, 2.7620291709899902, 0.0, 0.14577975869178772, 0.07412949949502945, 0.0, 2.729846954345703, 0.07605936378240585, 0.0, 0.0, 0.017670223489403725, 0.0, 0.0, 0.0, 0.0, 0.023483633995056152, 0.0, 0.0, 0.8336483836174011, 0.0, 0.0, 0.0, 0.04434170573949814, 0.4674646556377411, 0.001449192175641656, 0.0, 0.0, 0.0, 0.06272026896476746, 0.6343005299568176, 0.009236420504748821, 0.0, 2.0307888984680176, 0.5837888121604919, 0.5748825073242188, 0.008755877614021301, 0.5918643474578857, 0.0, 0.06733036041259766, 0.0, 0.013095584698021412, 0.0, 0.003614553716033697, 0.6186279654502869, 0.016814017668366432, 0.13345138728618622, 0.03997912257909775, 0.0452016219496727, 0.0, 0.08978857100009918, 0.0762920007109642, 0.8863967061042786, 0.180333212018013, 0.0, 0.6823573708534241, 0.02484053745865822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3228968679904938, 0.10643185675144196, 0.0, 0.11618708819150925, 0.5866293907165527, 0.0, 0.0, 0.0, 0.9777822494506836, 0.490630567073822, 0.0, 0.0, 0.9339373111724854, 0.07681754976511002, 0.024343490600585938, 0.0, 0.0, 0.18864032626152039, 0.00037628563586622477, 0.0, 0.323928564786911, 0.0, 0.02661403827369213, 1.3741828203201294, 0.16354480385780334, 0.0, 0.0, 0.0879182443022728, 0.5894649028778076, 0.0, 0.34026768803596497, 0.5635188221931458, 0.05605442821979523, 3.4011435508728027, 0.006036998704075813, 0.4847202003002167, 0.0, 0.46890923380851746, 0.34799039363861084, 0.6353884339332581, 0.026870550587773323, 1.0468403100967407, 1.205521821975708, 2.2978315353393555, 0.0, 0.6603925824165344, 0.0, 0.05824165418744087, 0.12918338179588318, 0.0, 0.0, 0.527998149394989, 0.0, 0.0, 0.48201075196266174, 0.0, 0.07491932064294815, 0.0007425021030940115, 0.7032232284545898, 1.9705530405044556, 2.98219895362854, 0.036590199917554855, 0.0, 0.4216558635234833, 0.6417551636695862, 0.39113596081733704, 0.8131051063537598, 0.022940319031476974, 0.07719988375902176, 2.792773485183716, 0.0590696819126606, 0.5001288652420044, 0.0, 0.0, 0.013347716070711613, 0.0, 0.0, 0.02072766050696373, 1.4867782592773438, 0.0, 0.8901461362838745, 0.08490309119224548, 0.17659223079681396, 0.12210506945848465, 0.20036639273166656, 0.0, 0.24322065711021423, 0.0, 0.11032523214817047, 0.14845819771289825, 0.0, 0.5786800980567932, 1.7492940425872803, 0.2916374206542969, 0.3540157377719879, 0.028247181326150894, 0.03861360624432564, 0.0, 0.13200269639492035, 0.0, 0.26232895255088806, 0.2097567766904831, 0.8131067156791687, 0.6155275106430054, 0.4295266568660736, 0.6224663257598877, 0.0, 0.538293719291687, 0.43506550788879395, 0.024045392870903015, 0.010339236818253994, 0.0, 0.0, 0.6363608837127686, 0.7759546637535095, 0.7830886244773865, 0.9900400042533875, 0.0, 0.0, 1.260430932044983, 0.17659276723861694, 0.023537304252386093, 0.0, 0.0, 0.0, 0.5361819863319397, 0.0689602866768837, 1.82715904712677, 0.0, 0.0, 0.0, 2.771075487136841, 0.11864204704761505, 0.0, 1.3900091648101807, 0.0, 1.6694931983947754, 0.5401857495307922, 0.0, 0.094761423766613, 1.0492297410964966, 1.5394182205200195, 0.11247043311595917, 0.5313417911529541, 2.7944908142089844, 0.010230529122054577, 0.0, 1.9714274406433105, 0.0, 0.069766104221344, 0.0, 0.03009129874408245, 0.0, 0.412960410118103, 0.18467356264591217, 0.9253419637680054, 1.5269968509674072, 0.6074432730674744, 0.5965811610221863, 0.0, 1.9258249998092651, 0.06695292145013809, 0.01621381938457489, 0.04655023664236069, 0.7656487226486206, 0.33131447434425354, 0.191977396607399, 1.8311166763305664, 0.2830409109592438, 0.0, 0.10425958782434464, 0.25481724739074707, 0.0080784372985363, 0.0, 0.3514840006828308, 2.0047411918640137, 0.09269287437200546, 0.9579081535339355, 0.4192148745059967, 0.1652258336544037, 0.7541874647140503, 0.0, 0.0, 0.03537143021821976, 0.7702552676200867, 0.0764642134308815, 0.0034071060363203287, 0.3594057261943817, 0.3867637515068054, 2.2410449981689453, 1.3159565925598145, 0.0, 0.057573284953832626, 0.0, 0.33994218707084656, 0.0, 0.0, 0.04298491030931473, 0.0, 0.3219304382801056, 0.6249467730522156, 0.10015788674354553, 0.22541305422782898, 0.36943483352661133, 0.4508967101573944, 2.349194288253784, 0.08560631424188614, 0.003315893467515707, 0.17053821682929993, 0.2775852382183075, 0.0, 0.0, 0.0, 0.9320783019065857, 0.025238797068595886, 0.003822933416813612, 0.2490393966436386, 0.23901578783988953, 0.0, 0.051851462572813034, 0.36476486921310425, 1.1110831499099731, 0.0, 2.0730063915252686, 1.7654709815979004, 0.20882734656333923, 0.0, 0.5521925091743469, 0.0, 2.3667635917663574, 0.7341262102127075, 0.0, 1.3827170133590698, 0.09108848869800568, 0.07977060228586197, 0.06157280132174492, 0.0330670028924942, 0.8236605525016785, 0.45880836248397827, 0.34147047996520996, 0.12103551626205444, 0.11141113191843033, 0.23531396687030792, 2.424644708633423, 0.0, 0.009579787030816078, 0.06877294182777405, 0.49784761667251587, 0.3109511435031891, 0.3255339562892914, 0.0, 0.3486284911632538, 0.09515174478292465, 0.18345345556735992, 0.0, 0.0, 0.0, 0.12255364656448364, 0.0, 1.3495482206344604, 0.0, 0.0, 0.15097500383853912, 0.4035942256450653, 1.3242634534835815, 0.019468476995825768, 0.0, 0.0, 0.7011993527412415, 2.876723051071167, 0.0, 0.20947158336639404, 0.004374767187982798, 0.0, 0.2930850684642792, 0.1766480952501297, 0.1509530246257782, 0.14605559408664703, 0.0, 0.0, 1.6641871929168701, 0.05182160064578056, 1.0345673561096191, 0.6409136056900024, 0.07029559463262558, 0.0, 0.7723730206489563, 1.0109552145004272, 0.02356604114174843, 1.65168035030365, 0.6756995916366577, 0.3055780529975891, 0.09789124131202698, 0.0, 0.3367559611797333, 0.4382550120353699, 0.35791903734207153, 0.017463240772485733, 0.03636204078793526, 0.0, 0.2769309878349304, 0.02064567245543003, 0.0, 0.0030427160672843456, 0.023045135661959648, 1.2218413352966309, 0.8714925646781921, 0.0, 0.8278035521507263, 0.0, 0.02688985876739025, 0.6254523992538452, 0.01101536862552166, 1.5282368659973145, 0.06993652135133743, 1.9146225452423096, 0.0924965962767601, 0.9071215391159058, 0.45827510952949524, 0.2936057448387146, 0.8108488321304321, 2.4932494163513184, 0.00989647675305605, 0.024157119914889336, 0.7810570001602173, 0.0, 0.6236898303031921, 1.120120882987976, 0.014567798934876919, 0.9773550033569336, 0.2614952623844147, 0.0, 0.016023609787225723, 0.0, 0.008987437933683395, 0.3317869007587433, 0.0, 0.1298341006040573, 0.4371158480644226, 0.14460773766040802, 0.009882349520921707, 0.46909818053245544, 0.8585620522499084, 0.5425941348075867, 0.2925531566143036, 0.00044330963282845914, 0.028926080092787743, 0.0, 1.8738408088684082, 0.0, 0.4846089482307434, 0.7650159001350403, 0.0033223938662558794, 0.14806723594665527, 0.0, 0.010601002722978592, 0.08049825578927994, 0.08718258887529373, 0.0, 0.9675291180610657, 0.5368496775627136, 0.0955832377076149, 0.4798052906990051, 0.3704245686531067, 0.04515352472662926, 0.0050503588281571865, 0.0])]", "name": "stdout"}]}, {"metadata": {}, "id": "f0c855fd", "cell_type": "raw", "source": "df.loc[0,'features'].shape"}, {"metadata": {"trusted": true}, "id": "ef42063b", "cell_type": "code", "source": "PATH_Result = \"s3a://p8-data-djamel/jupyter/hadoop/data/Results/\"\n\ndf = spark.read.parquet(PATH_Result, engine='pysparrow')", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "id": "a4333776", "cell_type": "code", "source": "# R\u00e9cup\u00e9rer la premi\u00e8re ligne\nfirst_row = df.first()\n\n# Acc\u00e9der \u00e0 la colonne 'features'\nfeatures_array = first_row['features']\n\nprint(type(features_array))\nprint(features_array.shape if hasattr(features_array, 'shape') else len(features_array))\n", "execution_count": 25, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "<class 'list'>\n1280", "name": "stdout"}]}, {"metadata": {}, "id": "648f9481", "cell_type": "raw", "source": "df.shape"}, {"metadata": {"trusted": true}, "id": "49fd0872", "cell_type": "code", "source": "# Nombre de lignes\nnum_rows = df.count()\n\n# Nombre de colonnes\nnum_cols = len(df.columns)\n\nprint(f\"Shape: ({num_rows}, {num_cols})\")\n", "execution_count": 26, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "Shape: (22688, 3)", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Export des features vers CSV"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import udf, col\nfrom pyspark.sql.types import StringType\nfrom pyspark.ml.functions import array_to_vector\nfrom pyspark.ml.feature import PCA\nimport time\n\n# \ud83d\ude80 Session Spark\nspark = SparkSession.builder.appName(\"Export_Features_PCA\").getOrCreate()\n\n# \ud83d\udcc2 Chemins S3 ou HDFS\nPATH_Result = \"s3a://p8-data-djamel/jupyter/hadoop/data/Results/\"\nPATH_CSV_NO_PCA = \"s3a://p8-data-djamel/jupyter/hadoop/data/Matrice/Features\"\nPATH_CSV_PCA = \"s3a://p8-data-djamel/jupyter/hadoop/data/Matrice/Features_pca\"\n\n# 1\ufe0f\u20e3 Lecture du parquet initial\ndf = spark.read.parquet(PATH_Result)\nprint(\"\u2705 Donn\u00e9es charg\u00e9es :\")\ndf.printSchema()\n\n# 2\ufe0f\u20e3 Conversion array<float> \u2192 string (pour CSV)\narray_to_str = udf(lambda arr: ','.join([str(x) for x in arr]) if arr is not None else '', StringType())\ndf_csv = df.withColumn(\"features_str\", array_to_str(col(\"features\"))).select(\"label\", \"features_str\")\n\n# 3\ufe0f\u20e3 Export CSV sans PCA\nstart_no_pca = time.time()\ndf_csv.write.mode(\"overwrite\").option(\"header\", True).csv(PATH_CSV_NO_PCA)\nend_no_pca = time.time()\nprint(f\"\u23f1\ufe0f Export CSV sans PCA termin\u00e9 en {end_no_pca - start_no_pca:.2f} s -> {PATH_CSV_NO_PCA}\")\n\n# 4\ufe0f\u20e3 Application PCA\ndf_vec = df.withColumn(\"features\", array_to_vector(\"features\"))\npca = PCA(k=15, inputCol=\"features\", outputCol=\"pcaFeatures\")\npca_model = pca.fit(df_vec)\ndf_pca = pca_model.transform(df_vec)\n\n# 5\ufe0f\u20e3 Conversion des vecteurs PCA en string\nvector_to_str = udf(lambda v: ','.join([str(x) for x in v.toArray()]), StringType())\ndf_pca_csv = df_pca.withColumn(\"pca_str\", vector_to_str(col(\"pcaFeatures\"))).select(\"label\", \"pca_str\")\n\n# 6\ufe0f\u20e3 Export CSV avec PCA\nstart_pca = time.time()\ndf_pca_csv.write.mode(\"overwrite\").option(\"header\", True).csv(PATH_CSV_PCA)\nend_pca = time.time()\nprint(f\"\u23f1\ufe0f Export CSV avec PCA termin\u00e9 en {end_pca - start_pca:.2f} s -> {PATH_CSV_PCA}\")\n\n# 7\ufe0f\u20e3 Fin\nspark.stop()\nprint(\"\ud83c\udfaf Export complet termin\u00e9.\")\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>21</td><td>application_1760655022197_0024</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-45-20.eu-west-3.compute.internal:20888/proxy/application_1760655022197_0024/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-40-68.eu-west-3.compute.internal:8042/node/containerlogs/container_1760655022197_0024_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "\u2705 Donn\u00e9es charg\u00e9es :\nroot\n |-- path: string (nullable = true)\n |-- label: string (nullable = true)\n |-- features: array (nullable = true)\n |    |-- element: float (containsNull = true)\n\n\u23f1\ufe0f Export CSV sans PCA termin\u00e9 en 17.05 s -> s3a://p8-data-djamel/jupyter/hadoop/data/Matrice/Features\n\u23f1\ufe0f Export CSV avec PCA termin\u00e9 en 8.36 s -> s3a://p8-data-djamel/jupyter/hadoop/data/Matrice/Features_pca\n\ud83c\udfaf Export complet termin\u00e9.", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from pyspark.ml.functions import array_to_vector\nfrom pyspark.ml.feature import PCA\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import ArrayType, FloatType, StringType\nimport time\nimport json\n\n# === 1\ufe0f\u20e3 Conversion array -> vector ===\nfeatures_vector_df = features_df.withColumn(\"features\", array_to_vector(\"features\"))\n\n# === 2\ufe0f\u20e3 PCA (facultatif) ===\napply_pca = True  # \u2699\ufe0f Mets False pour version sans PCA\nk = 15\n\nif apply_pca:\n    print(\"\ud83e\uddee Application de la PCA...\")\n    pca = PCA(k=k, inputCol=\"features\", outputCol=\"pcaFeatures\")\n    pca_model = pca.fit(features_vector_df)\n    df_transformed = pca_model.transform(features_vector_df)\n    df_final = df_transformed.select(\"path\", \"label\", \"pcaFeatures\")\nelse:\n    df_final = features_vector_df.select(\"path\", \"label\", \"features\")\n\n# === 3\ufe0f\u20e3 Conversion du vecteur en tableau JSON (lisible dans CSV) ===\ndef vector_to_json(v):\n    return json.dumps(v.toArray().tolist())\n\nvector_to_json_udf = udf(vector_to_json, StringType())\n\ndf_final = df_final.withColumn(\n    \"features_json\",\n    vector_to_json_udf(col(\"pcaFeatures\") if apply_pca else col(\"features\"))\n).select(\"path\", \"label\", \"features_json\")\n\n# === 4\ufe0f\u20e3 \u00c9criture CSV ===\nPATH_CSV = (\n    \"s3a://p8-data-djamel/jupyter/hadoop/data/Results_CSV_PCA/\"\n    if apply_pca else\n    \"s3a://p8-data-djamel/jupyter/hadoop/data/Results_CSV/\"\n)\n\nstart_time = time.time()\ndf_final.write.mode(\"overwrite\").option(\"header\", \"true\").csv(PATH_CSV)\nend_time = time.time()\n\nprint(f\"\u2705 CSV export\u00e9 vers : {PATH_CSV}\")\nprint(f\"\u23f1\ufe0f Temps d'\u00e9criture : {end_time - start_time:.2f} sec\")\n", "execution_count": 27, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "\ud83e\uddee Application de la PCA...\n\u2705 CSV export\u00e9 vers : s3a://p8-data-djamel/jupyter/hadoop/data/Results_CSV_PCA/\n\u23f1\ufe0f Temps d'\u00e9criture : 314.91 sec", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "PATH_Result = \"s3://p8-data-djamel/jupyter/hadoop/data/Results/\"\n\n# Lecture du r\u00e9sultat Parquet\ndf_spark = spark.read.parquet(PATH_Result)\n\n# V\u00e9rifie le sch\u00e9ma\ndf_spark.printSchema()\n\n# Affiche quelques lignes\ndf_spark.show(5, truncate=False)\n\n# Nombre de lignes\nprint(\"Nombre de lignes :\", df_spark.count())\n", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "72974aab", "cell_type": "markdown", "source": "<u>On peut \u00e9galement constater la pr\u00e9sence des fichiers <br />\n    au format \"**parquet**\" sur le **serveur S3**</u> :\n\n![Affichage des r\u00e9sultats sur S3](img/S3_Results.png)\n\n## 4.11 Suivi de l'avancement des t\u00e2ches avec le Serveur d'Historique Spark\n\nIl est possible de voir l'avancement des t\u00e2ches en cours <br />\navec le **serveur d'historique Spark**.\n\n![Acc\u00e8s au serveur d'historique spark](img/EMR_serveur_historique_spark_acces.png)\n\n**Il est \u00e9galement possible de revenir et d'\u00e9tudier les t\u00e2ches <br />\nqui ont \u00e9t\u00e9 r\u00e9alis\u00e9, afin de debugger, optimiser les futurs <br />\nt\u00e2ches \u00e0 r\u00e9aliser.**\n\n<u>Lorsque la commande \"**features_df.write.mode(\"overwrite\").parquet(PATH_Result)**\" <br />\n\u00e9tait en cours, nous pouvions observer son \u00e9tat d'avancement</u> :\n\n![Progression execution script](img/EMR_jupyterhub_avancement.png)\n\n<u>Le **serveur d'historique Spark** nous permet une vision beaucoup plus pr\u00e9cise <br />\nde l'ex\u00e9cution des diff\u00e9rentes t\u00e2che sur les diff\u00e9rentes machines du cluster</u> :\n\n![Suivi des t\u00e2ches spark](img/EMR_SHSpark_01.png)\n\nOn peut \u00e9galement constater que notre cluster de calcul a mis <br />\nun tout petit peu **moins de 8 minutes** pour traiter les **22 688 images**.\n\n![Temps de traitement](img/EMR_SHSpark_02.png)\n"}, {"metadata": {}, "id": "b22d65bf", "cell_type": "markdown", "source": "## 4.12 R\u00e9siliation de l'instance EMR\n\nNotre travail est maintenant termin\u00e9. <br />\nLe cluster de machines EMR est **factur\u00e9 \u00e0 la demande**, <br />\net nous continuons d'\u00eatre factur\u00e9 m\u00eame lorsque <br />\nles machines sont au repos.<br />\nPour **optimiser la facturation**, il nous faut <br />\nmaintenant **r\u00e9silier le cluster**.\n\n<u>Je r\u00e9alise cette commande depuis l'interface AWS</u> :\n\n1. Commencez par **d\u00e9sactiver le tunnel ssh dans FoxyProxy** pour \u00e9viter des probl\u00e8mes de **timeout**.\n![D\u00e9sactivation de FoxyProxy](img/EMR_foxyproxy_desactivation.png)\n2. Cliquez sur \"**R\u00e9silier**\"\n![Cliquez sur R\u00e9silier](img/EMR_resiliation_01.png)\n3. Confirmez la r\u00e9siliation\n![Confirmez la r\u00e9siliation](img/EMR_resiliation_02.png)\n4. La r\u00e9siliation prend environ **1 minute**\n![R\u00e9siliation en cours](img/EMR_resiliation_03.png)\n5. La r\u00e9siliation est effectu\u00e9e\n![R\u00e9siliation termin\u00e9e](img/EMR_resiliation_04.png)\n\n## 4.13 Cloner le serveur EMR (si besoin)\n\nSi nous devons de nouveau ex\u00e9cuter notre notebook dans les m\u00eames conditions, <br />\nil nous suffit de **cloner notre cluster** et ainsi en obtenir une copie fonctionnelle <br />\nsous 15/20 minutes, le temps de son instanciation.\n\n<u>Pour cela deux solutions</u> :\n1. <u>Depuis l'interface AWS</u> :\n 1. Cliquez sur \"**Cloner**\"\n   ![Cloner un cluster](img/EMR_cloner_01.png)\n 2. Dans notre cas nous ne souhaitons pas inclure d'\u00e9tapes\n   ![Ne pas inclure d'\u00e9tapes](img/EMR_cloner_02.png)\n 3. La configuration du cluster est recr\u00e9\u00e9e \u00e0 l\u2019identique. <br />\n    On peut revenir sur les diff\u00e9rentes \u00e9tapes si on souhaite apporter des modifications<br />\n    Quand tout est pr\u00eat, cliquez sur \"**Cr\u00e9er un cluster**\"\n  ![V\u00e9rification/Modification/Cr\u00e9er un cluster](img/EMR_cloner_03.png)\n2. <u>En ligne de commande</u> (avec AWS CLI d'install\u00e9 et de configur\u00e9 et en s'assurant <br />\n   de s'attribuer les droits n\u00e9cessaires sur le compte AMI utilis\u00e9)\n 1. Cliquez sur \"**Exporter AWS CLI**\"\n ![Exporter AWS CLI](img/EMR_cloner_cli_01.png)\n 2. Copier/Coller la commande **depuis un terminal**\n ![Copier Coller Commande](img/EMR_cloner_cli_02.png)\n\n## 4.14 Arborescence du serveur S3 \u00e0 la fin du projet\n\n<u>Pour information, voici **l'arborescence compl\u00e8te de mon bucket S3 p8-data** \u00e0 la fin du projet</u> : <br />\n*Par soucis de lisibilit\u00e9, je ne liste pas les 131 sous dossiers du r\u00e9pertoire \"Test\"*\n\n1. Results/_SUCCESS\n1. Results/part-00000-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00001-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00002-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00003-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00004-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00005-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00006-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00007-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00008-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00009-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00010-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00011-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00012-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00013-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00014-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00015-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00016-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00017-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00018-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00019-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00020-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00021-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00022-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Results/part-00023-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n1. Test/\n1. bootstrap-emr.sh\n1. jupyter-s3-conf.json\n1. jupyter/jovyan/.s3keep\n1. jupyter/jovyan/P8_01_Notebook.ipynb\n1. jupyter/jovyan/_metadata\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/file-perm.sqlite\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/html/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/latex/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbsignatures.db\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/notebook_secret\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled1-checkpoint.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/test3-checkpoint.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled1.ipynb\n1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/test3.ipynb"}, {"metadata": {}, "id": "4eba46f9", "cell_type": "markdown", "source": "# 5. Conclusion\n\nNous avons r\u00e9alis\u00e9 ce projet **en deux temps** en tenant <br />\ncompte des contraintes qui nous ont \u00e9t\u00e9 impos\u00e9es.\n\nNous avons **dans un premier temps d\u00e9velopp\u00e9 notre solution en local** <br />\nsur une machine virtuelle dans un environnement Linux Ubuntu.\n\nLa <u>premi\u00e8re phase</u> a consist\u00e9 \u00e0 **installer l'environnement de travail Spark**. <br />\n**Spark** a un param\u00e8tre qui nous permet de travaill\u00e9 en local et nous permet <br />\nainsi de **simuler du calcul partag\u00e9** en consid\u00e9rant <br />\n**chaque c\u0153ur d'un processeur comme un worker ind\u00e9pendant**.<br />\nNous avons travaill\u00e9 sur un plus **petit jeu de donn\u00e9e**, l'id\u00e9e \u00e9tait <br />\nsimplement de **valider le bon fonctionnement de la solution**.\n\nNous avons fait le choix de r\u00e9aliser du **transfert learning** <br />\n\u00e0 partir du model **MobileNetV2**.<br />\nCe mod\u00e8le a \u00e9t\u00e9 retenu pour sa **l\u00e9g\u00e8ret\u00e9** et sa **rapidit\u00e9 d'ex\u00e9cution** <br />\nainsi que pour la **faible dimension de son vecteur en sortie**.\n\nLes r\u00e9sultats ont \u00e9t\u00e9 enregistr\u00e9s sur disque en plusieurs <br />\npartitions au format \"**parquet**\".\n\n<u>**La solution a parfaitement fonctionn\u00e9 en mode local**</u>.\n\nLa <u>deuxi\u00e8me phase</u> a consist\u00e9 \u00e0 cr\u00e9er un **r\u00e9el cluster de calculs**. <br />\nL'objectif \u00e9tait de pouvoir **anticiper une future augmentation de la charge de travail**.\n\nLe meilleur choix retenu a \u00e9t\u00e9 l'utilisation du prestataire de services **Amazon Web Services** <br />\nqui nous permet de **louer \u00e0 la demande de la puissance de calculs**, <br />\npour un **co\u00fbt tout \u00e0 fait acceptable**.<br />\nCe service se nomme **EC2** et se classe parmi les offres **Infrastructure As A Service** (IAAS).\n\nNous sommes allez plus loin en utilisant un service de plus <br />\nhaut niveau (**Plateforme As A Service** PAAS)<br />\nen utilisant le service **EMR** qui nous permet d'un seul coup <br />\nd'**instancier plusieurs serveur (un cluster)** sur lesquels <br />\nnous avons pu demander l'installation et la configuration de plusieurs<br />\nprogrammes et librairies n\u00e9cessaires \u00e0 notre projet comme **Spark**, <br />\n**Hadoop**, **JupyterHub** ainsi que la librairie **TensorFlow**.\n\nEn plus d'\u00eatre plus **rapide et efficace \u00e0 mettre en place**, nous avons <br />\nla **certitude du bon fonctionnement de la solution**, celle-ci ayant \u00e9t\u00e9 <br />\npr\u00e9alablement valid\u00e9 par les ing\u00e9nieurs d'Amazon.\n\nNous avons \u00e9galement pu installer, sans difficult\u00e9, **les packages <br />\nn\u00e9cessaires sur l'ensembles des machines du cluster**.\n\nEnfin, avec tr\u00e8s peu de modification, et plus simplement encore, <br />\nnous avons pu **ex\u00e9cuter notre notebook comme nous l'avions fait localement**.<br />\nNous avons cette fois-ci ex\u00e9cut\u00e9 le traitement sur **l'ensemble des images de notre dossier \"Test\"**.\n\nNous avons opt\u00e9 pour le service **Amazon S3** pour **stocker les donn\u00e9es de notre projet**. <br />\nS3 offre, pour un faible co\u00fbt, toutes les conditions dont nous avons besoin pour stocker <br />\net exploiter de mani\u00e8re efficace nos donn\u00e9es.<br />\nL'espace allou\u00e9 est potentiellement **illimit\u00e9**, mais les co\u00fbts seront fonction de l'espace utilis\u00e9.\n\nIl nous sera **facile de faire face \u00e0 une mont\u00e9 de la charge de travail** en **redimensionnant** <br />\nsimplement notre cluster de machines (horizontalement et/ou verticalement au besoin), <br />\nles co\u00fbts augmenteront en cons\u00e9quence mais resteront nettement inf\u00e9rieurs aux co\u00fbts engendr\u00e9s <br />\npar l'achat de mat\u00e9riels ou par la location de serveurs d\u00e9di\u00e9s."}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "calc(100% - 180px)", "left": "10px", "top": "150px", "width": "432.4px"}, "toc_section_display": true, "toc_window_display": true}}, "nbformat": 4, "nbformat_minor": 5}